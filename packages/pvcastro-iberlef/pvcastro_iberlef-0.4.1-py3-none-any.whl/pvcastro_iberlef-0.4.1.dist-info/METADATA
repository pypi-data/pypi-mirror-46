Metadata-Version: 2.1
Name: pvcastro-iberlef
Version: 0.4.1
Summary: System for the IberLEF 2019 NER Task
Home-page: http://www.inf.pucrs.br/linatural/wordpress/iberlef-2019/
Author: Pedro Vitor Quinta de Castro
Author-email: pvcastro@gmail.com
License: UNKNOWN
Platform: UNKNOWN
Description-Content-Type: text/markdown
Requires-Dist: fire

## Installation instructions

1. Download and install the latest Anaconda distribution from [here](https://www.anaconda.com/distribution/#download-section)

2. Start the *Anaconda Powershell Prompt* if running Windows, or a terminal otherwise. Make sure conda is available in the command line path.

3. Create a conda environment running `conda create -n pvcastro-iberlef python=3.6`

4. Update Anaconda running `conda update -n base -c defaults conda`

5. Install pytorch running `conda install pytorch-cpu -c pytorch -n pvcastro-iberlef`

6. Activate the created conda environment using `conda activate pvcastro-iberlef`

7. Install the AllenNLP framework running `pip install -U allennlp`

8. Download the spacy model running `python -m spacy download en_core_web_sm`

9. Install the pvcastro-iberlef module running `pip install -U pvcastro-iberlef`

---

## Execution instructions

Run the NER prediction with a command as `python -m pvcastro_iberlef.predict_ner --document-path path_to_the_input_document --out-path path_to_the_output_file`

Parameters: 

- **document-path**: path to the document containing the text to be predicted for NER, with one token per line, with sentences separated by blank lines.
- **out-path**: path to the document where the predictions results will be written. **Must specify a filename**. Example: C:\iberlef\predictions.txt

## Observations

Since the IberLEF NER model uses two language models based on [ELMo](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md), the trained model ended up quite big, with **1.4Gb aproximately**. It takes a while to download it the first time, but the model is cached, so following executions after the first will be quicker. 


