{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Decode BBCI Data with Start-Stop-Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to read and decode BBCI data with start and stop markers. The data loading part is more complicated and it is advised to read the other tutorials before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup logging to see outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.DEBUG, stream=sys.stdout)\n",
    "log = logging.getLogger()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit more complicated than before since we have to add breaks etc. Here I now opt to add breaks do all preprocessings per run and only later combine them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from braindecode.datautil.splitters import concatenate_sets\n",
    "from braindecode.datautil.trial_segment import create_signal_target_from_raw_mne, add_breaks\n",
    "from braindecode.datasets.bbci import load_bbci_sets_from_folder\n",
    "from copy import deepcopy\n",
    "from braindecode.mne_ext.signalproc import resample_cnt, mne_apply\n",
    "from braindecode.datautil.signalproc import lowpass_cnt\n",
    "from braindecode.datautil.signalproc import exponential_running_standardize\n",
    "\n",
    "def create_cnts(folder, runs,):\n",
    "    # Load data\n",
    "    cnts = load_bbci_sets_from_folder(folder, runs)\n",
    "    \n",
    "    # Now do some preprocessings:\n",
    "    # Resampling to 250 Hz, lowpass below 38, eponential standardization\n",
    "    \n",
    "    new_cnts = []\n",
    "    for cnt in cnts:\n",
    "        # Only take some channels \n",
    "        #cnt = cnt.drop_channels(['STI 014']) # This would remove stimulus channel\n",
    "        cnt = cnt.pick_channels(['C3', 'CPz', 'C4'])\n",
    "        log.info(\"Preprocessing....\")\n",
    "        cnt = mne_apply(lambda a: lowpass_cnt(a, 38,cnt.info['sfreq'], axis=1), cnt)\n",
    "        cnt = resample_cnt(cnt, 250)\n",
    "        # mne apply will apply the function to the data (a 2d-numpy-array)\n",
    "        # have to transpose data back and forth, since\n",
    "        # exponential_running_standardize expects time x chans order\n",
    "        # while mne object has chans x time order\n",
    "        cnt = mne_apply(lambda a: exponential_running_standardize(\n",
    "            a.T, init_block_size=1000,factor_new=0.001, eps=1e-4).T,\n",
    "            cnt)\n",
    "        new_cnts.append(cnt)\n",
    "    return new_cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:54:16,149 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R01_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=151350\n",
      "    Range : 0 ... 151349 =      0.000 ...   605.396 secs\n",
      "Ready.\n",
      "2017-11-03 17:54:17,481 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R02_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=153500\n",
      "    Range : 0 ... 153499 =      0.000 ...   613.996 secs\n",
      "Ready.\n",
      "2017-11-03 17:54:18,843 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/AnLaNBD1S001R03_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=180700\n",
      "    Range : 0 ... 180699 =      0.000 ...   722.796 secs\n",
      "Ready.\n",
      "2017-11-03 17:54:20,609 INFO : Preprocessing....\n",
      "2017-11-03 17:54:20,626 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-11-03 17:54:20,801 INFO : Preprocessing....\n",
      "2017-11-03 17:54:20,809 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-11-03 17:54:21,018 INFO : Preprocessing....\n",
      "2017-11-03 17:54:21,026 INFO : Just copying data, no resampling, since new sampling rate same.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "train_runs = [1,2,3]\n",
    "train_cnts = create_cnts('/home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R01-8/', \n",
    "                         train_runs,)\n",
    "\n",
    "name_to_start_code = OrderedDict([('Right Hand', 1), ('Feet', 4),\n",
    "            ('Rotation', 8), ('Words', [10])])\n",
    "\n",
    "name_to_stop_code = OrderedDict([('Right Hand', [20,21,22,23,24,28,30]),\n",
    "        ('Feet', [20,21,22,23,24,28,30]),\n",
    "        ('Rotation', [20,21,22,23,24,28,30]), \n",
    "        ('Words', [20,21,22,23,24,28,30])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:54:21,179 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/AnLaNBD1S001R09_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=152050\n",
      "    Range : 0 ... 152049 =      0.000 ...   608.196 secs\n",
      "Ready.\n",
      "2017-11-03 17:54:22,618 INFO : Loading /home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/AnLaNBD1S001R10_1-1_250Hz.BBCI.mat\n",
      "Creating RawArray with float64 data, n_channels=64, n_times=151100\n",
      "    Range : 0 ... 151099 =      0.000 ...   604.396 secs\n",
      "Ready.\n",
      "2017-11-03 17:54:24,103 INFO : Preprocessing....\n",
      "2017-11-03 17:54:24,112 INFO : Just copying data, no resampling, since new sampling rate same.\n",
      "2017-11-03 17:54:24,277 INFO : Preprocessing....\n",
      "2017-11-03 17:54:24,284 INFO : Just copying data, no resampling, since new sampling rate same.\n"
     ]
    }
   ],
   "source": [
    "test_runs = [9,10]\n",
    "test_cnts = create_cnts('/home/schirrmr/data/robot-hall/AnLa/AnLaNBD1R09-10/', test_runs,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already create the model now, since we need to know the receptive field size for properly cutting out the data to predict. We need to cut out data starting at -receptive_field_size samples before the first sample we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 predictions per input/trial\n",
      "Receptive field: 518/2072.00 (samples/ms)\n"
     ]
    }
   ],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = True\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "\n",
    "# This will determine how many crops are processed in parallel\n",
    "input_time_length = 650\n",
    "in_chans = train_cnts[0].get_data().shape[0]\n",
    "# final_conv_length determines the size of the receptive field of the ConvNet\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=5, input_time_length=input_time_length,\n",
    "                        final_conv_length=29).create_network()\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "from braindecode.torch_ext.util import np_to_var\n",
    "import numpy as np\n",
    "# determine output size\n",
    "test_input = np_to_var(np.ones((2, in_chans, input_time_length, 1), dtype=np.float32))\n",
    "if cuda:\n",
    "    test_input = test_input.cuda()\n",
    "out = model(test_input)\n",
    "n_preds_per_input = out.cpu().data.numpy().shape[2]\n",
    "print(\"{:d} predictions per input/trial\".format(n_preds_per_input))\n",
    "n_receptive_field = input_time_length - n_preds_per_input\n",
    "receptive_field_ms = n_receptive_field * 1000.0 / train_cnts[0].info['sfreq']\n",
    "print(\"Receptive field: {:d}/{:.2f} (samples/ms)\".format(n_receptive_field,\n",
    "                                                      receptive_field_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SignalAndTarget Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:54:27,739 INFO : Trial per class:\n",
      "Counter({'Break': 72, 'Right Hand': 29, 'Words': 21, 'Feet': 19, 'Rotation': 4})\n",
      "2017-11-03 17:54:27,766 INFO : Trial per class:\n",
      "Counter({'Break': 80, 'Feet': 31, 'Words': 26, 'Right Hand': 18, 'Rotation': 6})\n",
      "2017-11-03 17:54:27,796 INFO : Trial per class:\n",
      "Counter({'Break': 95, 'Feet': 38, 'Words': 29, 'Right Hand': 22, 'Rotation': 7})\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datautil.trial_segment import create_signal_target_with_breaks_from_mne\n",
    "\n",
    "break_start_offset_ms = 1000\n",
    "break_stop_offset_ms = -500\n",
    "\n",
    "train_sets = [create_signal_target_with_breaks_from_mne(\n",
    "    cnt, name_to_start_code, [0,0], \n",
    "    name_to_stop_code, min_break_length_ms=1000, max_break_length_ms=10000,\n",
    "    break_epoch_ival_ms=[500,-500],\n",
    "    prepad_trials_to_n_samples=input_time_length) \n",
    "              for cnt in train_cnts]\n",
    "train_set = concatenate_sets(train_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:54:27,856 INFO : Trial per class:\n",
      "Counter({'Break': 76, 'Feet': 24, 'Right Hand': 24, 'Words': 19, 'Rotation': 10})\n",
      "2017-11-03 17:54:27,884 INFO : Trial per class:\n",
      "Counter({'Break': 80, 'Feet': 30, 'Right Hand': 22, 'Words': 21, 'Rotation': 8})\n"
     ]
    }
   ],
   "source": [
    "test_sets = [create_signal_target_with_breaks_from_mne(\n",
    "    cnt, name_to_start_code, [0,0], \n",
    "    name_to_stop_code, min_break_length_ms=1000, max_break_length_ms=10000,\n",
    "    break_epoch_ival_ms=[500,-500],\n",
    "    prepad_trials_to_n_samples=input_time_length) \n",
    "              for cnt in test_cnts]\n",
    "test_set = concatenate_sets(test_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.splitters import split_into_two_sets\n",
    "\n",
    "train_set, valid_set = split_into_two_sets(train_set, first_set_fraction=0.8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup optimizer and iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.iterators import CropsFromTrialsIterator\n",
    "iterator = CropsFromTrialsIterator(batch_size=32,input_time_length=input_time_length,\n",
    "                                  n_preds_per_input=n_preds_per_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Monitors, Loss function, Stop Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.experiments.experiment import Experiment\n",
    "from braindecode.experiments.monitors import RuntimeMonitor, LossMonitor, CroppedTrialMisclassMonitor, MisclassMonitor\n",
    "from braindecode.experiments.stopcriteria import MaxEpochs\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "from braindecode.torch_ext.modules import Expression\n",
    "from braindecode.torch_ext.losses import log_categorical_crossentropy\n",
    "\n",
    "\n",
    "loss_function = log_categorical_crossentropy\n",
    "\n",
    "model_constraint = None\n",
    "monitors = [LossMonitor(), MisclassMonitor(col_suffix='sample_misclass'),\n",
    "            CroppedTrialMisclassMonitor(input_time_length), RuntimeMonitor(),]\n",
    "stop_criterion = MaxEpochs(20)\n",
    "exp = Experiment(model, train_set, valid_set, test_set, iterator, loss_function, optimizer, model_constraint,\n",
    "          monitors, stop_criterion, remember_best_column='valid_misclass',\n",
    "          run_after_early_stop=True, batch_modifier=None, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:54:28,100 INFO : Run until first stop...\n",
      "2017-11-03 17:54:29,008 INFO : Epoch 0\n",
      "2017-11-03 17:54:29,011 INFO : train_loss                6.69229\n",
      "2017-11-03 17:54:29,012 INFO : valid_loss                6.46568\n",
      "2017-11-03 17:54:29,013 INFO : test_loss                 7.03033\n",
      "2017-11-03 17:54:29,014 INFO : train_sample_misclass     0.82260\n",
      "2017-11-03 17:54:29,015 INFO : valid_sample_misclass     0.80963\n",
      "2017-11-03 17:54:29,016 INFO : test_sample_misclass      0.84529\n",
      "2017-11-03 17:54:29,017 INFO : train_misclass            0.84673\n",
      "2017-11-03 17:54:29,018 INFO : valid_misclass            0.83838\n",
      "2017-11-03 17:54:29,019 INFO : test_misclass             0.87261\n",
      "2017-11-03 17:54:29,020 INFO : runtime                   0.00000\n",
      "2017-11-03 17:54:29,021 INFO : \n",
      "2017-11-03 17:54:29,023 INFO : New best valid_misclass: 0.838384\n",
      "2017-11-03 17:54:29,024 INFO : \n",
      "2017-11-03 17:54:29,883 INFO : Time only for training updates: 0.76s\n",
      "2017-11-03 17:54:30,662 INFO : Epoch 1\n",
      "2017-11-03 17:54:30,663 INFO : train_loss                1.11019\n",
      "2017-11-03 17:54:30,664 INFO : valid_loss                1.27928\n",
      "2017-11-03 17:54:30,665 INFO : test_loss                 1.36444\n",
      "2017-11-03 17:54:30,666 INFO : train_sample_misclass     0.42905\n",
      "2017-11-03 17:54:30,667 INFO : valid_sample_misclass     0.49247\n",
      "2017-11-03 17:54:30,668 INFO : test_sample_misclass      0.53468\n",
      "2017-11-03 17:54:30,669 INFO : train_misclass            0.35427\n",
      "2017-11-03 17:54:30,670 INFO : valid_misclass            0.44444\n",
      "2017-11-03 17:54:30,671 INFO : test_misclass             0.45541\n",
      "2017-11-03 17:54:30,672 INFO : runtime                   1.78367\n",
      "2017-11-03 17:54:30,673 INFO : \n",
      "2017-11-03 17:54:30,675 INFO : New best valid_misclass: 0.444444\n",
      "2017-11-03 17:54:30,676 INFO : \n",
      "2017-11-03 17:54:31,506 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:32,301 INFO : Epoch 2\n",
      "2017-11-03 17:54:32,304 INFO : train_loss                0.89880\n",
      "2017-11-03 17:54:32,305 INFO : valid_loss                1.17010\n",
      "2017-11-03 17:54:32,306 INFO : test_loss                 1.30903\n",
      "2017-11-03 17:54:32,307 INFO : train_sample_misclass     0.34776\n",
      "2017-11-03 17:54:32,308 INFO : valid_sample_misclass     0.41259\n",
      "2017-11-03 17:54:32,309 INFO : test_sample_misclass      0.50234\n",
      "2017-11-03 17:54:32,310 INFO : train_misclass            0.28643\n",
      "2017-11-03 17:54:32,311 INFO : valid_misclass            0.40404\n",
      "2017-11-03 17:54:32,312 INFO : test_misclass             0.46815\n",
      "2017-11-03 17:54:32,313 INFO : runtime                   1.62281\n",
      "2017-11-03 17:54:32,314 INFO : \n",
      "2017-11-03 17:54:32,317 INFO : New best valid_misclass: 0.404040\n",
      "2017-11-03 17:54:32,318 INFO : \n",
      "2017-11-03 17:54:33,151 INFO : Time only for training updates: 0.73s\n",
      "2017-11-03 17:54:33,950 INFO : Epoch 3\n",
      "2017-11-03 17:54:33,952 INFO : train_loss                0.81194\n",
      "2017-11-03 17:54:33,953 INFO : valid_loss                1.23906\n",
      "2017-11-03 17:54:33,954 INFO : test_loss                 1.32349\n",
      "2017-11-03 17:54:33,955 INFO : train_sample_misclass     0.31683\n",
      "2017-11-03 17:54:33,956 INFO : valid_sample_misclass     0.44712\n",
      "2017-11-03 17:54:33,957 INFO : test_sample_misclass      0.49383\n",
      "2017-11-03 17:54:33,957 INFO : train_misclass            0.25628\n",
      "2017-11-03 17:54:33,958 INFO : valid_misclass            0.43434\n",
      "2017-11-03 17:54:33,959 INFO : test_misclass             0.45860\n",
      "2017-11-03 17:54:33,960 INFO : runtime                   1.64646\n",
      "2017-11-03 17:54:33,960 INFO : \n",
      "2017-11-03 17:54:34,776 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:35,547 INFO : Epoch 4\n",
      "2017-11-03 17:54:35,549 INFO : train_loss                0.73879\n",
      "2017-11-03 17:54:35,549 INFO : valid_loss                1.21058\n",
      "2017-11-03 17:54:35,550 INFO : test_loss                 1.31367\n",
      "2017-11-03 17:54:35,551 INFO : train_sample_misclass     0.27924\n",
      "2017-11-03 17:54:35,552 INFO : valid_sample_misclass     0.42925\n",
      "2017-11-03 17:54:35,553 INFO : test_sample_misclass      0.47731\n",
      "2017-11-03 17:54:35,553 INFO : train_misclass            0.23618\n",
      "2017-11-03 17:54:35,554 INFO : valid_misclass            0.39394\n",
      "2017-11-03 17:54:35,555 INFO : test_misclass             0.44586\n",
      "2017-11-03 17:54:35,556 INFO : runtime                   1.62406\n",
      "2017-11-03 17:54:35,556 INFO : \n",
      "2017-11-03 17:54:35,559 INFO : New best valid_misclass: 0.393939\n",
      "2017-11-03 17:54:35,559 INFO : \n",
      "2017-11-03 17:54:36,368 INFO : Time only for training updates: 0.71s\n",
      "2017-11-03 17:54:37,117 INFO : Epoch 5\n",
      "2017-11-03 17:54:37,118 INFO : train_loss                0.69937\n",
      "2017-11-03 17:54:37,119 INFO : valid_loss                1.20308\n",
      "2017-11-03 17:54:37,120 INFO : test_loss                 1.31024\n",
      "2017-11-03 17:54:37,121 INFO : train_sample_misclass     0.26148\n",
      "2017-11-03 17:54:37,121 INFO : valid_sample_misclass     0.42965\n",
      "2017-11-03 17:54:37,122 INFO : test_sample_misclass      0.46976\n",
      "2017-11-03 17:54:37,123 INFO : train_misclass            0.23116\n",
      "2017-11-03 17:54:37,124 INFO : valid_misclass            0.41414\n",
      "2017-11-03 17:54:37,124 INFO : test_misclass             0.46497\n",
      "2017-11-03 17:54:37,125 INFO : runtime                   1.59298\n",
      "2017-11-03 17:54:37,126 INFO : \n",
      "2017-11-03 17:54:37,940 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:38,703 INFO : Epoch 6\n",
      "2017-11-03 17:54:38,704 INFO : train_loss                0.68692\n",
      "2017-11-03 17:54:38,705 INFO : valid_loss                1.21140\n",
      "2017-11-03 17:54:38,706 INFO : test_loss                 1.37866\n",
      "2017-11-03 17:54:38,707 INFO : train_sample_misclass     0.26337\n",
      "2017-11-03 17:54:38,707 INFO : valid_sample_misclass     0.42246\n",
      "2017-11-03 17:54:38,708 INFO : test_sample_misclass      0.47892\n",
      "2017-11-03 17:54:38,709 INFO : train_misclass            0.22613\n",
      "2017-11-03 17:54:38,710 INFO : valid_misclass            0.41414\n",
      "2017-11-03 17:54:38,710 INFO : test_misclass             0.43631\n",
      "2017-11-03 17:54:38,711 INFO : runtime                   1.57037\n",
      "2017-11-03 17:54:38,712 INFO : \n",
      "2017-11-03 17:54:39,529 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:40,288 INFO : Epoch 7\n",
      "2017-11-03 17:54:40,290 INFO : train_loss                0.64330\n",
      "2017-11-03 17:54:40,291 INFO : valid_loss                1.26310\n",
      "2017-11-03 17:54:40,291 INFO : test_loss                 1.33326\n",
      "2017-11-03 17:54:40,292 INFO : train_sample_misclass     0.23914\n",
      "2017-11-03 17:54:40,293 INFO : valid_sample_misclass     0.43057\n",
      "2017-11-03 17:54:40,294 INFO : test_sample_misclass      0.45974\n",
      "2017-11-03 17:54:40,295 INFO : train_misclass            0.19347\n",
      "2017-11-03 17:54:40,295 INFO : valid_misclass            0.37374\n",
      "2017-11-03 17:54:40,296 INFO : test_misclass             0.43312\n",
      "2017-11-03 17:54:40,297 INFO : runtime                   1.58912\n",
      "2017-11-03 17:54:40,298 INFO : \n",
      "2017-11-03 17:54:40,300 INFO : New best valid_misclass: 0.373737\n",
      "2017-11-03 17:54:40,301 INFO : \n",
      "2017-11-03 17:54:41,126 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:41,882 INFO : Epoch 8\n",
      "2017-11-03 17:54:41,884 INFO : train_loss                0.63941\n",
      "2017-11-03 17:54:41,885 INFO : valid_loss                1.26822\n",
      "2017-11-03 17:54:41,885 INFO : test_loss                 1.37385\n",
      "2017-11-03 17:54:41,886 INFO : train_sample_misclass     0.24020\n",
      "2017-11-03 17:54:41,887 INFO : valid_sample_misclass     0.43108\n",
      "2017-11-03 17:54:41,888 INFO : test_sample_misclass      0.47164\n",
      "2017-11-03 17:54:41,888 INFO : train_misclass            0.20352\n",
      "2017-11-03 17:54:41,889 INFO : valid_misclass            0.44444\n",
      "2017-11-03 17:54:41,890 INFO : test_misclass             0.42675\n",
      "2017-11-03 17:54:41,891 INFO : runtime                   1.59709\n",
      "2017-11-03 17:54:41,891 INFO : \n",
      "2017-11-03 17:54:42,704 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:43,453 INFO : Epoch 9\n",
      "2017-11-03 17:54:43,455 INFO : train_loss                0.61007\n",
      "2017-11-03 17:54:43,456 INFO : valid_loss                1.22956\n",
      "2017-11-03 17:54:43,456 INFO : test_loss                 1.40305\n",
      "2017-11-03 17:54:43,457 INFO : train_sample_misclass     0.22529\n",
      "2017-11-03 17:54:43,458 INFO : valid_sample_misclass     0.43356\n",
      "2017-11-03 17:54:43,459 INFO : test_sample_misclass      0.48479\n",
      "2017-11-03 17:54:43,459 INFO : train_misclass            0.19849\n",
      "2017-11-03 17:54:43,460 INFO : valid_misclass            0.43434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:54:43,461 INFO : test_misclass             0.46497\n",
      "2017-11-03 17:54:43,462 INFO : runtime                   1.57837\n",
      "2017-11-03 17:54:43,462 INFO : \n",
      "2017-11-03 17:54:44,271 INFO : Time only for training updates: 0.71s\n",
      "2017-11-03 17:54:45,020 INFO : Epoch 10\n",
      "2017-11-03 17:54:45,021 INFO : train_loss                0.64797\n",
      "2017-11-03 17:54:45,022 INFO : valid_loss                1.28604\n",
      "2017-11-03 17:54:45,023 INFO : test_loss                 1.41996\n",
      "2017-11-03 17:54:45,023 INFO : train_sample_misclass     0.24798\n",
      "2017-11-03 17:54:45,024 INFO : valid_sample_misclass     0.44050\n",
      "2017-11-03 17:54:45,025 INFO : test_sample_misclass      0.47793\n",
      "2017-11-03 17:54:45,026 INFO : train_misclass            0.23869\n",
      "2017-11-03 17:54:45,027 INFO : valid_misclass            0.41414\n",
      "2017-11-03 17:54:45,027 INFO : test_misclass             0.44904\n",
      "2017-11-03 17:54:45,028 INFO : runtime                   1.56668\n",
      "2017-11-03 17:54:45,029 INFO : \n",
      "2017-11-03 17:54:45,847 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:46,639 INFO : Epoch 11\n",
      "2017-11-03 17:54:46,640 INFO : train_loss                0.60028\n",
      "2017-11-03 17:54:46,641 INFO : valid_loss                1.19866\n",
      "2017-11-03 17:54:46,642 INFO : test_loss                 1.51705\n",
      "2017-11-03 17:54:46,642 INFO : train_sample_misclass     0.22617\n",
      "2017-11-03 17:54:46,643 INFO : valid_sample_misclass     0.43046\n",
      "2017-11-03 17:54:46,644 INFO : test_sample_misclass      0.50496\n",
      "2017-11-03 17:54:46,645 INFO : train_misclass            0.18593\n",
      "2017-11-03 17:54:46,646 INFO : valid_misclass            0.34343\n",
      "2017-11-03 17:54:46,646 INFO : test_misclass             0.47134\n",
      "2017-11-03 17:54:46,647 INFO : runtime                   1.57587\n",
      "2017-11-03 17:54:46,648 INFO : \n",
      "2017-11-03 17:54:46,650 INFO : New best valid_misclass: 0.343434\n",
      "2017-11-03 17:54:46,651 INFO : \n",
      "2017-11-03 17:54:47,467 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:48,218 INFO : Epoch 12\n",
      "2017-11-03 17:54:48,219 INFO : train_loss                0.57952\n",
      "2017-11-03 17:54:48,220 INFO : valid_loss                1.23002\n",
      "2017-11-03 17:54:48,221 INFO : test_loss                 1.39561\n",
      "2017-11-03 17:54:48,222 INFO : train_sample_misclass     0.21030\n",
      "2017-11-03 17:54:48,222 INFO : valid_sample_misclass     0.42522\n",
      "2017-11-03 17:54:48,223 INFO : test_sample_misclass      0.45922\n",
      "2017-11-03 17:54:48,224 INFO : train_misclass            0.17337\n",
      "2017-11-03 17:54:48,225 INFO : valid_misclass            0.39394\n",
      "2017-11-03 17:54:48,225 INFO : test_misclass             0.42038\n",
      "2017-11-03 17:54:48,226 INFO : runtime                   1.61997\n",
      "2017-11-03 17:54:48,227 INFO : \n",
      "2017-11-03 17:54:49,066 INFO : Time only for training updates: 0.74s\n",
      "2017-11-03 17:54:49,828 INFO : Epoch 13\n",
      "2017-11-03 17:54:49,829 INFO : train_loss                0.56454\n",
      "2017-11-03 17:54:49,830 INFO : valid_loss                1.30951\n",
      "2017-11-03 17:54:49,831 INFO : test_loss                 1.35587\n",
      "2017-11-03 17:54:49,832 INFO : train_sample_misclass     0.20067\n",
      "2017-11-03 17:54:49,833 INFO : valid_sample_misclass     0.43243\n",
      "2017-11-03 17:54:49,833 INFO : test_sample_misclass      0.45508\n",
      "2017-11-03 17:54:49,834 INFO : train_misclass            0.17839\n",
      "2017-11-03 17:54:49,835 INFO : valid_misclass            0.40404\n",
      "2017-11-03 17:54:49,836 INFO : test_misclass             0.41083\n",
      "2017-11-03 17:54:49,836 INFO : runtime                   1.59916\n",
      "2017-11-03 17:54:49,837 INFO : \n",
      "2017-11-03 17:54:50,655 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:51,412 INFO : Epoch 14\n",
      "2017-11-03 17:54:51,413 INFO : train_loss                0.62104\n",
      "2017-11-03 17:54:51,414 INFO : valid_loss                1.40254\n",
      "2017-11-03 17:54:51,415 INFO : test_loss                 1.41643\n",
      "2017-11-03 17:54:51,415 INFO : train_sample_misclass     0.23836\n",
      "2017-11-03 17:54:51,416 INFO : valid_sample_misclass     0.45438\n",
      "2017-11-03 17:54:51,417 INFO : test_sample_misclass      0.46678\n",
      "2017-11-03 17:54:51,418 INFO : train_misclass            0.23367\n",
      "2017-11-03 17:54:51,419 INFO : valid_misclass            0.39394\n",
      "2017-11-03 17:54:51,419 INFO : test_misclass             0.39172\n",
      "2017-11-03 17:54:51,420 INFO : runtime                   1.58891\n",
      "2017-11-03 17:54:51,421 INFO : \n",
      "2017-11-03 17:54:52,235 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:53,001 INFO : Epoch 15\n",
      "2017-11-03 17:54:53,002 INFO : train_loss                0.55985\n",
      "2017-11-03 17:54:53,003 INFO : valid_loss                1.38133\n",
      "2017-11-03 17:54:53,004 INFO : test_loss                 1.49168\n",
      "2017-11-03 17:54:53,005 INFO : train_sample_misclass     0.19814\n",
      "2017-11-03 17:54:53,006 INFO : valid_sample_misclass     0.44258\n",
      "2017-11-03 17:54:53,006 INFO : test_sample_misclass      0.47665\n",
      "2017-11-03 17:54:53,007 INFO : train_misclass            0.16332\n",
      "2017-11-03 17:54:53,008 INFO : valid_misclass            0.43434\n",
      "2017-11-03 17:54:53,009 INFO : test_misclass             0.43312\n",
      "2017-11-03 17:54:53,009 INFO : runtime                   1.57987\n",
      "2017-11-03 17:54:53,010 INFO : \n",
      "2017-11-03 17:54:53,824 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:54,592 INFO : Epoch 16\n",
      "2017-11-03 17:54:54,593 INFO : train_loss                0.52848\n",
      "2017-11-03 17:54:54,594 INFO : valid_loss                1.33559\n",
      "2017-11-03 17:54:54,595 INFO : test_loss                 1.51660\n",
      "2017-11-03 17:54:54,596 INFO : train_sample_misclass     0.18632\n",
      "2017-11-03 17:54:54,596 INFO : valid_sample_misclass     0.46433\n",
      "2017-11-03 17:54:54,597 INFO : test_sample_misclass      0.48484\n",
      "2017-11-03 17:54:54,598 INFO : train_misclass            0.15578\n",
      "2017-11-03 17:54:54,599 INFO : valid_misclass            0.42424\n",
      "2017-11-03 17:54:54,599 INFO : test_misclass             0.43949\n",
      "2017-11-03 17:54:54,600 INFO : runtime                   1.58907\n",
      "2017-11-03 17:54:54,601 INFO : \n",
      "2017-11-03 17:54:55,417 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:56,169 INFO : Epoch 17\n",
      "2017-11-03 17:54:56,171 INFO : train_loss                0.53104\n",
      "2017-11-03 17:54:56,171 INFO : valid_loss                1.27837\n",
      "2017-11-03 17:54:56,172 INFO : test_loss                 1.56129\n",
      "2017-11-03 17:54:56,173 INFO : train_sample_misclass     0.19424\n",
      "2017-11-03 17:54:56,174 INFO : valid_sample_misclass     0.43299\n",
      "2017-11-03 17:54:56,175 INFO : test_sample_misclass      0.48812\n",
      "2017-11-03 17:54:56,175 INFO : train_misclass            0.16583\n",
      "2017-11-03 17:54:56,176 INFO : valid_misclass            0.39394\n",
      "2017-11-03 17:54:56,177 INFO : test_misclass             0.44904\n",
      "2017-11-03 17:54:56,178 INFO : runtime                   1.59308\n",
      "2017-11-03 17:54:56,178 INFO : \n",
      "2017-11-03 17:54:56,988 INFO : Time only for training updates: 0.71s\n",
      "2017-11-03 17:54:57,764 INFO : Epoch 18\n",
      "2017-11-03 17:54:57,766 INFO : train_loss                0.52136\n",
      "2017-11-03 17:54:57,767 INFO : valid_loss                1.35125\n",
      "2017-11-03 17:54:57,767 INFO : test_loss                 1.46087\n",
      "2017-11-03 17:54:57,768 INFO : train_sample_misclass     0.18336\n",
      "2017-11-03 17:54:57,769 INFO : valid_sample_misclass     0.44739\n",
      "2017-11-03 17:54:57,770 INFO : test_sample_misclass      0.48096\n",
      "2017-11-03 17:54:57,770 INFO : train_misclass            0.16332\n",
      "2017-11-03 17:54:57,771 INFO : valid_misclass            0.39394\n",
      "2017-11-03 17:54:57,772 INFO : test_misclass             0.42675\n",
      "2017-11-03 17:54:57,773 INFO : runtime                   1.57133\n",
      "2017-11-03 17:54:57,774 INFO : \n",
      "2017-11-03 17:54:58,595 INFO : Time only for training updates: 0.72s\n",
      "2017-11-03 17:54:59,356 INFO : Epoch 19\n",
      "2017-11-03 17:54:59,357 INFO : train_loss                0.52737\n",
      "2017-11-03 17:54:59,358 INFO : valid_loss                1.33823\n",
      "2017-11-03 17:54:59,359 INFO : test_loss                 1.56256\n",
      "2017-11-03 17:54:59,360 INFO : train_sample_misclass     0.19466\n",
      "2017-11-03 17:54:59,360 INFO : valid_sample_misclass     0.44720\n",
      "2017-11-03 17:54:59,361 INFO : test_sample_misclass      0.47450\n",
      "2017-11-03 17:54:59,362 INFO : train_misclass            0.15578\n",
      "2017-11-03 17:54:59,363 INFO : valid_misclass            0.42424\n",
      "2017-11-03 17:54:59,364 INFO : test_misclass             0.42675\n",
      "2017-11-03 17:54:59,364 INFO : runtime                   1.60626\n",
      "2017-11-03 17:54:59,365 INFO : \n",
      "2017-11-03 17:55:00,184 INFO : Time only for training updates: 0.72s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:55:00,944 INFO : Epoch 20\n",
      "2017-11-03 17:55:00,945 INFO : train_loss                0.50380\n",
      "2017-11-03 17:55:00,946 INFO : valid_loss                1.28838\n",
      "2017-11-03 17:55:00,947 INFO : test_loss                 1.54519\n",
      "2017-11-03 17:55:00,947 INFO : train_sample_misclass     0.17429\n",
      "2017-11-03 17:55:00,948 INFO : valid_sample_misclass     0.43744\n",
      "2017-11-03 17:55:00,949 INFO : test_sample_misclass      0.48286\n",
      "2017-11-03 17:55:00,950 INFO : train_misclass            0.17085\n",
      "2017-11-03 17:55:00,950 INFO : valid_misclass            0.38384\n",
      "2017-11-03 17:55:00,951 INFO : test_misclass             0.42994\n",
      "2017-11-03 17:55:00,952 INFO : runtime                   1.58936\n",
      "2017-11-03 17:55:00,953 INFO : \n",
      "2017-11-03 17:55:00,954 INFO : Setup for second stop...\n",
      "2017-11-03 17:55:00,957 INFO : Train loss to reach 0.60028\n",
      "2017-11-03 17:55:00,958 INFO : Run until second stop...\n",
      "2017-11-03 17:55:01,805 INFO : Epoch 12\n",
      "2017-11-03 17:55:01,806 INFO : train_loss                0.71588\n",
      "2017-11-03 17:55:01,807 INFO : valid_loss                1.19866\n",
      "2017-11-03 17:55:01,808 INFO : test_loss                 1.51705\n",
      "2017-11-03 17:55:01,808 INFO : train_sample_misclass     0.26564\n",
      "2017-11-03 17:55:01,809 INFO : valid_sample_misclass     0.43046\n",
      "2017-11-03 17:55:01,810 INFO : test_sample_misclass      0.50496\n",
      "2017-11-03 17:55:01,811 INFO : train_misclass            0.21730\n",
      "2017-11-03 17:55:01,812 INFO : valid_misclass            0.34343\n",
      "2017-11-03 17:55:01,812 INFO : test_misclass             0.47134\n",
      "2017-11-03 17:55:01,813 INFO : runtime                   0.77324\n",
      "2017-11-03 17:55:01,814 INFO : \n",
      "2017-11-03 17:55:02,820 INFO : Time only for training updates: 0.89s\n",
      "2017-11-03 17:55:03,681 INFO : Epoch 13\n",
      "2017-11-03 17:55:03,683 INFO : train_loss                0.71408\n",
      "2017-11-03 17:55:03,684 INFO : valid_loss                1.02489\n",
      "2017-11-03 17:55:03,684 INFO : test_loss                 1.36414\n",
      "2017-11-03 17:55:03,685 INFO : train_sample_misclass     0.26404\n",
      "2017-11-03 17:55:03,686 INFO : valid_sample_misclass     0.38184\n",
      "2017-11-03 17:55:03,687 INFO : test_sample_misclass      0.47608\n",
      "2017-11-03 17:55:03,688 INFO : train_misclass            0.21328\n",
      "2017-11-03 17:55:03,688 INFO : valid_misclass            0.35354\n",
      "2017-11-03 17:55:03,689 INFO : test_misclass             0.42357\n",
      "2017-11-03 17:55:03,690 INFO : runtime                   1.86268\n",
      "2017-11-03 17:55:03,691 INFO : \n",
      "2017-11-03 17:55:04,693 INFO : Time only for training updates: 0.88s\n",
      "2017-11-03 17:55:05,529 INFO : Epoch 14\n",
      "2017-11-03 17:55:05,531 INFO : train_loss                0.68211\n",
      "2017-11-03 17:55:05,532 INFO : valid_loss                0.92467\n",
      "2017-11-03 17:55:05,532 INFO : test_loss                 1.41786\n",
      "2017-11-03 17:55:05,533 INFO : train_sample_misclass     0.25519\n",
      "2017-11-03 17:55:05,534 INFO : valid_sample_misclass     0.34189\n",
      "2017-11-03 17:55:05,535 INFO : test_sample_misclass      0.48768\n",
      "2017-11-03 17:55:05,536 INFO : train_misclass            0.22133\n",
      "2017-11-03 17:55:05,537 INFO : valid_misclass            0.28283\n",
      "2017-11-03 17:55:05,539 INFO : test_misclass             0.45860\n",
      "2017-11-03 17:55:05,540 INFO : runtime                   1.87288\n",
      "2017-11-03 17:55:05,541 INFO : \n",
      "2017-11-03 17:55:06,539 INFO : Time only for training updates: 0.88s\n",
      "2017-11-03 17:55:07,379 INFO : Epoch 15\n",
      "2017-11-03 17:55:07,381 INFO : train_loss                0.65594\n",
      "2017-11-03 17:55:07,382 INFO : valid_loss                0.87031\n",
      "2017-11-03 17:55:07,383 INFO : test_loss                 1.45573\n",
      "2017-11-03 17:55:07,385 INFO : train_sample_misclass     0.23964\n",
      "2017-11-03 17:55:07,386 INFO : valid_sample_misclass     0.33582\n",
      "2017-11-03 17:55:07,387 INFO : test_sample_misclass      0.49530\n",
      "2017-11-03 17:55:07,388 INFO : train_misclass            0.22938\n",
      "2017-11-03 17:55:07,389 INFO : valid_misclass            0.33333\n",
      "2017-11-03 17:55:07,390 INFO : test_misclass             0.50637\n",
      "2017-11-03 17:55:07,392 INFO : runtime                   1.84665\n",
      "2017-11-03 17:55:07,393 INFO : \n",
      "2017-11-03 17:55:08,391 INFO : Time only for training updates: 0.88s\n",
      "2017-11-03 17:55:09,225 INFO : Epoch 16\n",
      "2017-11-03 17:55:09,227 INFO : train_loss                0.67155\n",
      "2017-11-03 17:55:09,228 INFO : valid_loss                0.88822\n",
      "2017-11-03 17:55:09,229 INFO : test_loss                 1.46725\n",
      "2017-11-03 17:55:09,231 INFO : train_sample_misclass     0.25023\n",
      "2017-11-03 17:55:09,232 INFO : valid_sample_misclass     0.35430\n",
      "2017-11-03 17:55:09,233 INFO : test_sample_misclass      0.51942\n",
      "2017-11-03 17:55:09,234 INFO : train_misclass            0.22736\n",
      "2017-11-03 17:55:09,235 INFO : valid_misclass            0.30303\n",
      "2017-11-03 17:55:09,237 INFO : test_misclass             0.47134\n",
      "2017-11-03 17:55:09,238 INFO : runtime                   1.85138\n",
      "2017-11-03 17:55:09,239 INFO : \n",
      "2017-11-03 17:55:10,282 INFO : Time only for training updates: 0.92s\n",
      "2017-11-03 17:55:11,169 INFO : Epoch 17\n",
      "2017-11-03 17:55:11,171 INFO : train_loss                0.65888\n",
      "2017-11-03 17:55:11,172 INFO : valid_loss                0.85140\n",
      "2017-11-03 17:55:11,174 INFO : test_loss                 1.38991\n",
      "2017-11-03 17:55:11,175 INFO : train_sample_misclass     0.24352\n",
      "2017-11-03 17:55:11,176 INFO : valid_sample_misclass     0.32228\n",
      "2017-11-03 17:55:11,177 INFO : test_sample_misclass      0.47197\n",
      "2017-11-03 17:55:11,179 INFO : train_misclass            0.23139\n",
      "2017-11-03 17:55:11,180 INFO : valid_misclass            0.28283\n",
      "2017-11-03 17:55:11,181 INFO : test_misclass             0.44904\n",
      "2017-11-03 17:55:11,182 INFO : runtime                   1.89099\n",
      "2017-11-03 17:55:11,183 INFO : \n",
      "2017-11-03 17:55:12,185 INFO : Time only for training updates: 0.88s\n",
      "2017-11-03 17:55:13,031 INFO : Epoch 18\n",
      "2017-11-03 17:55:13,033 INFO : train_loss                0.60783\n",
      "2017-11-03 17:55:13,034 INFO : valid_loss                0.75969\n",
      "2017-11-03 17:55:13,035 INFO : test_loss                 1.40295\n",
      "2017-11-03 17:55:13,037 INFO : train_sample_misclass     0.22382\n",
      "2017-11-03 17:55:13,038 INFO : valid_sample_misclass     0.29660\n",
      "2017-11-03 17:55:13,039 INFO : test_sample_misclass      0.48256\n",
      "2017-11-03 17:55:13,040 INFO : train_misclass            0.18511\n",
      "2017-11-03 17:55:13,042 INFO : valid_misclass            0.27273\n",
      "2017-11-03 17:55:13,043 INFO : test_misclass             0.45860\n",
      "2017-11-03 17:55:13,044 INFO : runtime                   1.90315\n",
      "2017-11-03 17:55:13,045 INFO : \n",
      "2017-11-03 17:55:14,056 INFO : Time only for training updates: 0.89s\n",
      "2017-11-03 17:55:14,953 INFO : Epoch 19\n",
      "2017-11-03 17:55:14,956 INFO : train_loss                0.61093\n",
      "2017-11-03 17:55:14,959 INFO : valid_loss                0.78444\n",
      "2017-11-03 17:55:14,960 INFO : test_loss                 1.37623\n",
      "2017-11-03 17:55:14,963 INFO : train_sample_misclass     0.22366\n",
      "2017-11-03 17:55:14,965 INFO : valid_sample_misclass     0.30558\n",
      "2017-11-03 17:55:14,966 INFO : test_sample_misclass      0.47023\n",
      "2017-11-03 17:55:14,969 INFO : train_misclass            0.18712\n",
      "2017-11-03 17:55:14,970 INFO : valid_misclass            0.24242\n",
      "2017-11-03 17:55:14,973 INFO : test_misclass             0.43312\n",
      "2017-11-03 17:55:14,975 INFO : runtime                   1.87216\n",
      "2017-11-03 17:55:14,977 INFO : \n",
      "2017-11-03 17:55:15,992 INFO : Time only for training updates: 0.89s\n",
      "2017-11-03 17:55:16,858 INFO : Epoch 20\n",
      "2017-11-03 17:55:16,860 INFO : train_loss                0.59346\n",
      "2017-11-03 17:55:16,861 INFO : valid_loss                0.71784\n",
      "2017-11-03 17:55:16,861 INFO : test_loss                 1.45776\n",
      "2017-11-03 17:55:16,862 INFO : train_sample_misclass     0.21111\n",
      "2017-11-03 17:55:16,863 INFO : valid_sample_misclass     0.26341\n",
      "2017-11-03 17:55:16,864 INFO : test_sample_misclass      0.49474\n",
      "2017-11-03 17:55:16,865 INFO : train_misclass            0.20322\n",
      "2017-11-03 17:55:16,865 INFO : valid_misclass            0.27273\n",
      "2017-11-03 17:55:16,866 INFO : test_misclass             0.46815\n",
      "2017-11-03 17:55:16,867 INFO : runtime                   1.93566\n",
      "2017-11-03 17:55:16,868 INFO : \n",
      "2017-11-03 17:55:17,876 INFO : Time only for training updates: 0.89s\n",
      "2017-11-03 17:55:18,753 INFO : Epoch 21\n",
      "2017-11-03 17:55:18,755 INFO : train_loss                0.60215\n",
      "2017-11-03 17:55:18,756 INFO : valid_loss                0.75351\n",
      "2017-11-03 17:55:18,756 INFO : test_loss                 1.50636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-03 17:55:18,757 INFO : train_sample_misclass     0.21574\n",
      "2017-11-03 17:55:18,758 INFO : valid_sample_misclass     0.28888\n",
      "2017-11-03 17:55:18,759 INFO : test_sample_misclass      0.51284\n",
      "2017-11-03 17:55:18,760 INFO : train_misclass            0.19517\n",
      "2017-11-03 17:55:18,760 INFO : valid_misclass            0.28283\n",
      "2017-11-03 17:55:18,761 INFO : test_misclass             0.48089\n",
      "2017-11-03 17:55:18,762 INFO : runtime                   1.88302\n",
      "2017-11-03 17:55:18,763 INFO : \n",
      "2017-11-03 17:55:19,771 INFO : Time only for training updates: 0.89s\n",
      "2017-11-03 17:55:20,627 INFO : Epoch 22\n",
      "2017-11-03 17:55:20,628 INFO : train_loss                0.65365\n",
      "2017-11-03 17:55:20,629 INFO : valid_loss                0.82897\n",
      "2017-11-03 17:55:20,629 INFO : test_loss                 1.40076\n",
      "2017-11-03 17:55:20,630 INFO : train_sample_misclass     0.25455\n",
      "2017-11-03 17:55:20,631 INFO : valid_sample_misclass     0.33560\n",
      "2017-11-03 17:55:20,632 INFO : test_sample_misclass      0.48546\n",
      "2017-11-03 17:55:20,632 INFO : train_misclass            0.24145\n",
      "2017-11-03 17:55:20,633 INFO : valid_misclass            0.30303\n",
      "2017-11-03 17:55:20,634 INFO : test_misclass             0.46178\n",
      "2017-11-03 17:55:20,635 INFO : runtime                   1.89486\n",
      "2017-11-03 17:55:20,636 INFO : \n"
     ]
    }
   ],
   "source": [
    "exp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We arrive at about 54% accuracy. With only 3 sensors and 3 training runs, we cannot get much better :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
