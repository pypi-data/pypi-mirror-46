{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trialwise Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use a convolutional neural network on the [Physiobank EEG Motor Movement/Imagery Dataset](https://www.physionet.org/physiobank/database/eegmmidb/) to decode two classes:\n",
    "\n",
    "1. Executed and imagined opening and closing of both hands\n",
    "2. Executed and imagined opening and closing of both feet\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "We use only one subject (with 90 trials) in this tutorial for demonstration purposes. A more interesting decoding task with many more trials would be to do cross-subject decoding on the same dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load and preprocess your EEG dataset in any way, Braindecode only expects a 3darray (trials, channels, timesteps) of input signals `X` and a vector of labels `y` later (see below). In this tutorial, we will use the [MNE](https://www.martinos.org/mne/stable/index.html) library to load an EEG motor imagery/motor execution dataset. For a tutorial from MNE using Common Spatial Patterns to decode this data, see [here](http://martinos.org/mne/stable/auto_examples/decoding/plot_decoding_csp_eeg.html). For another library useful for loading EEG data, take a look at [Neo IO](https://pythonhosted.org/neo/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 22 # carefully cherry-picked to give nice results on such limited data :)\n",
    "event_codes = [5,6,9,10,13,14]\n",
    "#event_codes = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto', verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands_or_left=2, feet_or_right=3), tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to Braindecode format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braindecode has a minimalistic ```SignalAndTarget``` class, with attributes `X` for the signal and `y` for the labels. `X` should have these dimensions: trials x channels x timesteps. `y` should have one label per trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 40 trials for training and the next 30 trials for validation. The validation accuracies can be used to tune hyperparameters such as learning rate etc. The final 20 trials are split apart so we have a final hold-out evaluation set that is not part of any hyperparameter optimization. As mentioned before, this dataset is dangerously small to get any meaningful results and only used here for quick demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "train_set = SignalAndTarget(X[:40], y=y[:40])\n",
    "valid_set = SignalAndTarget(X[40:70], y=y[40:70])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braindecode comes with some predefined convolutional neural network architectures for raw time-domain EEG. Here, we use the shallow ConvNet model from [Deep learning with convolutional neural networks for EEG decoding and visualization](https://arxiv.org/abs/1703.05051)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=train_set.X.shape[2],\n",
    "                        final_conv_length='auto')\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [AdamW](https://arxiv.org/abs/1711.05101) to optimize the parameters of our network together with [Cosine Annealing](https://arxiv.org/abs/1608.03983) of the learning rate. We supply some default parameters that we have found to work well for motor decoding, however we strongly encourage you to perform your own hyperparameter optimization using cross validation on your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "We will now use the Braindecode model class directly to perform the training in a few lines of code. If you instead want to use your own training loop, have a look at the [Trialwise Low-Level Tutorial](./TrialWise_LowLevel.html).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-06 18:42:33,667 INFO : Run until first stop...\n",
      "2019-05-06 18:42:34,374 INFO : Epoch 0\n",
      "2019-05-06 18:42:34,377 INFO : train_loss                5.34665\n",
      "2019-05-06 18:42:34,379 INFO : valid_loss                5.13145\n",
      "2019-05-06 18:42:34,381 INFO : train_misclass            0.47500\n",
      "2019-05-06 18:42:34,383 INFO : valid_misclass            0.46667\n",
      "2019-05-06 18:42:34,385 INFO : runtime                   0.00000\n",
      "2019-05-06 18:42:34,388 INFO : \n",
      "2019-05-06 18:42:35,177 INFO : Time only for training updates: 0.79s\n",
      "2019-05-06 18:42:35,805 INFO : Epoch 1\n",
      "2019-05-06 18:42:35,808 INFO : train_loss                1.18747\n",
      "2019-05-06 18:42:35,810 INFO : valid_loss                1.44545\n",
      "2019-05-06 18:42:35,811 INFO : train_misclass            0.45000\n",
      "2019-05-06 18:42:35,813 INFO : valid_misclass            0.53333\n",
      "2019-05-06 18:42:35,815 INFO : runtime                   1.50794\n",
      "2019-05-06 18:42:35,816 INFO : \n",
      "2019-05-06 18:42:36,564 INFO : Time only for training updates: 0.75s\n",
      "2019-05-06 18:42:37,222 INFO : Epoch 2\n",
      "2019-05-06 18:42:37,224 INFO : train_loss                0.97474\n",
      "2019-05-06 18:42:37,226 INFO : valid_loss                1.21793\n",
      "2019-05-06 18:42:37,228 INFO : train_misclass            0.40000\n",
      "2019-05-06 18:42:37,229 INFO : valid_misclass            0.50000\n",
      "2019-05-06 18:42:37,231 INFO : runtime                   1.38697\n",
      "2019-05-06 18:42:37,233 INFO : \n",
      "2019-05-06 18:42:37,979 INFO : Time only for training updates: 0.75s\n",
      "2019-05-06 18:42:38,606 INFO : Epoch 3\n",
      "2019-05-06 18:42:38,608 INFO : train_loss                0.67758\n",
      "2019-05-06 18:42:38,610 INFO : valid_loss                0.90153\n",
      "2019-05-06 18:42:38,612 INFO : train_misclass            0.30000\n",
      "2019-05-06 18:42:38,613 INFO : valid_misclass            0.40000\n",
      "2019-05-06 18:42:38,615 INFO : runtime                   1.41578\n",
      "2019-05-06 18:42:38,616 INFO : \n",
      "2019-05-06 18:42:39,378 INFO : Time only for training updates: 0.76s\n",
      "2019-05-06 18:42:40,084 INFO : Epoch 4\n",
      "2019-05-06 18:42:40,087 INFO : train_loss                0.44458\n",
      "2019-05-06 18:42:40,088 INFO : valid_loss                0.67693\n",
      "2019-05-06 18:42:40,090 INFO : train_misclass            0.27500\n",
      "2019-05-06 18:42:40,091 INFO : valid_misclass            0.30000\n",
      "2019-05-06 18:42:40,093 INFO : runtime                   1.39690\n",
      "2019-05-06 18:42:40,095 INFO : \n",
      "2019-05-06 18:42:40,840 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:42:41,484 INFO : Epoch 5\n",
      "2019-05-06 18:42:41,487 INFO : train_loss                0.29853\n",
      "2019-05-06 18:42:41,488 INFO : valid_loss                0.55172\n",
      "2019-05-06 18:42:41,490 INFO : train_misclass            0.20000\n",
      "2019-05-06 18:42:41,491 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:41,493 INFO : runtime                   1.46328\n",
      "2019-05-06 18:42:41,495 INFO : \n",
      "2019-05-06 18:42:42,221 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:42:42,869 INFO : Epoch 6\n",
      "2019-05-06 18:42:42,872 INFO : train_loss                0.21160\n",
      "2019-05-06 18:42:42,874 INFO : valid_loss                0.50792\n",
      "2019-05-06 18:42:42,876 INFO : train_misclass            0.10000\n",
      "2019-05-06 18:42:42,877 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:42:42,879 INFO : runtime                   1.38157\n",
      "2019-05-06 18:42:42,880 INFO : \n",
      "2019-05-06 18:42:43,618 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:42:44,268 INFO : Epoch 7\n",
      "2019-05-06 18:42:44,270 INFO : train_loss                0.13291\n",
      "2019-05-06 18:42:44,272 INFO : valid_loss                0.46993\n",
      "2019-05-06 18:42:44,273 INFO : train_misclass            0.05000\n",
      "2019-05-06 18:42:44,275 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:42:44,277 INFO : runtime                   1.39710\n",
      "2019-05-06 18:42:44,278 INFO : \n",
      "2019-05-06 18:42:45,013 INFO : Time only for training updates: 0.73s\n",
      "2019-05-06 18:42:45,655 INFO : Epoch 8\n",
      "2019-05-06 18:42:45,658 INFO : train_loss                0.09791\n",
      "2019-05-06 18:42:45,659 INFO : valid_loss                0.45241\n",
      "2019-05-06 18:42:45,661 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:45,663 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:42:45,664 INFO : runtime                   1.39461\n",
      "2019-05-06 18:42:45,666 INFO : \n",
      "2019-05-06 18:42:46,435 INFO : Time only for training updates: 0.77s\n",
      "2019-05-06 18:42:47,119 INFO : Epoch 9\n",
      "2019-05-06 18:42:47,121 INFO : train_loss                0.07745\n",
      "2019-05-06 18:42:47,123 INFO : valid_loss                0.45302\n",
      "2019-05-06 18:42:47,125 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:47,126 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:47,128 INFO : runtime                   1.42410\n",
      "2019-05-06 18:42:47,130 INFO : \n",
      "2019-05-06 18:42:47,857 INFO : Time only for training updates: 0.73s\n",
      "2019-05-06 18:42:48,485 INFO : Epoch 10\n",
      "2019-05-06 18:42:48,487 INFO : train_loss                0.06647\n",
      "2019-05-06 18:42:48,489 INFO : valid_loss                0.45930\n",
      "2019-05-06 18:42:48,490 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:48,492 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:48,494 INFO : runtime                   1.41996\n",
      "2019-05-06 18:42:48,495 INFO : \n",
      "2019-05-06 18:42:49,252 INFO : Time only for training updates: 0.76s\n",
      "2019-05-06 18:42:49,883 INFO : Epoch 11\n",
      "2019-05-06 18:42:49,885 INFO : train_loss                0.05948\n",
      "2019-05-06 18:42:49,887 INFO : valid_loss                0.47226\n",
      "2019-05-06 18:42:49,888 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:49,890 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:49,891 INFO : runtime                   1.39512\n",
      "2019-05-06 18:42:49,893 INFO : \n",
      "2019-05-06 18:42:50,655 INFO : Time only for training updates: 0.76s\n",
      "2019-05-06 18:42:51,264 INFO : Epoch 12\n",
      "2019-05-06 18:42:51,267 INFO : train_loss                0.05326\n",
      "2019-05-06 18:42:51,269 INFO : valid_loss                0.48800\n",
      "2019-05-06 18:42:51,270 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:51,272 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:51,273 INFO : runtime                   1.40249\n",
      "2019-05-06 18:42:51,275 INFO : \n",
      "2019-05-06 18:42:52,007 INFO : Time only for training updates: 0.73s\n",
      "2019-05-06 18:42:52,638 INFO : Epoch 13\n",
      "2019-05-06 18:42:52,640 INFO : train_loss                0.04709\n",
      "2019-05-06 18:42:52,642 INFO : valid_loss                0.50408\n",
      "2019-05-06 18:42:52,644 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:52,645 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:52,647 INFO : runtime                   1.35249\n",
      "2019-05-06 18:42:52,648 INFO : \n",
      "2019-05-06 18:42:53,368 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:42:54,046 INFO : Epoch 14\n",
      "2019-05-06 18:42:54,048 INFO : train_loss                0.04247\n",
      "2019-05-06 18:42:54,050 INFO : valid_loss                0.50821\n",
      "2019-05-06 18:42:54,052 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:54,053 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:54,055 INFO : runtime                   1.36095\n",
      "2019-05-06 18:42:54,057 INFO : \n",
      "2019-05-06 18:42:54,803 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:42:55,433 INFO : Epoch 15\n",
      "2019-05-06 18:42:55,435 INFO : train_loss                0.03919\n",
      "2019-05-06 18:42:55,437 INFO : valid_loss                0.51205\n",
      "2019-05-06 18:42:55,439 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:55,440 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:55,442 INFO : runtime                   1.43444\n",
      "2019-05-06 18:42:55,443 INFO : \n",
      "2019-05-06 18:42:56,212 INFO : Time only for training updates: 0.77s\n",
      "2019-05-06 18:42:56,836 INFO : Epoch 16\n",
      "2019-05-06 18:42:56,839 INFO : train_loss                0.03620\n",
      "2019-05-06 18:42:56,841 INFO : valid_loss                0.51271\n",
      "2019-05-06 18:42:56,842 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:56,844 INFO : valid_misclass            0.20000\n",
      "2019-05-06 18:42:56,845 INFO : runtime                   1.40935\n",
      "2019-05-06 18:42:56,847 INFO : \n",
      "2019-05-06 18:42:57,572 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:42:58,206 INFO : Epoch 17\n",
      "2019-05-06 18:42:58,208 INFO : train_loss                0.03297\n",
      "2019-05-06 18:42:58,210 INFO : valid_loss                0.50702\n",
      "2019-05-06 18:42:58,212 INFO : train_misclass            0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-06 18:42:58,213 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:42:58,215 INFO : runtime                   1.35937\n",
      "2019-05-06 18:42:58,216 INFO : \n",
      "2019-05-06 18:42:58,945 INFO : Time only for training updates: 0.73s\n",
      "2019-05-06 18:42:59,587 INFO : Epoch 18\n",
      "2019-05-06 18:42:59,589 INFO : train_loss                0.03033\n",
      "2019-05-06 18:42:59,591 INFO : valid_loss                0.50634\n",
      "2019-05-06 18:42:59,593 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:42:59,594 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:42:59,596 INFO : runtime                   1.37295\n",
      "2019-05-06 18:42:59,597 INFO : \n",
      "2019-05-06 18:43:00,321 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:43:00,967 INFO : Epoch 19\n",
      "2019-05-06 18:43:00,970 INFO : train_loss                0.02815\n",
      "2019-05-06 18:43:00,972 INFO : valid_loss                0.50780\n",
      "2019-05-06 18:43:00,973 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:00,975 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:00,976 INFO : runtime                   1.37697\n",
      "2019-05-06 18:43:00,978 INFO : \n",
      "2019-05-06 18:43:01,698 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:43:02,338 INFO : Epoch 20\n",
      "2019-05-06 18:43:02,340 INFO : train_loss                0.02614\n",
      "2019-05-06 18:43:02,342 INFO : valid_loss                0.51158\n",
      "2019-05-06 18:43:02,344 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:02,345 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:02,347 INFO : runtime                   1.37624\n",
      "2019-05-06 18:43:02,348 INFO : \n",
      "2019-05-06 18:43:03,095 INFO : Time only for training updates: 0.75s\n",
      "2019-05-06 18:43:03,718 INFO : Epoch 21\n",
      "2019-05-06 18:43:03,720 INFO : train_loss                0.02446\n",
      "2019-05-06 18:43:03,722 INFO : valid_loss                0.51534\n",
      "2019-05-06 18:43:03,724 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:03,725 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:03,727 INFO : runtime                   1.39749\n",
      "2019-05-06 18:43:03,728 INFO : \n",
      "2019-05-06 18:43:04,468 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:43:05,095 INFO : Epoch 22\n",
      "2019-05-06 18:43:05,097 INFO : train_loss                0.02319\n",
      "2019-05-06 18:43:05,099 INFO : valid_loss                0.51802\n",
      "2019-05-06 18:43:05,101 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:05,102 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:05,104 INFO : runtime                   1.37266\n",
      "2019-05-06 18:43:05,106 INFO : \n",
      "2019-05-06 18:43:05,844 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:43:06,467 INFO : Epoch 23\n",
      "2019-05-06 18:43:06,469 INFO : train_loss                0.02210\n",
      "2019-05-06 18:43:06,471 INFO : valid_loss                0.52048\n",
      "2019-05-06 18:43:06,473 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:06,474 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:06,476 INFO : runtime                   1.37606\n",
      "2019-05-06 18:43:06,477 INFO : \n",
      "2019-05-06 18:43:07,227 INFO : Time only for training updates: 0.75s\n",
      "2019-05-06 18:43:07,847 INFO : Epoch 24\n",
      "2019-05-06 18:43:07,850 INFO : train_loss                0.02131\n",
      "2019-05-06 18:43:07,851 INFO : valid_loss                0.52309\n",
      "2019-05-06 18:43:07,853 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:07,855 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:07,856 INFO : runtime                   1.38342\n",
      "2019-05-06 18:43:07,858 INFO : \n",
      "2019-05-06 18:43:08,607 INFO : Time only for training updates: 0.75s\n",
      "2019-05-06 18:43:09,232 INFO : Epoch 25\n",
      "2019-05-06 18:43:09,235 INFO : train_loss                0.02070\n",
      "2019-05-06 18:43:09,236 INFO : valid_loss                0.52473\n",
      "2019-05-06 18:43:09,238 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:09,239 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:09,241 INFO : runtime                   1.37992\n",
      "2019-05-06 18:43:09,242 INFO : \n",
      "2019-05-06 18:43:09,982 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:43:10,609 INFO : Epoch 26\n",
      "2019-05-06 18:43:10,612 INFO : train_loss                0.02029\n",
      "2019-05-06 18:43:10,614 INFO : valid_loss                0.52578\n",
      "2019-05-06 18:43:10,615 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:10,617 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:10,618 INFO : runtime                   1.37474\n",
      "2019-05-06 18:43:10,620 INFO : \n",
      "2019-05-06 18:43:11,343 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:43:11,956 INFO : Epoch 27\n",
      "2019-05-06 18:43:11,959 INFO : train_loss                0.02002\n",
      "2019-05-06 18:43:11,961 INFO : valid_loss                0.52576\n",
      "2019-05-06 18:43:11,962 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:11,964 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:11,965 INFO : runtime                   1.36079\n",
      "2019-05-06 18:43:11,967 INFO : \n",
      "2019-05-06 18:43:12,704 INFO : Time only for training updates: 0.74s\n",
      "2019-05-06 18:43:13,354 INFO : Epoch 28\n",
      "2019-05-06 18:43:13,356 INFO : train_loss                0.01986\n",
      "2019-05-06 18:43:13,358 INFO : valid_loss                0.52516\n",
      "2019-05-06 18:43:13,359 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:13,361 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:13,362 INFO : runtime                   1.36182\n",
      "2019-05-06 18:43:13,364 INFO : \n",
      "2019-05-06 18:43:14,087 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:43:14,721 INFO : Epoch 29\n",
      "2019-05-06 18:43:14,723 INFO : train_loss                0.01978\n",
      "2019-05-06 18:43:14,725 INFO : valid_loss                0.52423\n",
      "2019-05-06 18:43:14,726 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:14,728 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:14,730 INFO : runtime                   1.38255\n",
      "2019-05-06 18:43:14,731 INFO : \n",
      "2019-05-06 18:43:15,454 INFO : Time only for training updates: 0.72s\n",
      "2019-05-06 18:43:16,097 INFO : Epoch 30\n",
      "2019-05-06 18:43:16,100 INFO : train_loss                0.01976\n",
      "2019-05-06 18:43:16,102 INFO : valid_loss                0.52316\n",
      "2019-05-06 18:43:16,103 INFO : train_misclass            0.00000\n",
      "2019-05-06 18:43:16,105 INFO : valid_misclass            0.16667\n",
      "2019-05-06 18:43:16,107 INFO : runtime                   1.36712\n",
      "2019-05-06 18:43:16,108 INFO : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.experiments.experiment.Experiment at 0x7f5535795320>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set.X, train_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(valid_set.X, valid_set.y),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monitored values are also stored into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_misclass</th>\n",
       "      <th>valid_misclass</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.346650</td>\n",
       "      <td>5.131454</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.187475</td>\n",
       "      <td>1.445455</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.507944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.974738</td>\n",
       "      <td>1.217930</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.386974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677581</td>\n",
       "      <td>0.901529</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.415777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444578</td>\n",
       "      <td>0.676926</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.396895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.298532</td>\n",
       "      <td>0.551718</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.463284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.211604</td>\n",
       "      <td>0.507916</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.381572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.132911</td>\n",
       "      <td>0.469931</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.397097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.097909</td>\n",
       "      <td>0.452412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.394606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.077447</td>\n",
       "      <td>0.453016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.424096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.066469</td>\n",
       "      <td>0.459295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.419965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.059478</td>\n",
       "      <td>0.472262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.395120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.053263</td>\n",
       "      <td>0.487996</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.402493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.047088</td>\n",
       "      <td>0.504077</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.352493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.042468</td>\n",
       "      <td>0.508207</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.360953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.512055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.434442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.512710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.409351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.507016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.359374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.030331</td>\n",
       "      <td>0.506345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.372946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028149</td>\n",
       "      <td>0.507799</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.376972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.511581</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.376243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.515338</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.397492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.518017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.372657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.376061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.021306</td>\n",
       "      <td>0.523087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.383422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.524735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.379921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.020286</td>\n",
       "      <td>0.525781</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.374738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.020023</td>\n",
       "      <td>0.525763</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.360787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.019861</td>\n",
       "      <td>0.525161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.361817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.524233</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.382550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.019764</td>\n",
       "      <td>0.523159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.367123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_loss  train_misclass  valid_misclass   runtime\n",
       "0     5.346650    5.131454           0.475        0.466667  0.000000\n",
       "1     1.187475    1.445455           0.450        0.533333  1.507944\n",
       "2     0.974738    1.217930           0.400        0.500000  1.386974\n",
       "3     0.677581    0.901529           0.300        0.400000  1.415777\n",
       "4     0.444578    0.676926           0.275        0.300000  1.396895\n",
       "5     0.298532    0.551718           0.200        0.200000  1.463284\n",
       "6     0.211604    0.507916           0.100        0.166667  1.381572\n",
       "7     0.132911    0.469931           0.050        0.166667  1.397097\n",
       "8     0.097909    0.452412           0.000        0.166667  1.394606\n",
       "9     0.077447    0.453016           0.000        0.200000  1.424096\n",
       "10    0.066469    0.459295           0.000        0.200000  1.419965\n",
       "11    0.059478    0.472262           0.000        0.200000  1.395120\n",
       "12    0.053263    0.487996           0.000        0.200000  1.402493\n",
       "13    0.047088    0.504077           0.000        0.200000  1.352493\n",
       "14    0.042468    0.508207           0.000        0.200000  1.360953\n",
       "15    0.039185    0.512055           0.000        0.200000  1.434442\n",
       "16    0.036200    0.512710           0.000        0.200000  1.409351\n",
       "17    0.032971    0.507016           0.000        0.166667  1.359374\n",
       "18    0.030331    0.506345           0.000        0.166667  1.372946\n",
       "19    0.028149    0.507799           0.000        0.166667  1.376972\n",
       "20    0.026143    0.511581           0.000        0.166667  1.376243\n",
       "21    0.024460    0.515338           0.000        0.166667  1.397492\n",
       "22    0.023193    0.518017           0.000        0.166667  1.372657\n",
       "23    0.022102    0.520476           0.000        0.166667  1.376061\n",
       "24    0.021306    0.523087           0.000        0.166667  1.383422\n",
       "25    0.020703    0.524735           0.000        0.166667  1.379921\n",
       "26    0.020286    0.525781           0.000        0.166667  1.374738\n",
       "27    0.020023    0.525763           0.000        0.166667  1.360787\n",
       "28    0.019861    0.525161           0.000        0.166667  1.361817\n",
       "29    0.019783    0.524233           0.000        0.166667  1.382550\n",
       "30    0.019764    0.523159           0.000        0.166667  1.367123"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we arrive at 83.4% accuracy, so 25 from 30 trials are correctly predicted. In the [Cropped Decoding Tutorial](./Cropped_Decoding.html), we can learn how to achieve higher accuracies using cropped training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all our hyperparameters and architectural choices done, we can evaluate the accuracies to report in our publication by evaluating on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4304921627044678,\n",
       " 'misclass': 0.19999999999999996,\n",
       " 'runtime': 0.0006480216979980469}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = SignalAndTarget(X[70:], y=y[70:])\n",
    "\n",
    "model.evaluate(test_set.X, test_set.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also retrieve predicted labels per trial as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_set.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also retrieve the raw network outputs per trial as such:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Note these are log-softmax outputs, so to get probabilities one would have to exponentiate them using `th.exp`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.1080518 , -0.04571718],\n",
       "       [-0.18738084, -1.7668402 ],\n",
       "       [-3.5502133 , -0.02913891],\n",
       "       [-0.00889281, -4.7269588 ],\n",
       "       [-0.03029968, -3.5117292 ],\n",
       "       [-0.00847233, -4.7751865 ],\n",
       "       [-4.0069547 , -0.01835621],\n",
       "       [-0.4073634 , -1.0948265 ],\n",
       "       [-0.02217743, -3.8197494 ],\n",
       "       [-0.22672895, -1.5952237 ],\n",
       "       [-3.5868273 , -0.02807647],\n",
       "       [-1.3834732 , -0.2886243 ],\n",
       "       [-0.3264436 , -1.2782836 ],\n",
       "       [-1.3229185 , -0.30973244],\n",
       "       [-0.08954807, -2.4574194 ],\n",
       "       [-0.0186951 , -3.9888294 ],\n",
       "       [-0.09142663, -2.437584  ],\n",
       "       [-0.24392618, -1.530375  ],\n",
       "       [-0.03590978, -3.3446462 ],\n",
       "       [-0.16686127, -1.8728634 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_outs(test_set.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you want to try cross-subject decoding, changing the loading code to the following will perform cross-subject decoding on imagined left vs right hand closing, with 50 training and 5 validation subjects (Warning, might be very slow if you are on CPU):\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.io import concatenate_raws\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "# First 50 subjects as train\n",
    "physionet_paths = [ mne.datasets.eegbci.load_data(sub_id,[4,8,12,]) for sub_id in range(1,51)]\n",
    "physionet_paths = np.concatenate(physionet_paths)\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto')\n",
    "         for path in physionet_paths] \n",
    "\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=picks,\n",
    "                baseline=None, preload=True)\n",
    "\n",
    "# 51-55 as validation subjects\n",
    "physionet_paths_valid = [mne.datasets.eegbci.load_data(sub_id,[4,8,12,]) for sub_id in range(51,56)]\n",
    "physionet_paths_valid = np.concatenate(physionet_paths_valid)\n",
    "parts_valid = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto')\n",
    "         for path in physionet_paths_valid]\n",
    "raw_valid = concatenate_raws(parts_valid)\n",
    "\n",
    "picks_valid = mne.pick_types(raw_valid.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "events_valid = mne.find_events(raw_valid, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epoched_valid = mne.Epochs(raw_valid, events_valid, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=picks_valid,\n",
    "                baseline=None, preload=True)\n",
    "\n",
    "train_X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "train_y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1\n",
    "valid_X = (epoched_valid.get_data() * 1e6).astype(np.float32)\n",
    "valid_y = (epoched_valid.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1\n",
    "train_set = SignalAndTarget(train_X, y=train_y)\n",
    "valid_set = SignalAndTarget(valid_X, y=valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset references\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This dataset was created and contributed to PhysioNet by the developers of the [BCI2000](http://www.schalklab.org/research/bci2000) instrumentation system, which they used in making these recordings. The system is described in:\n",
    " \n",
    "     Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043.\n",
    "\n",
    "[PhysioBank](https://physionet.org/physiobank/) is a large and growing archive of well-characterized digital recordings of physiologic signals and related data for use by the biomedical research community and further described in:\n",
    "\n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
