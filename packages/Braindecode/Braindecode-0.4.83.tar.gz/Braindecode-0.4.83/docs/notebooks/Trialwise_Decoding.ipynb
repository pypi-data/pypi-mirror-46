{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "nbsphinx": "hidden"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.sys.path.insert(0, '/home/schirrmr/braindecode/code/braindecode/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trialwise Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use a convolutional neural network on the [Physiobank EEG Motor Movement/Imagery Dataset](https://www.physionet.org/physiobank/database/eegmmidb/) to decode two classes:\n",
    "\n",
    "1. Executed and imagined opening and closing of both hands\n",
    "2. Executed and imagined opening and closing of both feet\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "We use only one subject (with 90 trials) in this tutorial for demonstration purposes. A more interesting decoding task with many more trials would be to do cross-subject decoding on the same dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load and preprocess your EEG dataset in any way, Braindecode only expects a 3darray (trials, channels, timesteps) of input signals `X` and a vector of labels `y` later (see below). In this tutorial, we will use the [MNE](https://www.martinos.org/mne/stable/index.html) library to load an EEG motor imagery/motor execution dataset. For a tutorial from MNE using Common Spatial Patterns to decode this data, see [here](http://martinos.org/mne/stable/auto_examples/decoding/plot_decoding_csp_eeg.html). For another library useful for loading EEG data, take a look at [Neo IO](https://pythonhosted.org/neo/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.io import concatenate_raws\n",
    "\n",
    "# 5,6,7,10,13,14 are codes for executed and imagined hands/feet\n",
    "subject_id = 22 # carefully cherry-picked to give nice results on such limited data :)\n",
    "event_codes = [5,6,9,10,13,14]\n",
    "#event_codes = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "# This will download the files if you don't have them yet,\n",
    "# and then return the paths to the files.\n",
    "physionet_paths = mne.datasets.eegbci.load_data(subject_id, event_codes)\n",
    "\n",
    "# Load each of the files\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto', verbose='WARNING')\n",
    "         for path in physionet_paths]\n",
    "\n",
    "# Concatenate them\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "# Find the events in this dataset\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Use only EEG channels\n",
    "eeg_channel_inds = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "# Extract trials, only using EEG channels\n",
    "epoched = mne.Epochs(raw, events, dict(hands_or_left=2, feet_or_right=3), tmin=1, tmax=4.1, proj=False, picks=eeg_channel_inds,\n",
    "                baseline=None, preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to Braindecode format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braindecode has a minimalistic ```SignalAndTarget``` class, with attributes `X` for the signal and `y` for the labels. `X` should have these dimensions: trials x channels x timesteps. `y` should have one label per trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert data from volt to millivolt\n",
    "# Pytorch expects float32 for input and int64 for labels.\n",
    "X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the first 40 trials for training and the next 30 trials for validation. The validation accuracies can be used to tune hyperparameters such as learning rate etc. The final 20 trials are split apart so we have a final hold-out evaluation set that is not part of any hyperparameter optimization. As mentioned before, this dataset is dangerously small to get any meaningful results and only used here for quick demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "train_set = SignalAndTarget(X[:40], y=y[:40])\n",
    "valid_set = SignalAndTarget(X[40:70], y=y[40:70])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Braindecode comes with some predefined convolutional neural network architectures for raw time-domain EEG. Here, we use the shallow ConvNet model from [Deep learning with convolutional neural networks for EEG decoding and visualization](https://arxiv.org/abs/1703.05051)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from braindecode.models.shallow_fbcsp import ShallowFBCSPNet\n",
    "from torch import nn\n",
    "from braindecode.torch_ext.util import set_random_seeds\n",
    "\n",
    "# Set if you want to use GPU\n",
    "# You can also use torch.cuda.is_available() to determine if cuda is available on your machine.\n",
    "cuda = False\n",
    "set_random_seeds(seed=20170629, cuda=cuda)\n",
    "n_classes = 2\n",
    "in_chans = train_set.X.shape[1]\n",
    "# final_conv_length = auto ensures we only get a single output in the time dimension\n",
    "model = ShallowFBCSPNet(in_chans=in_chans, n_classes=n_classes,\n",
    "                        input_time_length=train_set.X.shape[2],\n",
    "                        final_conv_length='auto')\n",
    "if cuda:\n",
    "    model.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use [AdamW](https://arxiv.org/abs/1711.05101) to optimize the parameters of our network together with [Cosine Annealing](https://arxiv.org/abs/1608.03983) of the learning rate. We supply some default parameters that we have found to work well for motor decoding, however we strongly encourage you to perform your own hyperparameter optimization using cross validation on your training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "We will now use the Braindecode model class directly to perform the training in a few lines of code. If you instead want to use your own training loop, have a look at the [Trialwise Low-Level Tutorial](./TrialWise_LowLevel.html).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from braindecode.torch_ext.optimizers import AdamW\n",
    "import torch.nn.functional as F\n",
    "#optimizer = AdamW(model.parameters(), lr=1*0.01, weight_decay=0.5*0.001) # these are good values for the deep model\n",
    "optimizer = AdamW(model.parameters(), lr=0.0625 * 0.01, weight_decay=0)\n",
    "model.compile(loss=F.nll_loss, optimizer=optimizer, iterator_seed=1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-07 15:46:08,441 INFO : Run until first stop...\n",
      "2019-05-07 15:46:09,171 INFO : Epoch 0\n",
      "2019-05-07 15:46:09,172 INFO : train_loss                5.34665\n",
      "2019-05-07 15:46:09,173 INFO : valid_loss                5.13145\n",
      "2019-05-07 15:46:09,173 INFO : train_misclass            0.47500\n",
      "2019-05-07 15:46:09,174 INFO : valid_misclass            0.46667\n",
      "2019-05-07 15:46:09,175 INFO : runtime                   0.00000\n",
      "2019-05-07 15:46:09,176 INFO : \n",
      "2019-05-07 15:46:09,979 INFO : Time only for training updates: 0.80s\n",
      "2019-05-07 15:46:10,596 INFO : Epoch 1\n",
      "2019-05-07 15:46:10,597 INFO : train_loss                1.18747\n",
      "2019-05-07 15:46:10,597 INFO : valid_loss                1.44545\n",
      "2019-05-07 15:46:10,598 INFO : train_misclass            0.45000\n",
      "2019-05-07 15:46:10,599 INFO : valid_misclass            0.53333\n",
      "2019-05-07 15:46:10,599 INFO : runtime                   1.53744\n",
      "2019-05-07 15:46:10,600 INFO : \n",
      "2019-05-07 15:46:11,312 INFO : Time only for training updates: 0.71s\n",
      "2019-05-07 15:46:11,960 INFO : Epoch 2\n",
      "2019-05-07 15:46:11,961 INFO : train_loss                0.97474\n",
      "2019-05-07 15:46:11,962 INFO : valid_loss                1.21793\n",
      "2019-05-07 15:46:11,963 INFO : train_misclass            0.40000\n",
      "2019-05-07 15:46:11,963 INFO : valid_misclass            0.50000\n",
      "2019-05-07 15:46:11,964 INFO : runtime                   1.33326\n",
      "2019-05-07 15:46:11,964 INFO : \n",
      "2019-05-07 15:46:12,691 INFO : Time only for training updates: 0.73s\n",
      "2019-05-07 15:46:13,305 INFO : Epoch 3\n",
      "2019-05-07 15:46:13,308 INFO : train_loss                0.67758\n",
      "2019-05-07 15:46:13,309 INFO : valid_loss                0.90153\n",
      "2019-05-07 15:46:13,311 INFO : train_misclass            0.30000\n",
      "2019-05-07 15:46:13,313 INFO : valid_misclass            0.40000\n",
      "2019-05-07 15:46:13,314 INFO : runtime                   1.38050\n",
      "2019-05-07 15:46:13,316 INFO : \n",
      "2019-05-07 15:46:14,042 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:14,663 INFO : Epoch 4\n",
      "2019-05-07 15:46:14,665 INFO : train_loss                0.44458\n",
      "2019-05-07 15:46:14,667 INFO : valid_loss                0.67693\n",
      "2019-05-07 15:46:14,669 INFO : train_misclass            0.27500\n",
      "2019-05-07 15:46:14,670 INFO : valid_misclass            0.30000\n",
      "2019-05-07 15:46:14,672 INFO : runtime                   1.35117\n",
      "2019-05-07 15:46:14,673 INFO : \n",
      "2019-05-07 15:46:15,405 INFO : Time only for training updates: 0.73s\n",
      "2019-05-07 15:46:16,034 INFO : Epoch 5\n",
      "2019-05-07 15:46:16,037 INFO : train_loss                0.29853\n",
      "2019-05-07 15:46:16,038 INFO : valid_loss                0.55172\n",
      "2019-05-07 15:46:16,040 INFO : train_misclass            0.20000\n",
      "2019-05-07 15:46:16,042 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:16,043 INFO : runtime                   1.36293\n",
      "2019-05-07 15:46:16,045 INFO : \n",
      "2019-05-07 15:46:16,762 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:17,392 INFO : Epoch 6\n",
      "2019-05-07 15:46:17,395 INFO : train_loss                0.21160\n",
      "2019-05-07 15:46:17,396 INFO : valid_loss                0.50792\n",
      "2019-05-07 15:46:17,398 INFO : train_misclass            0.10000\n",
      "2019-05-07 15:46:17,400 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:17,401 INFO : runtime                   1.35735\n",
      "2019-05-07 15:46:17,403 INFO : \n",
      "2019-05-07 15:46:18,218 INFO : Time only for training updates: 0.81s\n",
      "2019-05-07 15:46:18,854 INFO : Epoch 7\n",
      "2019-05-07 15:46:18,856 INFO : train_loss                0.13291\n",
      "2019-05-07 15:46:18,858 INFO : valid_loss                0.46993\n",
      "2019-05-07 15:46:18,860 INFO : train_misclass            0.05000\n",
      "2019-05-07 15:46:18,861 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:18,863 INFO : runtime                   1.45539\n",
      "2019-05-07 15:46:18,865 INFO : \n",
      "2019-05-07 15:46:19,619 INFO : Time only for training updates: 0.75s\n",
      "2019-05-07 15:46:20,259 INFO : Epoch 8\n",
      "2019-05-07 15:46:20,262 INFO : train_loss                0.09791\n",
      "2019-05-07 15:46:20,264 INFO : valid_loss                0.45241\n",
      "2019-05-07 15:46:20,265 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:20,267 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:20,269 INFO : runtime                   1.40119\n",
      "2019-05-07 15:46:20,270 INFO : \n",
      "2019-05-07 15:46:20,997 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:21,624 INFO : Epoch 9\n",
      "2019-05-07 15:46:21,627 INFO : train_loss                0.07745\n",
      "2019-05-07 15:46:21,628 INFO : valid_loss                0.45302\n",
      "2019-05-07 15:46:21,630 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:21,632 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:21,633 INFO : runtime                   1.37757\n",
      "2019-05-07 15:46:21,635 INFO : \n",
      "2019-05-07 15:46:22,351 INFO : Time only for training updates: 0.71s\n",
      "2019-05-07 15:46:22,965 INFO : Epoch 10\n",
      "2019-05-07 15:46:22,967 INFO : train_loss                0.06647\n",
      "2019-05-07 15:46:22,969 INFO : valid_loss                0.45930\n",
      "2019-05-07 15:46:22,971 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:22,972 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:22,974 INFO : runtime                   1.35443\n",
      "2019-05-07 15:46:22,976 INFO : \n",
      "2019-05-07 15:46:23,724 INFO : Time only for training updates: 0.75s\n",
      "2019-05-07 15:46:24,338 INFO : Epoch 11\n",
      "2019-05-07 15:46:24,341 INFO : train_loss                0.05948\n",
      "2019-05-07 15:46:24,342 INFO : valid_loss                0.47226\n",
      "2019-05-07 15:46:24,344 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:24,345 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:24,347 INFO : runtime                   1.37325\n",
      "2019-05-07 15:46:24,349 INFO : \n",
      "2019-05-07 15:46:25,079 INFO : Time only for training updates: 0.73s\n",
      "2019-05-07 15:46:25,732 INFO : Epoch 12\n",
      "2019-05-07 15:46:25,734 INFO : train_loss                0.05326\n",
      "2019-05-07 15:46:25,736 INFO : valid_loss                0.48800\n",
      "2019-05-07 15:46:25,737 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:25,739 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:25,741 INFO : runtime                   1.35506\n",
      "2019-05-07 15:46:25,742 INFO : \n",
      "2019-05-07 15:46:26,468 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:27,129 INFO : Epoch 13\n",
      "2019-05-07 15:46:27,132 INFO : train_loss                0.04709\n",
      "2019-05-07 15:46:27,133 INFO : valid_loss                0.50408\n",
      "2019-05-07 15:46:27,135 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:27,136 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:27,138 INFO : runtime                   1.38843\n",
      "2019-05-07 15:46:27,140 INFO : \n",
      "2019-05-07 15:46:27,862 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:28,493 INFO : Epoch 14\n",
      "2019-05-07 15:46:28,496 INFO : train_loss                0.04247\n",
      "2019-05-07 15:46:28,497 INFO : valid_loss                0.50821\n",
      "2019-05-07 15:46:28,499 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:28,501 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:28,502 INFO : runtime                   1.39463\n",
      "2019-05-07 15:46:28,504 INFO : \n",
      "2019-05-07 15:46:29,252 INFO : Time only for training updates: 0.75s\n",
      "2019-05-07 15:46:29,889 INFO : Epoch 15\n",
      "2019-05-07 15:46:29,892 INFO : train_loss                0.03919\n",
      "2019-05-07 15:46:29,893 INFO : valid_loss                0.51205\n",
      "2019-05-07 15:46:29,895 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:29,897 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:29,898 INFO : runtime                   1.38939\n",
      "2019-05-07 15:46:29,900 INFO : \n",
      "2019-05-07 15:46:30,712 INFO : Time only for training updates: 0.81s\n",
      "2019-05-07 15:46:31,325 INFO : Epoch 16\n",
      "2019-05-07 15:46:31,327 INFO : train_loss                0.03620\n",
      "2019-05-07 15:46:31,329 INFO : valid_loss                0.51271\n",
      "2019-05-07 15:46:31,331 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:31,332 INFO : valid_misclass            0.20000\n",
      "2019-05-07 15:46:31,334 INFO : runtime                   1.46129\n",
      "2019-05-07 15:46:31,335 INFO : \n",
      "2019-05-07 15:46:32,052 INFO : Time only for training updates: 0.71s\n",
      "2019-05-07 15:46:32,748 INFO : Epoch 17\n",
      "2019-05-07 15:46:32,751 INFO : train_loss                0.03297\n",
      "2019-05-07 15:46:32,753 INFO : valid_loss                0.50702\n",
      "2019-05-07 15:46:32,754 INFO : train_misclass            0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-07 15:46:32,756 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:32,757 INFO : runtime                   1.33846\n",
      "2019-05-07 15:46:32,759 INFO : \n",
      "2019-05-07 15:46:33,476 INFO : Time only for training updates: 0.71s\n",
      "2019-05-07 15:46:34,121 INFO : Epoch 18\n",
      "2019-05-07 15:46:34,123 INFO : train_loss                0.03033\n",
      "2019-05-07 15:46:34,125 INFO : valid_loss                0.50634\n",
      "2019-05-07 15:46:34,127 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:34,128 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:34,130 INFO : runtime                   1.42391\n",
      "2019-05-07 15:46:34,131 INFO : \n",
      "2019-05-07 15:46:34,862 INFO : Time only for training updates: 0.73s\n",
      "2019-05-07 15:46:35,501 INFO : Epoch 19\n",
      "2019-05-07 15:46:35,503 INFO : train_loss                0.02815\n",
      "2019-05-07 15:46:35,505 INFO : valid_loss                0.50780\n",
      "2019-05-07 15:46:35,507 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:35,509 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:35,511 INFO : runtime                   1.38650\n",
      "2019-05-07 15:46:35,512 INFO : \n",
      "2019-05-07 15:46:36,264 INFO : Time only for training updates: 0.75s\n",
      "2019-05-07 15:46:36,911 INFO : Epoch 20\n",
      "2019-05-07 15:46:36,914 INFO : train_loss                0.02614\n",
      "2019-05-07 15:46:36,915 INFO : valid_loss                0.51158\n",
      "2019-05-07 15:46:36,917 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:36,918 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:36,920 INFO : runtime                   1.40189\n",
      "2019-05-07 15:46:36,922 INFO : \n",
      "2019-05-07 15:46:37,647 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:38,281 INFO : Epoch 21\n",
      "2019-05-07 15:46:38,284 INFO : train_loss                0.02446\n",
      "2019-05-07 15:46:38,285 INFO : valid_loss                0.51534\n",
      "2019-05-07 15:46:38,287 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:38,289 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:38,290 INFO : runtime                   1.38325\n",
      "2019-05-07 15:46:38,292 INFO : \n",
      "2019-05-07 15:46:39,014 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:39,627 INFO : Epoch 22\n",
      "2019-05-07 15:46:39,629 INFO : train_loss                0.02319\n",
      "2019-05-07 15:46:39,631 INFO : valid_loss                0.51802\n",
      "2019-05-07 15:46:39,633 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:39,634 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:39,636 INFO : runtime                   1.36695\n",
      "2019-05-07 15:46:39,637 INFO : \n",
      "2019-05-07 15:46:40,454 INFO : Time only for training updates: 0.81s\n",
      "2019-05-07 15:46:41,068 INFO : Epoch 23\n",
      "2019-05-07 15:46:41,070 INFO : train_loss                0.02210\n",
      "2019-05-07 15:46:41,072 INFO : valid_loss                0.52048\n",
      "2019-05-07 15:46:41,074 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:41,075 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:41,077 INFO : runtime                   1.43981\n",
      "2019-05-07 15:46:41,078 INFO : \n",
      "2019-05-07 15:46:41,896 INFO : Time only for training updates: 0.82s\n",
      "2019-05-07 15:46:42,517 INFO : Epoch 24\n",
      "2019-05-07 15:46:42,520 INFO : train_loss                0.02131\n",
      "2019-05-07 15:46:42,521 INFO : valid_loss                0.52309\n",
      "2019-05-07 15:46:42,523 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:42,525 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:42,526 INFO : runtime                   1.44255\n",
      "2019-05-07 15:46:42,528 INFO : \n",
      "2019-05-07 15:46:43,280 INFO : Time only for training updates: 0.75s\n",
      "2019-05-07 15:46:43,896 INFO : Epoch 25\n",
      "2019-05-07 15:46:43,899 INFO : train_loss                0.02070\n",
      "2019-05-07 15:46:43,900 INFO : valid_loss                0.52473\n",
      "2019-05-07 15:46:43,902 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:43,904 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:43,905 INFO : runtime                   1.38322\n",
      "2019-05-07 15:46:43,907 INFO : \n",
      "2019-05-07 15:46:44,639 INFO : Time only for training updates: 0.73s\n",
      "2019-05-07 15:46:45,258 INFO : Epoch 26\n",
      "2019-05-07 15:46:45,261 INFO : train_loss                0.02029\n",
      "2019-05-07 15:46:45,262 INFO : valid_loss                0.52578\n",
      "2019-05-07 15:46:45,264 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:45,266 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:45,267 INFO : runtime                   1.35938\n",
      "2019-05-07 15:46:45,269 INFO : \n",
      "2019-05-07 15:46:46,002 INFO : Time only for training updates: 0.73s\n",
      "2019-05-07 15:46:46,618 INFO : Epoch 27\n",
      "2019-05-07 15:46:46,621 INFO : train_loss                0.02002\n",
      "2019-05-07 15:46:46,623 INFO : valid_loss                0.52576\n",
      "2019-05-07 15:46:46,625 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:46,626 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:46,628 INFO : runtime                   1.36309\n",
      "2019-05-07 15:46:46,629 INFO : \n",
      "2019-05-07 15:46:47,370 INFO : Time only for training updates: 0.74s\n",
      "2019-05-07 15:46:47,988 INFO : Epoch 28\n",
      "2019-05-07 15:46:47,991 INFO : train_loss                0.01986\n",
      "2019-05-07 15:46:47,992 INFO : valid_loss                0.52516\n",
      "2019-05-07 15:46:47,994 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:47,996 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:47,997 INFO : runtime                   1.36766\n",
      "2019-05-07 15:46:47,999 INFO : \n",
      "2019-05-07 15:46:48,717 INFO : Time only for training updates: 0.72s\n",
      "2019-05-07 15:46:49,392 INFO : Epoch 29\n",
      "2019-05-07 15:46:49,395 INFO : train_loss                0.01978\n",
      "2019-05-07 15:46:49,396 INFO : valid_loss                0.52423\n",
      "2019-05-07 15:46:49,398 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:49,400 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:49,401 INFO : runtime                   1.34718\n",
      "2019-05-07 15:46:49,403 INFO : \n",
      "2019-05-07 15:46:50,119 INFO : Time only for training updates: 0.71s\n",
      "2019-05-07 15:46:50,748 INFO : Epoch 30\n",
      "2019-05-07 15:46:50,751 INFO : train_loss                0.01976\n",
      "2019-05-07 15:46:50,752 INFO : valid_loss                0.52316\n",
      "2019-05-07 15:46:50,754 INFO : train_misclass            0.00000\n",
      "2019-05-07 15:46:50,755 INFO : valid_misclass            0.16667\n",
      "2019-05-07 15:46:50,757 INFO : runtime                   1.40228\n",
      "2019-05-07 15:46:50,759 INFO : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<braindecode.experiments.experiment.Experiment at 0x7fe6775de6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_set.X, train_set.y, epochs=30, batch_size=64, scheduler='cosine',\n",
    "         validation_data=(valid_set.X, valid_set.y),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monitored values are also stored into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_misclass</th>\n",
       "      <th>valid_misclass</th>\n",
       "      <th>runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.346650</td>\n",
       "      <td>5.131454</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.187475</td>\n",
       "      <td>1.445455</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.537441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.974738</td>\n",
       "      <td>1.217930</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.333265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.677581</td>\n",
       "      <td>0.901529</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.380500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.444578</td>\n",
       "      <td>0.676926</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.351172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.298532</td>\n",
       "      <td>0.551718</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.362934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.211604</td>\n",
       "      <td>0.507916</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.357354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.132911</td>\n",
       "      <td>0.469931</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.455387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.097909</td>\n",
       "      <td>0.452412</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.401193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.077447</td>\n",
       "      <td>0.453016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.377566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.066469</td>\n",
       "      <td>0.459295</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.354433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.059478</td>\n",
       "      <td>0.472262</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.373249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.053263</td>\n",
       "      <td>0.487996</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.355062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.047088</td>\n",
       "      <td>0.504077</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.388429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.042468</td>\n",
       "      <td>0.508207</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.394631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.039185</td>\n",
       "      <td>0.512055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.389391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.036200</td>\n",
       "      <td>0.512710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.461292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.032971</td>\n",
       "      <td>0.507016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.338458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.030331</td>\n",
       "      <td>0.506345</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.423910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028149</td>\n",
       "      <td>0.507799</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.386497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.026143</td>\n",
       "      <td>0.511581</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.401891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.024460</td>\n",
       "      <td>0.515338</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.383246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.023193</td>\n",
       "      <td>0.518017</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.366952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.022102</td>\n",
       "      <td>0.520476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.439813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.021306</td>\n",
       "      <td>0.523087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.442548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.524735</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.383222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.020286</td>\n",
       "      <td>0.525781</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.359383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.020023</td>\n",
       "      <td>0.525763</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.363086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.019861</td>\n",
       "      <td>0.525161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.367662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.524233</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.347175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.019764</td>\n",
       "      <td>0.523159</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.402279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  valid_loss  train_misclass  valid_misclass   runtime\n",
       "0     5.346650    5.131454           0.475        0.466667  0.000000\n",
       "1     1.187475    1.445455           0.450        0.533333  1.537441\n",
       "2     0.974738    1.217930           0.400        0.500000  1.333265\n",
       "3     0.677581    0.901529           0.300        0.400000  1.380500\n",
       "4     0.444578    0.676926           0.275        0.300000  1.351172\n",
       "5     0.298532    0.551718           0.200        0.200000  1.362934\n",
       "6     0.211604    0.507916           0.100        0.166667  1.357354\n",
       "7     0.132911    0.469931           0.050        0.166667  1.455387\n",
       "8     0.097909    0.452412           0.000        0.166667  1.401193\n",
       "9     0.077447    0.453016           0.000        0.200000  1.377566\n",
       "10    0.066469    0.459295           0.000        0.200000  1.354433\n",
       "11    0.059478    0.472262           0.000        0.200000  1.373249\n",
       "12    0.053263    0.487996           0.000        0.200000  1.355062\n",
       "13    0.047088    0.504077           0.000        0.200000  1.388429\n",
       "14    0.042468    0.508207           0.000        0.200000  1.394631\n",
       "15    0.039185    0.512055           0.000        0.200000  1.389391\n",
       "16    0.036200    0.512710           0.000        0.200000  1.461292\n",
       "17    0.032971    0.507016           0.000        0.166667  1.338458\n",
       "18    0.030331    0.506345           0.000        0.166667  1.423910\n",
       "19    0.028149    0.507799           0.000        0.166667  1.386497\n",
       "20    0.026143    0.511581           0.000        0.166667  1.401891\n",
       "21    0.024460    0.515338           0.000        0.166667  1.383246\n",
       "22    0.023193    0.518017           0.000        0.166667  1.366952\n",
       "23    0.022102    0.520476           0.000        0.166667  1.439813\n",
       "24    0.021306    0.523087           0.000        0.166667  1.442548\n",
       "25    0.020703    0.524735           0.000        0.166667  1.383222\n",
       "26    0.020286    0.525781           0.000        0.166667  1.359383\n",
       "27    0.020023    0.525763           0.000        0.166667  1.363086\n",
       "28    0.019861    0.525161           0.000        0.166667  1.367662\n",
       "29    0.019783    0.524233           0.000        0.166667  1.347175\n",
       "30    0.019764    0.523159           0.000        0.166667  1.402279"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we arrive at 83.4% accuracy, so 25 from 30 trials are correctly predicted. In the [Cropped Decoding Tutorial](./Cropped_Decoding.html), we can learn how to achieve higher accuracies using cropped training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have all our hyperparameters and architectural choices done, we can evaluate the accuracies to report in our publication by evaluating on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4304921627044678,\n",
       " 'misclass': 0.19999999999999996,\n",
       " 'runtime': 0.0002689361572265625}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = SignalAndTarget(X[70:], y=y[70:])\n",
    "\n",
    "model.evaluate(test_set.X, test_set.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also retrieve predicted labels per trial as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_set.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also retrieve the raw network outputs per trial as such:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "Note these are log-softmax outputs, so to get probabilities one would have to exponentiate them using `th.exp`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.1080518 , -0.04571718],\n",
       "       [-0.18738084, -1.7668402 ],\n",
       "       [-3.5502133 , -0.02913891],\n",
       "       [-0.00889281, -4.7269588 ],\n",
       "       [-0.03029968, -3.5117292 ],\n",
       "       [-0.00847233, -4.7751865 ],\n",
       "       [-4.0069547 , -0.01835621],\n",
       "       [-0.4073634 , -1.0948265 ],\n",
       "       [-0.02217743, -3.8197494 ],\n",
       "       [-0.22672895, -1.5952237 ],\n",
       "       [-3.5868273 , -0.02807647],\n",
       "       [-1.3834732 , -0.2886243 ],\n",
       "       [-0.3264436 , -1.2782836 ],\n",
       "       [-1.3229185 , -0.30973244],\n",
       "       [-0.08954807, -2.4574194 ],\n",
       "       [-0.0186951 , -3.9888294 ],\n",
       "       [-0.09142663, -2.437584  ],\n",
       "       [-0.24392618, -1.530375  ],\n",
       "       [-0.03590978, -3.3446462 ],\n",
       "       [-0.16686127, -1.8728634 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_outs(test_set.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you want to try cross-subject decoding, changing the loading code to the following will perform cross-subject decoding on imagined left vs right hand closing, with 50 training and 5 validation subjects (Warning, might be very slow if you are on CPU):\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "from mne.io import concatenate_raws\n",
    "from braindecode.datautil.signal_target import SignalAndTarget\n",
    "\n",
    "# First 50 subjects as train\n",
    "physionet_paths = [ mne.datasets.eegbci.load_data(sub_id,[4,8,12,]) for sub_id in range(1,51)]\n",
    "physionet_paths = np.concatenate(physionet_paths)\n",
    "parts = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto')\n",
    "         for path in physionet_paths] \n",
    "\n",
    "raw = concatenate_raws(parts)\n",
    "\n",
    "picks = mne.pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "events = mne.find_events(raw, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epoched = mne.Epochs(raw, events, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=picks,\n",
    "                baseline=None, preload=True)\n",
    "\n",
    "# 51-55 as validation subjects\n",
    "physionet_paths_valid = [mne.datasets.eegbci.load_data(sub_id,[4,8,12,]) for sub_id in range(51,56)]\n",
    "physionet_paths_valid = np.concatenate(physionet_paths_valid)\n",
    "parts_valid = [mne.io.read_raw_edf(path, preload=True,stim_channel='auto')\n",
    "         for path in physionet_paths_valid]\n",
    "raw_valid = concatenate_raws(parts_valid)\n",
    "\n",
    "picks_valid = mne.pick_types(raw_valid.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                   exclude='bads')\n",
    "\n",
    "events_valid = mne.find_events(raw_valid, shortest_event=0, stim_channel='STI 014')\n",
    "\n",
    "# Read epochs (train will be done only between 1 and 2s)\n",
    "# Testing will be done with a running classifier\n",
    "epoched_valid = mne.Epochs(raw_valid, events_valid, dict(hands=2, feet=3), tmin=1, tmax=4.1, proj=False, picks=picks_valid,\n",
    "                baseline=None, preload=True)\n",
    "\n",
    "train_X = (epoched.get_data() * 1e6).astype(np.float32)\n",
    "train_y = (epoched.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1\n",
    "valid_X = (epoched_valid.get_data() * 1e6).astype(np.float32)\n",
    "valid_y = (epoched_valid.events[:,2] - 2).astype(np.int64) #2,3 -> 0,1\n",
    "train_set = SignalAndTarget(train_X, y=train_y)\n",
    "valid_set = SignalAndTarget(valid_X, y=valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset references\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " This dataset was created and contributed to PhysioNet by the developers of the [BCI2000](http://www.schalklab.org/research/bci2000) instrumentation system, which they used in making these recordings. The system is described in:\n",
    " \n",
    "     Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. (2004) BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE TBME 51(6):1034-1043.\n",
    "\n",
    "[PhysioBank](https://physionet.org/physiobank/) is a large and growing archive of well-characterized digital recordings of physiologic signals and related data for use by the biomedical research community and further described in:\n",
    "\n",
    "    Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. (2000) PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
