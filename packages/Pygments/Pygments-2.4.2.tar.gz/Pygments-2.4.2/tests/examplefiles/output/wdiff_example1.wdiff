(lp0
(ccopy_reg
_reconstructor
p1
(cpygments.token
_TokenType
p2
c__builtin__
tuple
p3
(S'Text'
p4
tp5
tp6
Rp7
(dp8
S'Beer'
p9
g1
(g2
g3
(g4
g9
tp10
tp11
Rp12
(dp13
S'parent'
p14
g7
sS'subtypes'
p15
c__builtin__
set
p16
((lp17
tp18
Rp19
sbsS'Whitespace'
p20
g1
(g2
g3
(g4
g20
tp21
tp22
Rp23
(dp24
g14
g7
sg15
g16
((lp25
tp26
Rp27
sbsg14
g1
(g2
g3
(ttp28
Rp29
(dp30
S'Number'
p31
g1
(g2
g3
(S'Literal'
p32
g31
tp33
tp34
Rp35
(dp36
S'Integer'
p37
g1
(g2
g3
(g32
g31
g37
tp38
tp39
Rp40
(dp41
g14
g35
sS'Long'
p42
g1
(g2
g3
(g32
g31
g37
g42
tp43
tp44
Rp45
(dp46
g14
g40
sg15
g16
((lp47
tp48
Rp49
sbsg15
g16
((lp50
g45
atp51
Rp52
sbsg14
g1
(g2
g3
(g32
tp53
tp54
Rp55
(dp56
S'Scalar'
p57
g1
(g2
g3
(g32
g57
tp58
tp59
Rp60
(dp61
g14
g55
sg15
g16
((lp62
g1
(g2
g3
(g32
g57
S'Plain'
p63
tp64
tp65
Rp66
(dp67
g14
g60
sg15
g16
((lp68
tp69
Rp70
sbatp71
Rp72
sg63
g66
sbsg31
g35
sg14
g29
sS'Other'
p73
g1
(g2
g3
(g32
g73
tp74
tp75
Rp76
(dp77
g14
g55
sg15
g16
((lp78
tp79
Rp80
sbsS'Char'
p81
g1
(g2
g3
(g32
g81
tp82
tp83
Rp84
(dp85
g14
g55
sg15
g16
((lp86
tp87
Rp88
sbsS'String'
p89
g1
(g2
g3
(g32
g89
tp90
tp91
Rp92
(dp93
g81
g1
(g2
g3
(g32
g89
g81
tp94
tp95
Rp96
(dp97
g14
g92
sg15
g16
((lp98
tp99
Rp100
sbsS'Backtick'
p101
g1
(g2
g3
(g32
g89
g101
tp102
tp103
Rp104
(dp105
g14
g92
sg15
g16
((lp106
tp107
Rp108
sbsS'Heredoc'
p109
g1
(g2
g3
(g32
g89
g109
tp110
tp111
Rp112
(dp113
g14
g92
sg15
g16
((lp114
tp115
Rp116
sbsS'Symbol'
p117
g1
(g2
g3
(g32
g89
g117
tp118
tp119
Rp120
(dp121
g14
g92
sg15
g16
((lp122
tp123
Rp124
sbsS'Interpol'
p125
g1
(g2
g3
(g32
g89
g125
tp126
tp127
Rp128
(dp129
g14
g92
sg15
g16
((lp130
tp131
Rp132
sbsS'Delimiter'
p133
g1
(g2
g3
(g32
g89
g133
tp134
tp135
Rp136
(dp137
g14
g92
sg15
g16
((lp138
tp139
Rp140
sbsS'Boolean'
p141
g1
(g2
g3
(g32
g89
g141
tp142
tp143
Rp144
(dp145
g14
g92
sg15
g16
((lp146
tp147
Rp148
sbsS'Character'
p149
g1
(g2
g3
(g32
g89
g149
tp150
tp151
Rp152
(dp153
g14
g92
sg15
g16
((lp154
tp155
Rp156
sbsS'Double'
p157
g1
(g2
g3
(g32
g89
g157
tp158
tp159
Rp160
(dp161
g14
g92
sg15
g16
((lp162
tp163
Rp164
sbsS'Delimeter'
p165
g1
(g2
g3
(g32
g89
g165
tp166
tp167
Rp168
(dp169
g14
g92
sg15
g16
((lp170
tp171
Rp172
sbsS'Atom'
p173
g1
(g2
g3
(g32
g89
g173
tp174
tp175
Rp176
(dp177
g14
g92
sg15
g16
((lp178
tp179
Rp180
sbsS'Affix'
p181
g1
(g2
g3
(g32
g89
g181
tp182
tp183
Rp184
(dp185
g14
g92
sg15
g16
((lp186
tp187
Rp188
sbsS'Name'
p189
g1
(g2
g3
(g32
g89
g189
tp190
tp191
Rp192
(dp193
g14
g92
sg15
g16
((lp194
tp195
Rp196
sbsS'Regex'
p197
g1
(g2
g3
(g32
g89
g197
tp198
tp199
Rp200
(dp201
g14
g92
sg15
g16
((lp202
tp203
Rp204
sbsS'Interp'
p205
g1
(g2
g3
(g32
g89
g205
tp206
tp207
Rp208
(dp209
g14
g92
sg15
g16
((lp210
tp211
Rp212
sbsS'Escape'
p213
g1
(g2
g3
(g32
g89
g213
tp214
tp215
Rp216
(dp217
g14
g92
sg15
g16
((lp218
tp219
Rp220
sbsg15
g16
((lp221
g136
ag120
ag200
ag1
(g2
g3
(g32
g89
S'Doc'
p222
tp223
tp224
Rp225
(dp226
g14
g92
sg15
g16
((lp227
tp228
Rp229
sbag152
ag144
ag160
ag128
ag176
ag168
ag192
ag216
ag1
(g2
g3
(g32
g89
S'Single'
p230
tp231
tp232
Rp233
(dp234
g14
g92
sg15
g16
((lp235
tp236
Rp237
sbag1
(g2
g3
(g32
g89
g73
tp238
tp239
Rp240
(dp241
g14
g92
sg15
g16
((lp242
tp243
Rp244
sbag208
ag104
ag184
ag1
(g2
g3
(g32
g89
S'Moment'
p245
tp246
tp247
Rp248
(dp249
g14
g92
sg15
g16
((lp250
tp251
Rp252
sbag96
ag112
atp253
Rp254
sg230
g233
sg245
g248
sg14
g55
sg73
g240
sg222
g225
sbsg15
g16
((lp255
g92
ag84
ag76
ag1
(g2
g3
(g32
S'Date'
p256
tp257
tp258
Rp259
(dp260
g14
g55
sg15
g16
((lp261
tp262
Rp263
sbag60
ag35
atp264
Rp265
sg256
g259
sbsS'Bin'
p266
g1
(g2
g3
(g32
g31
g266
tp267
tp268
Rp269
(dp270
g14
g35
sg15
g16
((lp271
tp272
Rp273
sbsS'Radix'
p274
g1
(g2
g3
(g32
g31
g274
tp275
tp276
Rp277
(dp278
g14
g35
sg15
g16
((lp279
tp280
Rp281
sbsS'Oct'
p282
g1
(g2
g3
(g32
g31
g282
tp283
tp284
Rp285
(dp286
g14
g35
sg15
g16
((lp287
tp288
Rp289
sbsS'Dec'
p290
g1
(g2
g3
(g32
g31
g290
tp291
tp292
Rp293
(dp294
g14
g35
sg15
g16
((lp295
tp296
Rp297
sbsS'Hex'
p298
g1
(g2
g3
(g32
g31
g298
tp299
tp300
Rp301
(dp302
g14
g35
sg15
g16
((lp303
tp304
Rp305
sbsg15
g16
((lp306
g40
ag277
ag293
ag1
(g2
g3
(g32
g31
S'Decimal'
p307
tp308
tp309
Rp310
(dp311
g14
g35
sg15
g16
((lp312
tp313
Rp314
sbag269
ag1
(g2
g3
(g32
g31
S'Float'
p315
tp316
tp317
Rp318
(dp319
g14
g35
sg15
g16
((lp320
tp321
Rp322
sbag285
ag301
atp323
Rp324
sg307
g310
sg315
g318
sbsS'Generic'
p325
g1
(g2
g3
(g325
tp326
tp327
Rp328
(dp329
g14
g29
sS'Deleted'
p330
g1
(g2
g3
(g325
g330
tp331
tp332
Rp333
(dp334
g14
g328
sg15
g16
((lp335
tp336
Rp337
sbsS'Subheading'
p338
g1
(g2
g3
(g325
g338
tp339
tp340
Rp341
(dp342
g14
g328
sg15
g16
((lp343
tp344
Rp345
sbsS'Heading'
p346
g1
(g2
g3
(g325
g346
tp347
tp348
Rp349
(dp350
g14
g328
sg15
g16
((lp351
tp352
Rp353
sbsS'Emph'
p354
g1
(g2
g3
(g325
g354
tp355
tp356
Rp357
(dp358
g14
g328
sg15
g16
((lp359
tp360
Rp361
sbsS'Prompt'
p362
g1
(g2
g3
(g325
g362
tp363
tp364
Rp365
(dp366
g14
g328
sg15
g16
((lp367
tp368
Rp369
sbsS'Inserted'
p370
g1
(g2
g3
(g325
g370
tp371
tp372
Rp373
(dp374
g14
g328
sg15
g16
((lp375
tp376
Rp377
sbsS'Strong'
p378
g1
(g2
g3
(g325
g378
tp379
tp380
Rp381
(dp382
g14
g328
sg15
g16
((lp383
tp384
Rp385
sbsS'Error'
p386
g1
(g2
g3
(g325
g386
tp387
tp388
Rp389
(dp390
g14
g328
sg15
g16
((lp391
tp392
Rp393
sbsS'Traceback'
p394
g1
(g2
g3
(g325
g394
tp395
tp396
Rp397
(dp398
g14
g328
sg15
g16
((lp399
tp400
Rp401
sbsg15
g16
((lp402
g349
ag341
ag1
(g2
g3
(g325
S'Output'
p403
tp404
tp405
Rp406
(dp407
g14
g328
sg15
g16
((lp408
tp409
Rp410
sbag381
ag357
ag389
ag397
ag373
ag365
ag333
atp411
Rp412
sg403
g406
sbsS'Operator'
p413
g1
(g2
g3
(g413
tp414
tp415
Rp416
(dp417
g14
g29
sS'DBS'
p418
g1
(g2
g3
(g413
g418
tp419
tp420
Rp421
(dp422
g14
g416
sg15
g16
((lp423
tp424
Rp425
sbsg15
g16
((lp426
g421
ag1
(g2
g3
(g413
S'Word'
p427
tp428
tp429
Rp430
(dp431
g14
g416
sg15
g16
((lp432
tp433
Rp434
sbatp435
Rp436
sg427
g430
sbsg89
g92
sg189
g1
(g2
g3
(g189
tp437
tp438
Rp439
(dp440
S'Variable'
p441
g1
(g2
g3
(g189
g441
tp442
tp443
Rp444
(dp445
g14
g439
sS'Class'
p446
g1
(g2
g3
(g189
g441
g446
tp447
tp448
Rp449
(dp450
g14
g444
sg15
g16
((lp451
tp452
Rp453
sbsS'Anonymous'
p454
g1
(g2
g3
(g189
g441
g454
tp455
tp456
Rp457
(dp458
g14
g444
sg15
g16
((lp459
tp460
Rp461
sbsS'Instance'
p462
g1
(g2
g3
(g189
g441
g462
tp463
tp464
Rp465
(dp466
g14
g444
sg15
g16
((lp467
tp468
Rp469
sbsS'Global'
p470
g1
(g2
g3
(g189
g441
g470
tp471
tp472
Rp473
(dp474
g14
g444
sg15
g16
((lp475
tp476
Rp477
sbsg15
g16
((lp478
g457
ag465
ag1
(g2
g3
(g189
g441
S'Magic'
p479
tp480
tp481
Rp482
(dp483
g14
g444
sg15
g16
((lp484
tp485
Rp486
sbag473
ag449
atp487
Rp488
sg479
g482
sbsg413
g1
(g2
g3
(g189
g413
tp489
tp490
Rp491
(dp492
g14
g439
sg15
g16
((lp493
tp494
Rp495
sbsS'Decorator'
p496
g1
(g2
g3
(g189
g496
tp497
tp498
Rp499
(dp500
g14
g439
sg15
g16
((lp501
tp502
Rp503
sbsS'Entity'
p504
g1
(g2
g3
(g189
g504
tp505
tp506
Rp507
(dp508
g14
g439
sg418
g1
(g2
g3
(g189
g504
g418
tp509
tp510
Rp511
(dp512
g14
g507
sg15
g16
((lp513
tp514
Rp515
sbsg15
g16
((lp516
g511
atp517
Rp518
sbsg117
g1
(g2
g3
(g189
g117
tp519
tp520
Rp521
(dp522
g14
g439
sg15
g16
((lp523
tp524
Rp525
sbsS'Property'
p526
g1
(g2
g3
(g189
g526
tp527
tp528
Rp529
(dp530
g14
g439
sg15
g16
((lp531
tp532
Rp533
sbsS'Pseudo'
p534
g1
(g2
g3
(g189
g534
tp535
tp536
Rp537
(dp538
g14
g439
sg15
g16
((lp539
tp540
Rp541
sbsS'Type'
p542
g1
(g2
g3
(g189
g542
tp543
tp544
Rp545
(dp546
g14
g439
sg15
g16
((lp547
tp548
Rp549
sbsS'Classes'
p550
g1
(g2
g3
(g189
g550
tp551
tp552
Rp553
(dp554
g14
g439
sg15
g16
((lp555
tp556
Rp557
sbsS'Tag'
p558
g1
(g2
g3
(g189
g558
tp559
tp560
Rp561
(dp562
g14
g439
sg15
g16
((lp563
tp564
Rp565
sbsS'Constant'
p566
g1
(g2
g3
(g189
g566
tp567
tp568
Rp569
(dp570
g14
g439
sg15
g16
((lp571
tp572
Rp573
sbsS'Function'
p574
g1
(g2
g3
(g189
g574
tp575
tp576
Rp577
(dp578
g14
g439
sg15
g16
((lp579
g1
(g2
g3
(g189
g574
g479
tp580
tp581
Rp582
(dp583
g14
g577
sg15
g16
((lp584
tp585
Rp586
sbatp587
Rp588
sg479
g582
sbsS'Blubb'
p589
g1
(g2
g3
(g189
g589
tp590
tp591
Rp592
(dp593
g14
g439
sg15
g16
((lp594
tp595
Rp596
sbsS'Label'
p597
g1
(g2
g3
(g189
g597
tp598
tp599
Rp600
(dp601
g14
g439
sg15
g16
((lp602
tp603
Rp604
sbsS'Field'
p605
g1
(g2
g3
(g189
g605
tp606
tp607
Rp608
(dp609
g14
g439
sg15
g16
((lp610
tp611
Rp612
sbsS'Exception'
p613
g1
(g2
g3
(g189
g613
tp614
tp615
Rp616
(dp617
g14
g439
sg15
g16
((lp618
tp619
Rp620
sbsS'Namespace'
p621
g1
(g2
g3
(g189
g621
tp622
tp623
Rp624
(dp625
g14
g439
sg15
g16
((lp626
tp627
Rp628
sbsg15
g16
((lp629
g499
ag592
ag537
ag507
ag444
ag616
ag529
ag561
ag577
ag553
ag1
(g2
g3
(g189
g446
tp630
tp631
Rp632
(dp633
g14
g439
sg418
g1
(g2
g3
(g189
g446
g418
tp634
tp635
Rp636
(dp637
g14
g632
sg15
g16
((lp638
tp639
Rp640
sbsg15
g16
((lp641
g1
(g2
g3
(g189
g446
S'Start'
p642
tp643
tp644
Rp645
(dp646
g14
g632
sg15
g16
((lp647
tp648
Rp649
sbag636
atp650
Rp651
sg642
g645
sbag1
(g2
g3
(g189
g73
tp652
tp653
Rp654
(dp655
g14
g439
sS'Member'
p656
g1
(g2
g3
(g189
g73
g656
tp657
tp658
Rp659
(dp660
g14
g654
sg15
g16
((lp661
tp662
Rp663
sbsg15
g16
((lp664
g659
atp665
Rp666
sbag600
ag491
ag624
ag1
(g2
g3
(g189
S'Attribute'
p667
tp668
tp669
Rp670
(dp671
g14
g439
sg441
g1
(g2
g3
(g189
g667
g441
tp672
tp673
Rp674
(dp675
g14
g670
sg15
g16
((lp676
tp677
Rp678
sbsg15
g16
((lp679
g674
atp680
Rp681
sbag569
ag1
(g2
g3
(g189
S'Builtin'
p682
tp683
tp684
Rp685
(dp686
g14
g439
sg542
g1
(g2
g3
(g189
g682
g542
tp687
tp688
Rp689
(dp690
g14
g685
sg15
g16
((lp691
tp692
Rp693
sbsg15
g16
((lp694
g1
(g2
g3
(g189
g682
g534
tp695
tp696
Rp697
(dp698
g14
g685
sg15
g16
((lp699
tp700
Rp701
sbag689
atp702
Rp703
sg534
g697
sbag608
ag545
ag521
atp704
Rp705
sg14
g29
sg446
g632
sg682
g685
sg667
g670
sg73
g654
sbsS'Punctuation'
p706
g1
(g2
g3
(g706
tp707
tp708
Rp709
(dp710
g14
g29
sg15
g16
((lp711
g1
(g2
g3
(g706
S'Indicator'
p712
tp713
tp714
Rp715
(dp716
g14
g709
sg15
g16
((lp717
tp718
Rp719
sbatp720
Rp721
sg712
g715
sbsS'Comment'
p722
g1
(g2
g3
(g722
tp723
tp724
Rp725
(dp726
S'Multi'
p727
g1
(g2
g3
(g722
g727
tp728
tp729
Rp730
(dp731
g14
g725
sg15
g16
((lp732
tp733
Rp734
sbsg14
g29
sS'Special'
p735
g1
(g2
g3
(g722
g735
tp736
tp737
Rp738
(dp739
g14
g725
sg15
g16
((lp740
tp741
Rp742
sbsS'Hashbang'
p743
g1
(g2
g3
(g722
g743
tp744
tp745
Rp746
(dp747
g14
g725
sg15
g16
((lp748
tp749
Rp750
sbsS'Preproc'
p751
g1
(g2
g3
(g722
g751
tp752
tp753
Rp754
(dp755
g14
g725
sg15
g16
((lp756
tp757
Rp758
sbsg230
g1
(g2
g3
(g722
g230
tp759
tp760
Rp761
(dp762
g14
g725
sg15
g16
((lp763
tp764
Rp765
sbsS'Directive'
p766
g1
(g2
g3
(g722
g766
tp767
tp768
Rp769
(dp770
g14
g725
sg15
g16
((lp771
tp772
Rp773
sbsg222
g1
(g2
g3
(g722
g222
tp774
tp775
Rp776
(dp777
g14
g725
sg15
g16
((lp778
tp779
Rp780
sbsS'Singleline'
p781
g1
(g2
g3
(g722
g781
tp782
tp783
Rp784
(dp785
g14
g725
sg15
g16
((lp786
tp787
Rp788
sbsS'Multiline'
p789
g1
(g2
g3
(g722
g789
tp790
tp791
Rp792
(dp793
g14
g725
sg15
g16
((lp794
tp795
Rp796
sbsg15
g16
((lp797
g776
ag769
ag746
ag730
ag784
ag754
ag792
ag761
ag1
(g2
g3
(g722
S'PreprocFile'
p798
tp799
tp800
Rp801
(dp802
g14
g725
sg15
g16
((lp803
tp804
Rp805
sbag1
(g2
g3
(g722
S'SingleLine'
p806
tp807
tp808
Rp809
(dp810
g14
g725
sg15
g16
((lp811
tp812
Rp813
sbag738
atp814
Rp815
sg798
g801
sg806
g809
sbsg32
g55
sg73
g1
(g2
g3
(g73
tp816
tp817
Rp818
(dp819
g14
g29
sg15
g16
((lp820
tp821
Rp822
sbsg386
g1
(g2
g3
(g386
tp823
tp824
Rp825
(dp826
g14
g29
sg15
g16
((lp827
tp828
Rp829
sbsS'Token'
p830
g29
sg213
g1
(g2
g3
(g213
tp831
tp832
Rp833
(dp834
g14
g29
sg15
g16
((lp835
tp836
Rp837
sbsg15
g16
((lp838
g439
ag818
ag1
(g2
g3
(S'Keyword'
p839
tp840
tp841
Rp842
(dp843
g14
g29
sg542
g1
(g2
g3
(g839
g542
tp844
tp845
Rp846
(dp847
g14
g842
sg15
g16
((lp848
tp849
Rp850
sbsS'Control'
p851
g1
(g2
g3
(g839
g851
tp852
tp853
Rp854
(dp855
g14
g842
sg15
g16
((lp856
tp857
Rp858
sbsg566
g1
(g2
g3
(g839
g566
tp859
tp860
Rp861
(dp862
g14
g842
sg15
g16
((lp863
tp864
Rp865
sbsg621
g1
(g2
g3
(g839
g621
tp866
tp867
Rp868
(dp869
g14
g842
sg15
g16
((lp870
tp871
Rp872
sbsS'PreProc'
p873
g1
(g2
g3
(g839
g873
tp874
tp875
Rp876
(dp877
g14
g842
sg15
g16
((lp878
tp879
Rp880
sbsg534
g1
(g2
g3
(g839
g534
tp881
tp882
Rp883
(dp884
g14
g842
sg15
g16
((lp885
tp886
Rp887
sbsS'Reserved'
p888
g1
(g2
g3
(g839
g888
tp889
tp890
Rp891
(dp892
g14
g842
sg15
g16
((lp893
tp894
Rp895
sbsg15
g16
((lp896
g868
ag1
(g2
g3
(g839
g427
tp897
tp898
Rp899
(dp900
g14
g842
sg15
g16
((lp901
tp902
Rp903
sbag854
ag1
(g2
g3
(g839
S'Declaration'
p904
tp905
tp906
Rp907
(dp908
g14
g842
sg15
g16
((lp909
tp910
Rp911
sbag1
(g2
g3
(g839
g839
tp912
tp913
Rp914
(dp915
g14
g842
sg15
g16
((lp916
tp917
Rp918
sbag883
ag861
ag846
ag891
ag876
atp919
Rp920
sg839
g914
sg904
g907
sg427
g899
sbag328
ag7
ag416
ag833
ag709
ag725
ag825
ag55
atp921
Rp922
sg839
g842
sg4
g7
sbsS'Root'
p923
g1
(g2
g3
(g4
g923
tp924
tp925
Rp926
(dp927
g14
g7
sg15
g16
((lp928
tp929
Rp930
sbsg117
g1
(g2
g3
(g4
g117
tp931
tp932
Rp933
(dp934
g14
g7
sg15
g16
((lp935
tp936
Rp937
sbsg706
g1
(g2
g3
(g4
g706
tp938
tp939
Rp940
(dp941
g14
g7
sg15
g16
((lp942
tp943
Rp944
sbsg15
g16
((lp945
g926
ag933
ag940
ag23
ag12
ag1
(g2
g3
(g4
S'Rag'
p946
tp947
tp948
Rp949
(dp950
g14
g7
sg15
g16
((lp951
tp952
Rp953
sbatp954
Rp955
sg946
g949
sbV.. 
p956
tp957
a(g7
V-
p958
tp959
a(g7
V*
p960
tp961
a(g7
g958
tp962
a(g7
V mode: rst 
p963
tp964
a(g7
g958
tp965
a(g7
g960
tp966
a(g7
g958
tp967
a(g7
V\u000a\u000a
p968
tp969
a(g373
V{+
p970
tp971
a(g373
V.. highlight:: python
p972
tp973
a(g373
V+}
p974
tp975
a(g7
V\u000a\u000a====================\u000aWrite your own lexer\u000a====================\u000a\u000aIf a lexer for your favorite language is missing in the Pygments package, you\u000acan easily write your own and extend Pygments.\u000a\u000aAll you need can be found inside the :mod:`pygments.lexer` module.  As you can\u000aread in the :doc:`API documentation <api>`, a lexer is a class that is\u000ainitialized with some keyword arguments (the lexer options) and that provides a\u000a:meth:`.get_tokens_unprocessed()` method which is given a string or unicode\u000aobject with the data to 
p976
tp977
a(g333
V[-
p978
tp979
a(g333
Vparse.
p980
tp981
a(g333
V-]
p982
tp983
a(g7
V 
p984
tp985
a(g373
V{+
p986
tp987
a(g373
Vlex.
p988
tp989
a(g373
V+}
p990
tp991
a(g7
V\u000a\u000aThe :meth:`.get_tokens_unprocessed()` method must return an iterator or iterable\u000acontaining tuples in the form ``(index, token, value)``.  Normally you don't\u000aneed to do this since there are 
p992
tp993
a(g333
V[-
p994
tp995
a(g333
Vnumerous
p996
tp997
a(g333
V-]
p998
tp999
a(g7
V base lexers 
p1000
tp1001
a(g373
V{+
p1002
tp1003
a(g373
Vthat do most of the work and that
p1004
tp1005
a(g373
V+}
p1006
tp1007
a(g7
V\u000ayou can subclass.\u000a\u000a\u000aRegexLexer\u000a==========\u000a\u000a
p1008
tp1009
a(g333
V[-
p1010
tp1011
a(g333
VA very powerful (but quite easy to use)
p1012
tp1013
a(g333
V-]
p1014
tp1015
a(g7
V\u000a\u000a
p1016
tp1017
a(g373
V{+
p1018
tp1019
a(g373
VThe
p1020
tp1021
a(g373
V+}
p1022
tp1023
a(g7
V lexer 
p1024
tp1025
a(g373
V{+
p1026
tp1027
a(g373
Vbase class used by almost all of Pygments' lexers
p1028
tp1029
a(g373
V+}
p1030
tp1031
a(g7
V is the\u000a:class:`RegexLexer`.  This\u000a
p1032
tp1033
a(g333
V[-
p1034
tp1035
a(g333
Vlexer base
p1036
tp1037
a(g333
V-]
p1038
tp1039
a(g7
V class allows you to define lexing rules in terms of\u000a*regular expressions* for different *states*.\u000a\u000aStates are groups of regular expressions that are matched against the input\u000astring at the *current position*.  If one of these expressions matches, a\u000acorresponding action is performed 
p1040
tp1041
a(g333
V[-
p1042
tp1043
a(g333
V(normally
p1044
tp1045
a(g333
V-]
p1046
tp1047
a(g7
g984
tp1048
a(g373
V{+
p1049
tp1050
a(g373
V(such as
p1051
tp1052
a(g373
V+}
p1053
tp1054
a(g7
V yielding a token with a specific\u000a
p1055
tp1056
a(g333
V[-
p1057
tp1058
a(g333
Vtype),
p1059
tp1060
a(g333
V-]
p1061
tp1062
a(g7
V\u000a
p1063
tp1064
a(g373
V{+
p1065
tp1066
a(g373
Vtype, or changing state),
p1067
tp1068
a(g373
V+}
p1069
tp1070
a(g7
V the current position is set to where the last match\u000aended and the matching process continues with the first regex of the current\u000astate.\u000a\u000aLexer states are kept 
p1071
tp1072
a(g333
V[-
p1073
tp1074
a(g333
Vin
p1075
tp1076
a(g333
V-]
p1077
tp1078
a(g7
g984
tp1079
a(g373
V{+
p1080
tp1081
a(g373
Von
p1082
tp1083
a(g373
V+}
p1084
tp1085
a(g7
V a 
p1086
tp1087
a(g333
V[-
p1088
tp1089
a(g333
Vstate
p1090
tp1091
a(g333
V-]
p1092
tp1093
a(g7
V stack: each time a new state is entered, the new\u000astate is pushed onto the stack.  The most basic lexers (like the `DiffLexer`)\u000ajust need one state.\u000a\u000aEach state is defined as a list of tuples in the form (`regex`, `action`,\u000a`new_state`) where the last item is optional.  In the most basic form, `action`\u000ais a token type (like `Name.Builtin`).  That means: When `regex` matches, emit a\u000atoken with the match text and type `tokentype` and push `new_state` on the state\u000astack.  If the new state is ``'#pop'``, the topmost state is popped from the\u000astack instead. 
p1094
tp1095
a(g333
V[-
p1096
tp1097
a(g333
V(To
p1098
tp1099
a(g333
V-]
p1100
tp1101
a(g7
V  
p1102
tp1103
a(g373
V{+
p1104
tp1105
a(g373
VTo
p1106
tp1107
a(g373
V+}
p1108
tp1109
a(g7
V pop more than one state, use ``'#pop:2'`` and so 
p1110
tp1111
a(g333
V[-
p1112
tp1113
a(g333
Von.)
p1114
tp1115
a(g333
V-]
p1116
tp1117
a(g7
g984
tp1118
a(g373
V{+
p1119
tp1120
a(g373
Von.
p1121
tp1122
a(g373
V+}
p1123
tp1124
a(g7
V\u000a``'#push'`` is a synonym for pushing the current state on the stack.\u000a\u000aThe following example shows the `DiffLexer` from the builtin lexers.  Note that\u000ait contains some additional attributes `name`, `aliases` and `filenames` which\u000aaren't required for a lexer.  They are used by the builtin lexer lookup\u000afunctions.\u000a\u000a
p1125
tp1126
a(g333
V[-
p1127
tp1128
a(g333
V.. sourcecode:: python
p1129
tp1130
a(g333
V-]
p1131
tp1132
a(g7
g984
tp1133
a(g373
V{+
p1134
tp1135
a(g373
V::
p1136
tp1137
a(g373
V+}
p1138
tp1139
a(g7
V\u000a\u000a    from pygments.lexer import RegexLexer\u000a    from pygments.token import *\u000a\u000a    class DiffLexer(RegexLexer):\u000a        name = 'Diff'\u000a        aliases = 
p1140
tp1141
a(g7
V[
p1142
tp1143
a(g7
V'diff'
p1144
tp1145
a(g7
V]
p1146
tp1147
a(g7
V\u000a        filenames = 
p1148
tp1149
a(g7
g1142
tp1150
a(g7
V'*.diff'
p1151
tp1152
a(g7
g1146
tp1153
a(g7
V\u000a\u000a        tokens = 
p1154
tp1155
a(g7
V{
p1156
tp1157
a(g7
V\u000a            'root': 
p1158
tp1159
a(g7
g1142
tp1160
a(g7
V\u000a                (r' .*\u005cn', Text),\u000a                (r'\u005c
p1161
tp1162
a(g7
V+
p1163
tp1164
a(g7
V.*\u005cn', Generic.Inserted),\u000a                (r'
p1165
tp1166
a(g7
g958
tp1167
a(g7
V.*\u005cn', Generic.Deleted),\u000a                (r'@.*\u005cn', Generic.Subheading),\u000a                (r'Index.*\u005cn', Generic.Heading),\u000a                (r'=.*\u005cn', Generic.Heading),\u000a                (r'.*\u005cn', Text),\u000a            
p1168
tp1169
a(g7
g1146
tp1170
a(g7
V\u000a        
p1171
tp1172
a(g7
V}
p1173
tp1174
a(g7
V\u000a\u000aAs you can see this lexer only uses one state.  When the lexer starts scanning\u000athe text, it first checks if the current character is a space.  If this is true\u000ait scans everything until newline and returns the 
p1175
tp1176
a(g333
V[-
p1177
tp1178
a(g333
Vparsed
p1179
tp1180
a(g333
V-]
p1181
tp1182
a(g7
V data as 
p1183
tp1184
a(g373
V{+
p1185
tp1186
a(g373
Va
p1187
tp1188
a(g373
V+}
p1189
tp1190
a(g7
V `Text` 
p1191
tp1192
a(g333
V[-
p1193
tp1194
a(g333
Vtoken.
p1195
tp1196
a(g333
V-]
p1197
tp1198
a(g7
g984
tp1199
a(g373
V{+
p1200
tp1201
a(g373
Vtoken (which\u000ais the "no special highlighting" token).
p1202
tp1203
a(g373
V+}
p1204
tp1205
a(g7
V\u000a\u000aIf this rule doesn't match, it checks if the current char is a plus sign.  And\u000aso on.\u000a\u000aIf no rule matches at the current position, the current char is emitted as an\u000a`Error` token that indicates a 
p1206
tp1207
a(g333
V[-
p1208
tp1209
a(g333
Vparsing
p1210
tp1211
a(g333
V-]
p1212
tp1213
a(g7
g984
tp1214
a(g373
V{+
p1215
tp1216
a(g373
Vlexing
p1217
tp1218
a(g373
V+}
p1219
tp1220
a(g7
V error, and the position is increased by\u000a
p1221
tp1222
a(g333
V[-
p1223
tp1224
a(g333
V1.
p1225
tp1226
a(g333
V-]
p1227
tp1228
a(g7
V\u000a
p1229
tp1230
a(g373
V{+
p1231
tp1232
a(g373
Vone.
p1233
tp1234
a(g373
V+}
p1235
tp1236
a(g7
V\u000a\u000a\u000aAdding and testing a new lexer\u000a==============================\u000a\u000aTo make 
p1237
tp1238
a(g333
V[-
p1239
tp1240
a(g333
Vpygments
p1241
tp1242
a(g333
V-]
p1243
tp1244
a(g7
g984
tp1245
a(g373
V{+
p1246
tp1247
a(g373
VPygments
p1248
tp1249
a(g373
V+}
p1250
tp1251
a(g7
V aware of your new lexer, you have to perform the following\u000asteps:\u000a\u000aFirst, change to the current directory containing the 
p1252
tp1253
a(g333
V[-
p1254
tp1255
a(g333
Vpygments
p1256
tp1257
a(g333
V-]
p1258
tp1259
a(g7
g984
tp1260
a(g373
V{+
p1261
tp1262
a(g373
VPygments
p1263
tp1264
a(g373
V+}
p1265
tp1266
a(g7
V source code:\u000a\u000a.. 
p1267
tp1268
a(g333
V[-
p1269
tp1270
a(g333
Vsourcecode::
p1271
tp1272
a(g333
V-]
p1273
tp1274
a(g7
g984
tp1275
a(g373
V{+
p1276
tp1277
a(g373
Vcode
p1278
tp1279
a(g373
g958
tp1280
a(g373
Vblock::
p1281
tp1282
a(g373
V+}
p1283
tp1284
a(g7
V console\u000a\u000a    $ cd .../pygments
p1285
tp1286
a(g7
g958
tp1287
a(g7
Vmain\u000a\u000a
p1288
tp1289
a(g373
V{+
p1290
tp1291
a(g373
VSelect a matching module under ``pygments/lexers``, or create a new module for\u000ayour lexer class.
p1292
tp1293
a(g373
V+}
p1294
tp1295
a(g7
V\u000a\u000aNext, make sure the lexer is known from outside of the module.  All modules in\u000athe ``pygments.lexers`` specify ``__all__``. For example, 
p1296
tp1297
a(g333
V[-
p1298
tp1299
a(g333
V``other.py`` sets:\u000a\u000a.. sourcecode:: python
p1300
tp1301
a(g333
V-]
p1302
tp1303
a(g7
g984
tp1304
a(g373
V{+
p1305
tp1306
a(g373
V``esoteric.py`` sets::
p1307
tp1308
a(g373
V+}
p1309
tp1310
a(g7
V\u000a\u000a    __all__ = 
p1311
tp1312
a(g7
g1142
tp1313
a(g7
V'BrainfuckLexer', 'BefungeLexer', ...
p1314
tp1315
a(g7
g1146
tp1316
a(g7
V\u000a\u000aSimply add the name of your lexer class to this list.\u000a\u000aFinally the lexer can be made 
p1317
tp1318
a(g333
V[-
p1319
tp1320
a(g333
Vpublically
p1321
tp1322
a(g333
V-]
p1323
tp1324
a(g7
g984
tp1325
a(g373
V{+
p1326
tp1327
a(g373
Vpublicly
p1328
tp1329
a(g373
V+}
p1330
tp1331
a(g7
V known by rebuilding the lexer mapping:\u000a\u000a.. 
p1332
tp1333
a(g333
V[-
p1334
tp1335
a(g333
Vsourcecode::
p1336
tp1337
a(g333
V-]
p1338
tp1339
a(g7
g984
tp1340
a(g373
V{+
p1341
tp1342
a(g373
Vcode
p1343
tp1344
a(g373
g958
tp1345
a(g373
Vblock::
p1346
tp1347
a(g373
V+}
p1348
tp1349
a(g7
V console\u000a\u000a    $ make mapfiles\u000a\u000aTo test the new lexer, store an example file with the proper extension in\u000a``tests/examplefiles``.  For example, to test your ``DiffLexer``, add a\u000a``tests/examplefiles/example.diff`` containing a sample diff output.\u000a\u000aNow you can use pygmentize to render your example to HTML:\u000a\u000a.. 
p1350
tp1351
a(g333
V[-
p1352
tp1353
a(g333
Vsourcecode::
p1354
tp1355
a(g333
V-]
p1356
tp1357
a(g7
g984
tp1358
a(g373
V{+
p1359
tp1360
a(g373
Vcode
p1361
tp1362
a(g373
g958
tp1363
a(g373
Vblock::
p1364
tp1365
a(g373
V+}
p1366
tp1367
a(g7
V console\u000a\u000a    $ ./pygmentize 
p1368
tp1369
a(g7
g958
tp1370
a(g7
VO full 
p1371
tp1372
a(g7
g958
tp1373
a(g7
Vf html 
p1374
tp1375
a(g7
g958
tp1376
a(g7
Vo /tmp/example.html tests/examplefiles/example.diff\u000a\u000aNote that this 
p1377
tp1378
a(g333
V[-
p1379
tp1380
a(g333
Vexplicitely
p1381
tp1382
a(g333
V-]
p1383
tp1384
a(g7
g984
tp1385
a(g373
V{+
p1386
tp1387
a(g373
Vexplicitly
p1388
tp1389
a(g373
V+}
p1390
tp1391
a(g7
V calls the ``pygmentize`` in the current directory\u000aby preceding it with ``./``. This ensures your modifications are used.\u000aOtherwise a possibly already installed, unmodified version without your new\u000alexer would have been called from the system search path (``$PATH``).\u000a\u000aTo view the result, open ``/tmp/example.html`` in your browser.\u000a\u000aOnce the example renders as expected, you should run the complete test suite:\u000a\u000a.. 
p1392
tp1393
a(g333
V[-
p1394
tp1395
a(g333
Vsourcecode::
p1396
tp1397
a(g333
V-]
p1398
tp1399
a(g7
g984
tp1400
a(g373
V{+
p1401
tp1402
a(g373
Vcode
p1403
tp1404
a(g373
g958
tp1405
a(g373
Vblock::
p1406
tp1407
a(g373
V+}
p1408
tp1409
a(g7
V console\u000a\u000a    $ make test\u000a\u000a
p1410
tp1411
a(g373
V{+
p1412
tp1413
a(g373
VIt also tests that your lexer fulfills the lexer API and certain invariants,\u000asuch as that the concatenation of all token text is the same as the input text.
p1414
tp1415
a(g373
V+}
p1416
tp1417
a(g7
V\u000a\u000a\u000aRegex Flags\u000a===========\u000a\u000aYou can either define regex flags 
p1418
tp1419
a(g373
V{+
p1420
tp1421
a(g373
Vlocally
p1422
tp1423
a(g373
V+}
p1424
tp1425
a(g7
V in the regex (``r'(?x)foo bar'``) or\u000a
p1426
tp1427
a(g373
V{+
p1428
tp1429
a(g373
Vglobally
p1430
tp1431
a(g373
V+}
p1432
tp1433
a(g7
V by adding a `flags` attribute to your lexer class.  If no attribute is\u000adefined, it defaults to `re.MULTILINE`.  For more 
p1434
tp1435
a(g333
V[-
p1436
tp1437
a(g333
Vinformations
p1438
tp1439
a(g333
V-]
p1440
tp1441
a(g7
g984
tp1442
a(g373
V{+
p1443
tp1444
a(g373
Vinformation
p1445
tp1446
a(g373
V+}
p1447
tp1448
a(g7
V about regular\u000aexpression flags see the 
p1449
tp1450
a(g373
V{+
p1451
tp1452
a(g373
Vpage about
p1453
tp1454
a(g373
V+}
p1455
tp1456
a(g7
V `regular expressions`_ 
p1457
tp1458
a(g333
V[-
p1459
tp1460
a(g333
Vhelp page
p1461
tp1462
a(g333
V-]
p1463
tp1464
a(g7
V in the 
p1465
tp1466
a(g333
V[-
p1467
tp1468
a(g333
Vpython
p1469
tp1470
a(g333
V-]
p1471
tp1472
a(g7
g984
tp1473
a(g373
V{+
p1474
tp1475
a(g373
VPython
p1476
tp1477
a(g373
V+}
p1478
tp1479
a(g7
V\u000adocumentation.\u000a\u000a.. _regular expressions: 
p1480
tp1481
a(g333
V[-
p1482
tp1483
a(g333
Vhttp://docs.python.org/lib/re
p1484
tp1485
a(g333
g958
tp1486
a(g333
Vsyntax.html
p1487
tp1488
a(g333
V-]
p1489
tp1490
a(g7
g984
tp1491
a(g373
V{+
p1492
tp1493
a(g373
Vhttp://docs.python.org/library/re.html#regular
p1494
tp1495
a(g373
g958
tp1496
a(g373
Vexpression
p1497
tp1498
a(g373
g958
tp1499
a(g373
Vsyntax
p1500
tp1501
a(g373
V+}
p1502
tp1503
a(g7
V\u000a\u000a\u000aScanning multiple tokens at once\u000a================================\u000a\u000a
p1504
tp1505
a(g373
V{+
p1506
tp1507
a(g373
VSo far, the `action` element in the rule tuple of regex, action and state has\u000abeen a single token type.  Now we look at the first of several other possible\u000avalues.
p1508
tp1509
a(g373
V+}
p1510
tp1511
a(g7
V\u000a\u000aHere is a more complex lexer that highlights INI files.  INI files consist of\u000asections, comments and 
p1512
tp1513
a(g333
V[-
p1514
tp1515
a(g333
Vkey
p1516
tp1517
a(g333
V-]
p1518
tp1519
a(g7
g984
tp1520
a(g373
V{+
p1521
tp1522
a(g373
V``key
p1523
tp1524
a(g373
V+}
p1525
tp1526
a(g7
V = 
p1527
tp1528
a(g333
V[-
p1529
tp1530
a(g333
Vvalue pairs:\u000a\u000a.. sourcecode:: python
p1531
tp1532
a(g333
V-]
p1533
tp1534
a(g7
g984
tp1535
a(g373
V{+
p1536
tp1537
a(g373
Vvalue`` pairs::
p1538
tp1539
a(g373
V+}
p1540
tp1541
a(g7
V\u000a\u000a    from pygments.lexer import RegexLexer, bygroups\u000a    from pygments.token import *\u000a\u000a    class IniLexer(RegexLexer):\u000a        name = 'INI'\u000a        aliases = 
p1542
tp1543
a(g7
g1142
tp1544
a(g7
V'ini', 'cfg'
p1545
tp1546
a(g7
g1146
tp1547
a(g7
V\u000a        filenames = 
p1548
tp1549
a(g7
g1142
tp1550
a(g7
V'*.ini', '*.cfg'
p1551
tp1552
a(g7
g1146
tp1553
a(g7
V\u000a\u000a        tokens = 
p1554
tp1555
a(g7
g1156
tp1556
a(g7
V\u000a            'root': 
p1557
tp1558
a(g7
g1142
tp1559
a(g7
V\u000a                (r'\u005cs
p1560
tp1561
a(g7
g1163
tp1562
a(g7
V', Text),\u000a                (r';.*?$', Comment),\u000a                (r'\u005c
p1563
tp1564
a(g7
g1142
tp1565
a(g7
V.*?\u005c
p1566
tp1567
a(g7
g1146
tp1568
a(g7
V$', Keyword),\u000a                (r'(.*?)(\u005cs*)(=)(\u005cs*)(.*?)$',\u000a                 bygroups(Name.Attribute, Text, Operator, Text, String))\u000a            
p1569
tp1570
a(g7
g1146
tp1571
a(g7
V\u000a        
p1572
tp1573
a(g7
g1173
tp1574
a(g7
V\u000a\u000aThe lexer first looks for whitespace, comments and section names. 
p1575
tp1576
a(g333
V[-
p1577
tp1578
a(g333
VAnd later
p1579
tp1580
a(g333
V-]
p1581
tp1582
a(g7
V  
p1583
tp1584
a(g373
V{+
p1585
tp1586
a(g373
VLater
p1587
tp1588
a(g373
V+}
p1589
tp1590
a(g7
V it\u000alooks for a line that looks like a key, value pair, separated by an ``'='``\u000asign, and optional whitespace.\u000a\u000aThe `bygroups` helper 
p1591
tp1592
a(g333
V[-
p1593
tp1594
a(g333
Vmakes sure that
p1595
tp1596
a(g333
V-]
p1597
tp1598
a(g7
g984
tp1599
a(g373
V{+
p1600
tp1601
a(g373
Vyields
p1602
tp1603
a(g373
V+}
p1604
tp1605
a(g7
V each 
p1606
tp1607
a(g373
V{+
p1608
tp1609
a(g373
Vcapturing
p1610
tp1611
a(g373
V+}
p1612
tp1613
a(g7
V group 
p1614
tp1615
a(g333
V[-
p1616
tp1617
a(g333
Vis yielded
p1618
tp1619
a(g333
V-]
p1620
tp1621
a(g7
g984
tp1622
a(g373
V{+
p1623
tp1624
a(g373
Vin the regex
p1625
tp1626
a(g373
V+}
p1627
tp1628
a(g7
V with a different\u000atoken type.  First the `Name.Attribute` token, then a `Text` token for the\u000aoptional whitespace, after that a `Operator` token for the equals sign. Then a\u000a`Text` token for the whitespace again.  The rest of the line is returned as\u000a`String`.\u000a\u000aNote that for this to work, every part of the match must be inside a capturing\u000agroup (a ``(...)``), and there must not be any nested capturing groups.  If you\u000anevertheless need a group, use a non
p1629
tp1630
a(g7
g958
tp1631
a(g7
Vcapturing group defined using this syntax:\u000a
p1632
tp1633
a(g333
V[-
p1634
tp1635
a(g333
V``r'(?:some|words|here)'``
p1636
tp1637
a(g333
V-]
p1638
tp1639
a(g7
V\u000a
p1640
tp1641
a(g373
V{+
p1642
tp1643
a(g373
V``(?:some|words|here)``
p1644
tp1645
a(g373
V+}
p1646
tp1647
a(g7
V (note the ``?:`` after the beginning parenthesis).\u000a\u000aIf you find yourself needing a capturing group inside the regex which shouldn't\u000abe part of the output but is used in the regular expressions for backreferencing\u000a(eg: ``r'(<(foo|bar)>)(.*?)(</\u005c2>)'``), you can pass `None` to the bygroups\u000afunction and 
p1648
tp1649
a(g333
V[-
p1650
tp1651
a(g333
Vit will skip
p1652
tp1653
a(g333
V-]
p1654
tp1655
a(g7
V that group will be skipped in the output.\u000a\u000a\u000aChanging states\u000a===============\u000a\u000aMany lexers need multiple states to work as expected.  For example, some\u000alanguages allow multiline comments to be nested.  Since this is a recursive\u000apattern it's impossible to lex just using regular expressions.\u000a\u000aHere is 
p1656
tp1657
a(g333
V[-
p1658
tp1659
a(g333
Vthe solution:\u000a\u000a.. sourcecode:: python
p1660
tp1661
a(g333
V-]
p1662
tp1663
a(g7
g984
tp1664
a(g373
V{+
p1665
tp1666
a(g373
Va lexer that recognizes C
p1667
tp1668
a(g373
g1163
tp1669
a(g373
g1163
tp1670
a(g373
V style comments (multi
p1671
tp1672
a(g373
g958
tp1673
a(g373
Vline with ``/* */``\u000aand single
p1674
tp1675
a(g373
g958
tp1676
a(g373
Vline with ``//`` until end of line)::
p1677
tp1678
a(g373
V+}
p1679
tp1680
a(g7
V\u000a\u000a    from pygments.lexer import RegexLexer\u000a    from pygments.token import *\u000a\u000a    class 
p1681
tp1682
a(g333
V[-
p1683
tp1684
a(g333
VExampleLexer(RegexLexer):
p1685
tp1686
a(g333
V-]
p1687
tp1688
a(g7
g984
tp1689
a(g373
V{+
p1690
tp1691
a(g373
VCppCommentLexer(RegexLexer):
p1692
tp1693
a(g373
V+}
p1694
tp1695
a(g7
V\u000a        name = 'Example Lexer with states'\u000a\u000a        tokens = 
p1696
tp1697
a(g7
g1156
tp1698
a(g7
V\u000a            'root': 
p1699
tp1700
a(g7
g1142
tp1701
a(g7
V\u000a                (r'
p1702
tp1703
a(g7
g1142
tp1704
a(g7
V^/
p1705
tp1706
a(g7
g1146
tp1707
a(g7
g1163
tp1708
a(g7
V', Text),\u000a                (r'/\u005c*', Comment.Multiline, 'comment'),\u000a                (r'//.*?$', Comment.Singleline),\u000a                (r'/', Text)\u000a            
p1709
tp1710
a(g7
g1146
tp1711
a(g7
V,\u000a            'comment': 
p1712
tp1713
a(g7
g1142
tp1714
a(g7
V\u000a                (r'
p1715
tp1716
a(g7
g1142
tp1717
a(g7
V^*/
p1718
tp1719
a(g7
g1146
tp1720
a(g7
V', Comment.Multiline),\u000a                (r'/\u005c*', Comment.Multiline, '#push'),\u000a                (r'\u005c*/', Comment.Multiline, '#pop'),\u000a                (r'
p1721
tp1722
a(g7
g1142
tp1723
a(g7
V*/
p1724
tp1725
a(g7
g1146
tp1726
a(g7
V', Comment.Multiline)\u000a            
p1727
tp1728
a(g7
g1146
tp1729
a(g7
V\u000a        
p1730
tp1731
a(g7
g1173
tp1732
a(g7
V\u000a\u000aThis lexer starts lexing in the ``'root'`` state. It tries to match as much as\u000apossible until it finds a slash (``'/'``).  If the next character after the slash\u000ais 
p1733
tp1734
a(g333
V[-
p1735
tp1736
a(g333
Va star
p1737
tp1738
a(g333
V-]
p1739
tp1740
a(g7
g984
tp1741
a(g373
V{+
p1742
tp1743
a(g373
Van asterisk
p1744
tp1745
a(g373
V+}
p1746
tp1747
a(g7
V (``'*'``) the `RegexLexer` sends those two characters to the\u000aoutput stream marked as `Comment.Multiline` and continues 
p1748
tp1749
a(g333
V[-
p1750
tp1751
a(g333
Vparsing
p1752
tp1753
a(g333
V-]
p1754
tp1755
a(g7
g984
tp1756
a(g373
V{+
p1757
tp1758
a(g373
Vlexing
p1759
tp1760
a(g373
V+}
p1761
tp1762
a(g7
V with the rules\u000adefined in the ``'comment'`` state.\u000a\u000aIf there wasn't 
p1763
tp1764
a(g333
V[-
p1765
tp1766
a(g333
Va star
p1767
tp1768
a(g333
V-]
p1769
tp1770
a(g7
g984
tp1771
a(g373
V{+
p1772
tp1773
a(g373
Van asterisk
p1774
tp1775
a(g373
V+}
p1776
tp1777
a(g7
V after the slash, the `RegexLexer` checks if it's a\u000a
p1778
tp1779
a(g333
V[-
p1780
tp1781
a(g333
Vsingleline
p1782
tp1783
a(g333
V-]
p1784
tp1785
a(g7
V\u000a
p1786
tp1787
a(g373
V{+
p1788
tp1789
a(g373
VSingleline
p1790
tp1791
a(g373
V+}
p1792
tp1793
a(g7
V comment 
p1794
tp1795
a(g333
V[-
p1796
tp1797
a(g333
V(eg:
p1798
tp1799
a(g333
V-]
p1800
tp1801
a(g7
g984
tp1802
a(g373
V{+
p1803
tp1804
a(g373
V(i.e.
p1805
tp1806
a(g373
V+}
p1807
tp1808
a(g7
V followed by a second slash).  If this also wasn't the\u000acase it must be a single 
p1809
tp1810
a(g333
V[-
p1811
tp1812
a(g333
Vslash
p1813
tp1814
a(g333
V-]
p1815
tp1816
a(g7
g984
tp1817
a(g373
V{+
p1818
tp1819
a(g373
Vslash, which is not a comment starter
p1820
tp1821
a(g373
V+}
p1822
tp1823
a(g7
V (the separate\u000aregex for a single slash must also be given, else the slash would be marked as\u000aan error token).\u000a\u000aInside the ``'comment'`` state, we do the same thing again.  Scan until the\u000alexer finds a star or slash.  If it's the opening of a multiline comment, push\u000athe ``'comment'`` state on the stack and continue scanning, again in the\u000a``'comment'`` state.  Else, check if it's the end of the multiline comment.  If\u000ayes, pop one state from the stack.\u000a\u000aNote: If you pop from an empty stack you'll get an `IndexError`.  (There is an\u000aeasy way to prevent this from happening: don't ``'#pop'`` in the root state).\u000a\u000aIf the `RegexLexer` encounters a newline that is flagged as an error token, the\u000astack is emptied and the lexer continues scanning in the ``'root'`` state.  This\u000a
p1824
tp1825
a(g333
V[-
p1826
tp1827
a(g333
Vhelps
p1828
tp1829
a(g333
V-]
p1830
tp1831
a(g7
V\u000a
p1832
tp1833
a(g373
V{+
p1834
tp1835
a(g373
Vcan help
p1836
tp1837
a(g373
V+}
p1838
tp1839
a(g7
V producing error
p1840
tp1841
a(g7
g958
tp1842
a(g7
Vtolerant highlighting for erroneous input, e.g. when a\u000asingle
p1843
tp1844
a(g7
g958
tp1845
a(g7
Vline string is not closed.\u000a\u000a\u000aAdvanced state tricks\u000a=====================\u000a\u000aThere are a few more things you can do with states:\u000a\u000a
p1846
tp1847
a(g7
g958
tp1848
a(g7
V You can push multiple states onto the stack if you give a tuple instead of a\u000a  simple string as the third item in a rule tuple.  For example, if you want to\u000a  match a comment containing a directive, something 
p1849
tp1850
a(g333
V[-
p1851
tp1852
a(g333
Vlike::
p1853
tp1854
a(g333
V-]
p1855
tp1856
a(g7
g984
tp1857
a(g373
V{+
p1858
tp1859
a(g373
Vlike:\u000a\u000a  .. code
p1860
tp1861
a(g373
g958
tp1862
a(g373
Vblock:: text
p1863
tp1864
a(g373
V+}
p1865
tp1866
a(g7
V\u000a\u000a      /* <processing directive>    rest of comment */\u000a\u000a  you can use this 
p1867
tp1868
a(g333
V[-
p1869
tp1870
a(g333
Vrule:\u000a\u000a  .. sourcecode:: python
p1871
tp1872
a(g333
V-]
p1873
tp1874
a(g7
g984
tp1875
a(g373
V{+
p1876
tp1877
a(g373
Vrule::
p1878
tp1879
a(g373
V+}
p1880
tp1881
a(g7
V\u000a\u000a      tokens = 
p1882
tp1883
a(g7
g1156
tp1884
a(g7
V\u000a          'root': 
p1885
tp1886
a(g7
g1142
tp1887
a(g7
V\u000a              (r'/\u005c* <', Comment, ('comment', 'directive')),\u000a              ...\u000a          
p1888
tp1889
a(g7
g1146
tp1890
a(g7
V,\u000a          'directive': 
p1891
tp1892
a(g7
g1142
tp1893
a(g7
V\u000a              (r'
p1894
tp1895
a(g7
g1142
tp1896
a(g7
V^>
p1897
tp1898
a(g7
g1146
tp1899
a(g7
V*', Comment.Directive),\u000a              (r'>', Comment, '#pop'),\u000a          
p1900
tp1901
a(g7
g1146
tp1902
a(g7
V,\u000a          'comment': 
p1903
tp1904
a(g7
g1142
tp1905
a(g7
V\u000a              (r'
p1906
tp1907
a(g7
g1142
tp1908
a(g7
V^*
p1909
tp1910
a(g7
g1146
tp1911
a(g7
g1163
tp1912
a(g7
V', Comment),\u000a              (r'\u005c*/', Comment, '#pop'),\u000a              (r'\u005c*', Comment),\u000a          
p1913
tp1914
a(g7
g1146
tp1915
a(g7
V\u000a      
p1916
tp1917
a(g7
g1173
tp1918
a(g7
V\u000a\u000a  When this encounters the above sample, first ``'comment'`` and ``'directive'``\u000a  are pushed onto the stack, then the lexer continues in the directive state\u000a  until it finds the closing ``>``, then it continues in the comment state until\u000a  the closing ``*/``.  Then, both states are popped from the stack again and\u000a  lexing continues in the root state.\u000a\u000a  .. versionadded:: 0.9\u000a     The tuple can contain the special ``'#push'`` and ``'#pop'`` (but not\u000a     ``'#pop:n'``) directives.\u000a\u000a\u000a
p1919
tp1920
a(g7
g958
tp1921
a(g7
V You can include the rules of a state in the definition of another.  This is\u000a  done by using `include` from 
p1922
tp1923
a(g333
V[-
p1924
tp1925
a(g333
V`pygments.lexer`:\u000a\u000a  .. sourcecode:: python
p1926
tp1927
a(g333
V-]
p1928
tp1929
a(g7
g984
tp1930
a(g373
V{+
p1931
tp1932
a(g373
V`pygments.lexer`::
p1933
tp1934
a(g373
V+}
p1935
tp1936
a(g7
V\u000a\u000a      from pygments.lexer import RegexLexer, bygroups, include\u000a      from pygments.token import *\u000a\u000a      class ExampleLexer(RegexLexer):\u000a          tokens = 
p1937
tp1938
a(g7
g1156
tp1939
a(g7
V\u000a              'comments': 
p1940
tp1941
a(g7
g1142
tp1942
a(g7
V\u000a                  (r'/\u005c*.*?\u005c*/', Comment),\u000a                  (r'//.*?\u005cn', Comment),\u000a              
p1943
tp1944
a(g7
g1146
tp1945
a(g7
V,\u000a              'root': 
p1946
tp1947
a(g7
g1142
tp1948
a(g7
V\u000a                  include('comments'),\u000a                  (r'(function )(\u005cw
p1949
tp1950
a(g7
g1163
tp1951
a(g7
V)( 
p1952
tp1953
a(g7
g1156
tp1954
a(g7
V)',\u000a                   bygroups(Keyword, Name, Keyword), 'function'),\u000a                  (r'.', Text),\u000a              
p1955
tp1956
a(g7
g1146
tp1957
a(g7
V,\u000a              'function': 
p1958
tp1959
a(g7
g1142
tp1960
a(g7
V\u000a                  (r'
p1961
tp1962
a(g7
g1142
tp1963
a(g7
V^
p1964
tp1965
a(g7
g1173
tp1966
a(g7
V/
p1967
tp1968
a(g7
g1146
tp1969
a(g7
g1163
tp1970
a(g7
V', Text),\u000a                  include('comments'),\u000a                  (r'/', Text),\u000a                  
p1971
tp1972
a(g333
V[-
p1973
tp1974
a(g333
V(r'
p1975
tp1976
a(g333
g1173
tp1977
a(g333
V',
p1978
tp1979
a(g333
V-]
p1980
tp1981
a(g7
V\u000a                  
p1982
tp1983
a(g373
V{+
p1984
tp1985
a(g373
V(r'\u005c
p1986
tp1987
a(g373
g1173
tp1988
a(g373
V',
p1989
tp1990
a(g373
V+}
p1991
tp1992
a(g7
V Keyword, '#pop'),\u000a              
p1993
tp1994
a(g7
g1146
tp1995
a(g7
V\u000a          
p1996
tp1997
a(g7
g1173
tp1998
a(g7
V\u000a\u000a  This is a hypothetical lexer for a language that consist of functions and\u000a  comments.  Because comments can occur at toplevel and in functions, we need\u000a  rules for comments in both states.  As you can see, the `include` helper saves\u000a  repeating rules that occur more than once (in this example, the state\u000a  ``'comment'`` will never be entered by the lexer, as it's only there to be\u000a  included in ``'root'`` and ``'function'``).\u000a\u000a
p1999
tp2000
a(g7
g958
tp2001
a(g7
V Sometimes, you may want to "combine" a state from existing ones.  This is\u000a  possible with the 
p2002
tp2003
a(g333
V[-
p2004
tp2005
a(g333
V`combine`
p2006
tp2007
a(g333
V-]
p2008
tp2009
a(g7
g984
tp2010
a(g373
V{+
p2011
tp2012
a(g373
V`combined`
p2013
tp2014
a(g373
V+}
p2015
tp2016
a(g7
V helper from `pygments.lexer`.\u000a\u000a  If you, instead of a new state, write ``combined('state1', 'state2')`` as the\u000a  third item of a rule tuple, a new anonymous state will be formed from state1\u000a  and state2 and if the rule matches, the lexer will enter this state.\u000a\u000a  This is not used very often, but can be helpful in some cases, such as the\u000a  `PythonLexer`'s string literal processing.\u000a\u000a
p2017
tp2018
a(g7
g958
tp2019
a(g7
V If you want your lexer to start lexing in a different state you can modify the\u000a  stack by 
p2020
tp2021
a(g333
V[-
p2022
tp2023
a(g333
Voverloading
p2024
tp2025
a(g333
V-]
p2026
tp2027
a(g7
g984
tp2028
a(g373
V{+
p2029
tp2030
a(g373
Voverriding
p2031
tp2032
a(g373
V+}
p2033
tp2034
a(g7
V the `get_tokens_unprocessed()` 
p2035
tp2036
a(g333
V[-
p2037
tp2038
a(g333
Vmethod:\u000a\u000a  .. sourcecode:: python
p2039
tp2040
a(g333
V-]
p2041
tp2042
a(g7
g984
tp2043
a(g373
V{+
p2044
tp2045
a(g373
Vmethod::
p2046
tp2047
a(g373
V+}
p2048
tp2049
a(g7
V\u000a\u000a      from pygments.lexer import RegexLexer\u000a\u000a      class 
p2050
tp2051
a(g333
V[-
p2052
tp2053
a(g333
VMyLexer(RegexLexer):
p2054
tp2055
a(g333
V-]
p2056
tp2057
a(g7
g984
tp2058
a(g373
V{+
p2059
tp2060
a(g373
VExampleLexer(RegexLexer):
p2061
tp2062
a(g373
V+}
p2063
tp2064
a(g7
V\u000a          tokens = 
p2065
tp2066
a(g7
g1156
tp2067
a(g7
V...
p2068
tp2069
a(g7
g1173
tp2070
a(g7
V\u000a\u000a          def get_tokens_unprocessed(self, 
p2071
tp2072
a(g333
V[-
p2073
tp2074
a(g333
Vtext):\u000a              stack = 
p2075
tp2076
a(g333
g1142
tp2077
a(g333
V'root', 'otherstate'
p2078
tp2079
a(g333
g1146
tp2080
a(g333
V-]
p2081
tp2082
a(g7
g984
tp2083
a(g373
V{+
p2084
tp2085
a(g373
Vtext, stack=('root', 'otherstate')):
p2086
tp2087
a(g373
V+}
p2088
tp2089
a(g7
V\u000a              for item in RegexLexer.get_tokens_unprocessed(text, stack):\u000a                  yield item\u000a\u000a  Some lexers like the `PhpLexer` use this to make the leading ``<?php``\u000a  preprocessor comments optional.  Note that you can crash the lexer easily by\u000a  putting values into the stack that don't exist in the token map.  Also\u000a  removing ``'root'`` from the stack can result in strange errors!\u000a\u000a
p2090
tp2091
a(g7
g958
tp2092
a(g7
g984
tp2093
a(g333
V[-
p2094
tp2095
a(g333
VAn
p2096
tp2097
a(g333
V-]
p2098
tp2099
a(g7
g984
tp2100
a(g373
V{+
p2101
tp2102
a(g373
VIn some lexers, a state should be popped if anything is encountered that isn't\u000a  matched by a rule in the state.  You could use an
p2103
tp2104
a(g373
V+}
p2105
tp2106
a(g7
V empty regex at the end of 
p2107
tp2108
a(g333
V[-
p2109
tp2110
a(g333
g1187
tp2111
a(g333
V-]
p2112
tp2113
a(g7
V\u000a  
p2114
tp2115
a(g373
V{+
p2116
tp2117
a(g373
Vthe
p2118
tp2119
a(g373
V+}
p2120
tp2121
a(g7
V state list, 
p2122
tp2123
a(g333
V[-
p2124
tp2125
a(g333
Vcombined with ``'#pop'``, can\u000a  act as
p2126
tp2127
a(g333
V-]
p2128
tp2129
a(g7
g984
tp2130
a(g373
V{+
p2131
tp2132
a(g373
Vbut Pygments provides
p2133
tp2134
a(g373
V+}
p2135
tp2136
a(g7
V a 
p2137
tp2138
a(g333
V[-
p2139
tp2140
a(g333
Vreturn point
p2141
tp2142
a(g333
V-]
p2143
tp2144
a(g7
g984
tp2145
a(g373
V{+
p2146
tp2147
a(g373
Vmore obvious way of spelling that:\u000a  ``default('#pop')`` is equivalent to ``('', Text, '#pop')``.\u000a\u000a  .. versionadded:: 2.0\u000a\u000a\u000aSubclassing lexers derived
p2148
tp2149
a(g373
V+}
p2150
tp2151
a(g7
V from 
p2152
tp2153
a(g373
V{+
p2154
tp2155
a(g373
VRegexLexer\u000a==========================================\u000a\u000a.. versionadded:: 1.6\u000a\u000aSometimes multiple languages are very similar, but should still be lexed by\u000adifferent lexer classes.\u000a\u000aWhen subclassing
p2156
tp2157
a(g373
V+}
p2158
tp2159
a(g7
V a 
p2160
tp2161
a(g373
V{+
p2162
tp2163
a(g373
Vlexer derived from RegexLexer, the ``tokens`` dictionaries\u000adefined in the parent and child class are merged.  For example::\u000a\u000a      from pygments.lexer import RegexLexer, inherit\u000a      from pygments.token import *\u000a\u000a      class BaseLexer(RegexLexer):\u000a          tokens = 
p2164
tp2165
a(g373
g1156
tp2166
a(g373
V\u000a              'root': 
p2167
tp2168
a(g373
g1142
tp2169
a(g373
V\u000a                  ('
p2170
tp2171
a(g373
g1142
tp2172
a(g373
g1187
tp2173
a(g373
g958
tp2174
a(g373
Vz
p2175
tp2176
a(g373
g1146
tp2177
a(g373
g1163
tp2178
a(g373
V', Name),\u000a                  (r'/\u005c*', Comment, 'comment'),\u000a                  ('"', String, 'string'),\u000a                  ('\u005cs
p2179
tp2180
a(g373
g1163
tp2181
a(g373
V', Text),\u000a              
p2182
tp2183
a(g373
g1146
tp2184
a(g373
V,\u000a              'string': 
p2185
tp2186
a(g373
g1142
tp2187
a(g373
V\u000a                  ('
p2188
tp2189
a(g373
g1142
tp2190
a(g373
V^"
p2191
tp2192
a(g373
g1146
tp2193
a(g373
g1163
tp2194
a(g373
V', String),\u000a                  ('"', String, '#pop'),\u000a              
p2195
tp2196
a(g373
g1146
tp2197
a(g373
V,\u000a              'comment': 
p2198
tp2199
a(g373
g1142
tp2200
a(g373
V\u000a                  ...\u000a              
p2201
tp2202
a(g373
g1146
tp2203
a(g373
V,\u000a          
p2204
tp2205
a(g373
g1173
tp2206
a(g373
V\u000a\u000a      class DerivedLexer(BaseLexer):\u000a          tokens = 
p2207
tp2208
a(g373
g1156
tp2209
a(g373
V\u000a              'root': 
p2210
tp2211
a(g373
g1142
tp2212
a(g373
V\u000a                  ('
p2213
tp2214
a(g373
g1142
tp2215
a(g373
V0
p2216
tp2217
a(g373
g958
tp2218
a(g373
V9
p2219
tp2220
a(g373
g1146
tp2221
a(g373
g1163
tp2222
a(g373
V', Number),\u000a                  inherit,\u000a              
p2223
tp2224
a(g373
g1146
tp2225
a(g373
V,\u000a              'string': 
p2226
tp2227
a(g373
g1142
tp2228
a(g373
V\u000a                  (r'
p2229
tp2230
a(g373
g1142
tp2231
a(g373
V^"\u005c\u005c
p2232
tp2233
a(g373
g1146
tp2234
a(g373
g1163
tp2235
a(g373
V', String),\u000a                  (r'\u005c\u005c.', String.Escape),\u000a                  ('"', String, '#pop'),\u000a              
p2236
tp2237
a(g373
g1146
tp2238
a(g373
V,\u000a          
p2239
tp2240
a(g373
g1173
tp2241
a(g373
V\u000a\u000aThe `BaseLexer` defines two states, lexing names and strings.  The\u000a`DerivedLexer` defines its own tokens dictionary, which extends the definitions\u000aof the base lexer:\u000a\u000a* The "root"
p2242
tp2243
a(g373
V+}
p2244
tp2245
a(g7
V state 
p2246
tp2247
a(g373
V{+
p2248
tp2249
a(g373
Vhas an additional rule and then the special object `inherit`,\u000a  which tells Pygments to insert the token definitions of the parent class at
p2250
tp2251
a(g373
V+}
p2252
tp2253
a(g7
V\u000a  that 
p2254
tp2255
a(g333
V[-
p2256
tp2257
a(g333
Vdoesn't have a clear end marker.
p2258
tp2259
a(g333
V-]
p2260
tp2261
a(g7
g984
tp2262
a(g373
V{+
p2263
tp2264
a(g373
Vpoint.\u000a\u000a* The "string" state is replaced entirely, since there is not `inherit` rule.\u000a\u000a* The "comment" state is inherited entirely.
p2265
tp2266
a(g373
V+}
p2267
tp2268
a(g7
V\u000a\u000a\u000aUsing multiple lexers\u000a=====================\u000a\u000aUsing multiple lexers for the same input can be tricky.  One of the easiest\u000acombination techniques is shown here: You can replace the 
p2269
tp2270
a(g333
V[-
p2271
tp2272
a(g333
Vtoken type
p2273
tp2274
a(g333
V-]
p2275
tp2276
a(g7
g984
tp2277
a(g373
V{+
p2278
tp2279
a(g373
Vaction
p2280
tp2281
a(g373
V+}
p2282
tp2283
a(g7
V entry in a rule\u000atuple 
p2284
tp2285
a(g333
V[-
p2286
tp2287
a(g333
V(the second item)
p2288
tp2289
a(g333
V-]
p2290
tp2291
a(g7
V with a lexer class.  The matched text will then be lexed with that lexer,\u000aand the resulting tokens will be yielded.\u000a\u000aFor example, look at this stripped
p2292
tp2293
a(g7
g958
tp2294
a(g7
Vdown HTML 
p2295
tp2296
a(g333
V[-
p2297
tp2298
a(g333
Vlexer:\u000a\u000a.. sourcecode:: python
p2299
tp2300
a(g333
V-]
p2301
tp2302
a(g7
g984
tp2303
a(g373
V{+
p2304
tp2305
a(g373
Vlexer::
p2306
tp2307
a(g373
V+}
p2308
tp2309
a(g7
V\u000a\u000a    from pygments.lexer import RegexLexer, bygroups, using\u000a    from pygments.token import *\u000a    from 
p2310
tp2311
a(g333
V[-
p2312
tp2313
a(g333
Vpygments.lexers.web
p2314
tp2315
a(g333
V-]
p2316
tp2317
a(g7
g984
tp2318
a(g373
V{+
p2319
tp2320
a(g373
Vpygments.lexers.javascript
p2321
tp2322
a(g373
V+}
p2323
tp2324
a(g7
V import JavascriptLexer\u000a\u000a    class HtmlLexer(RegexLexer):\u000a        name = 'HTML'\u000a        aliases = 
p2325
tp2326
a(g7
g1142
tp2327
a(g7
V'html'
p2328
tp2329
a(g7
g1146
tp2330
a(g7
V\u000a        filenames = 
p2331
tp2332
a(g7
g1142
tp2333
a(g7
V'*.html', '*.htm'
p2334
tp2335
a(g7
g1146
tp2336
a(g7
V\u000a\u000a        flags = re.IGNORECASE | re.DOTALL\u000a        tokens = 
p2337
tp2338
a(g7
g1156
tp2339
a(g7
V\u000a            'root': 
p2340
tp2341
a(g7
g1142
tp2342
a(g7
V\u000a                ('
p2343
tp2344
a(g7
g1142
tp2345
a(g7
V^<&
p2346
tp2347
a(g7
g1146
tp2348
a(g7
g1163
tp2349
a(g7
V', Text),\u000a                ('&.*?;', Name.Entity),\u000a                (r'<\u005cs*script\u005cs*', Name.Tag, ('script
p2350
tp2351
a(g7
g958
tp2352
a(g7
Vcontent', 'tag')),\u000a                (r'<\u005cs*
p2353
tp2354
a(g7
g1142
tp2355
a(g7
g1187
tp2356
a(g7
g958
tp2357
a(g7
VzA
p2358
tp2359
a(g7
g958
tp2360
a(g7
VZ0
p2361
tp2362
a(g7
g958
tp2363
a(g7
V9:
p2364
tp2365
a(g7
g1146
tp2366
a(g7
g1163
tp2367
a(g7
V', Name.Tag, 'tag'),\u000a                (r'<\u005cs*/\u005cs*
p2368
tp2369
a(g7
g1142
tp2370
a(g7
g1187
tp2371
a(g7
g958
tp2372
a(g7
VzA
p2373
tp2374
a(g7
g958
tp2375
a(g7
VZ0
p2376
tp2377
a(g7
g958
tp2378
a(g7
V9:
p2379
tp2380
a(g7
g1146
tp2381
a(g7
g1163
tp2382
a(g7
V\u005cs*>', Name.Tag),\u000a            
p2383
tp2384
a(g7
g1146
tp2385
a(g7
V,\u000a            'script
p2386
tp2387
a(g7
g958
tp2388
a(g7
Vcontent': 
p2389
tp2390
a(g7
g1142
tp2391
a(g7
V\u000a                (r'(.
p2392
tp2393
a(g7
g1163
tp2394
a(g7
V?)(<\u005cs*/\u005cs*script\u005cs*>)',\u000a                 bygroups(using(JavascriptLexer), Name.Tag),\u000a                 '#pop'),\u000a            
p2395
tp2396
a(g7
g1146
tp2397
a(g7
V\u000a        
p2398
tp2399
a(g7
g1173
tp2400
a(g7
V\u000a\u000aHere the content of a ``<script>`` tag is passed to a newly created instance of\u000aa `JavascriptLexer` and not processed by the `HtmlLexer`.  This is done using\u000athe `using` helper that takes the other lexer class as its parameter.\u000a\u000aNote the combination of `bygroups` and `using`.  This makes sure that the\u000acontent up to the ``</script>`` end tag is processed by the `JavascriptLexer`,\u000awhile the end tag is yielded as a normal token with the `Name.Tag` type.\u000a\u000a
p2401
tp2402
a(g333
V[-
p2403
tp2404
a(g333
VAs an additional goodie, if the lexer class is replaced by `this` (imported from\u000a`pygments.lexer`), the "other" lexer will be the current one (because you cannot\u000arefer to the current class within the code that runs at class definition time).
p2405
tp2406
a(g333
V-]
p2407
tp2408
a(g7
V\u000a\u000aAlso note the ``(r'<\u005cs*script\u005cs*', Name.Tag, ('script
p2409
tp2410
a(g7
g958
tp2411
a(g7
Vcontent', 'tag'))`` rule.\u000aHere, two states are pushed onto the state stack, ``'script
p2412
tp2413
a(g7
g958
tp2414
a(g7
Vcontent'`` and\u000a``'tag'``.  That means that first ``'tag'`` is processed, which will 
p2415
tp2416
a(g333
V[-
p2417
tp2418
a(g333
Vparse
p2419
tp2420
a(g333
V-]
p2421
tp2422
a(g7
g984
tp2423
a(g373
V{+
p2424
tp2425
a(g373
Vlex
p2426
tp2427
a(g373
V+}
p2428
tp2429
a(g7
V\u000aattributes and the closing ``>``, then the ``'tag'`` state is popped and the\u000anext state on top of the stack will be ``'script
p2430
tp2431
a(g7
g958
tp2432
a(g7
Vcontent'``.\u000a\u000a
p2433
tp2434
a(g373
V{+
p2435
tp2436
a(g373
VSince you cannot refer to the class currently being defined, use `this`\u000a(imported from `pygments.lexer`) to refer to the current lexer class, i.e.\u000a``using(this)``.  This construct may seem unnecessary, but this is often the\u000amost obvious way of lexing arbitrary syntax between fixed delimiters without\u000aintroducing deeply nested states.
p2437
tp2438
a(g373
V+}
p2439
tp2440
a(g7
V\u000a\u000aThe `using()` helper has a special keyword argument, `state`, which works as\u000afollows: if given, the lexer to use initially is not in the ``"root"`` state,\u000abut in the state given by this argument.  This 
p2441
tp2442
a(g333
V[-
p2443
tp2444
a(g333
V*only* works
p2445
tp2446
a(g333
V-]
p2447
tp2448
a(g7
g984
tp2449
a(g373
V{+
p2450
tp2451
a(g373
Vdoes not work
p2452
tp2453
a(g373
V+}
p2454
tp2455
a(g7
V with 
p2456
tp2457
a(g333
V[-
p2458
tp2459
a(g333
Va `RegexLexer`.
p2460
tp2461
a(g333
V-]
p2462
tp2463
a(g7
g984
tp2464
a(g373
V{+
p2465
tp2466
a(g373
Vadvanced\u000a`RegexLexer` subclasses such as `ExtendedRegexLexer` (see below).
p2467
tp2468
a(g373
V+}
p2469
tp2470
a(g7
V\u000a\u000aAny other keywords arguments passed to `using()` are added to the keyword\u000aarguments used to create the lexer.\u000a\u000a\u000aDelegating Lexer\u000a================\u000a\u000aAnother approach for nested lexers is the `DelegatingLexer` which is for example\u000aused for the template engine lexers.  It takes two lexers as arguments on\u000ainitialisation: a `root_lexer` and a `language_lexer`.\u000a\u000aThe input is processed as follows: First, the whole text is lexed with the\u000a`language_lexer`.  All tokens yielded with 
p2471
tp2472
a(g333
V[-
p2473
tp2474
a(g333
g1187
tp2475
a(g333
V-]
p2476
tp2477
a(g7
g984
tp2478
a(g373
V{+
p2479
tp2480
a(g373
Vthe special
p2481
tp2482
a(g373
V+}
p2483
tp2484
a(g7
V type of ``Other`` are\u000athen concatenated and given to the `root_lexer`.  The language tokens of the\u000a`language_lexer` are then inserted into the `root_lexer`'s token stream at the\u000aappropriate positions.\u000a\u000a
p2485
tp2486
a(g333
V[-
p2487
tp2488
a(g333
V.. sourcecode:: python
p2489
tp2490
a(g333
V-]
p2491
tp2492
a(g7
g984
tp2493
a(g373
V{+
p2494
tp2495
a(g373
V::
p2496
tp2497
a(g373
V+}
p2498
tp2499
a(g7
V\u000a\u000a    from pygments.lexer import DelegatingLexer\u000a    from pygments.lexers.web import HtmlLexer, PhpLexer\u000a\u000a    class HtmlPhpLexer(DelegatingLexer):\u000a        def __init__(self, **options):\u000a            super(HtmlPhpLexer, self).__init__(HtmlLexer, PhpLexer, **options)\u000a\u000aThis procedure ensures that e.g. HTML with template tags in it is highlighted\u000acorrectly even if the template tags are put into HTML tags or attributes.\u000a\u000aIf you want to change the needle token ``Other`` to something else, you can give\u000athe lexer another token type as the third 
p2500
tp2501
a(g333
V[-
p2502
tp2503
a(g333
Vparameter:\u000a\u000a.. sourcecode:: python
p2504
tp2505
a(g333
V-]
p2506
tp2507
a(g7
g984
tp2508
a(g373
V{+
p2509
tp2510
a(g373
Vparameter::
p2511
tp2512
a(g373
V+}
p2513
tp2514
a(g7
V\u000a\u000a    DelegatingLexer.__init__(MyLexer, OtherLexer, Text, **options)\u000a\u000a\u000aCallbacks\u000a=========\u000a\u000aSometimes the grammar of a language is so complex that a lexer would be unable\u000ato 
p2515
tp2516
a(g333
V[-
p2517
tp2518
a(g333
Vparse
p2519
tp2520
a(g333
V-]
p2521
tp2522
a(g7
g984
tp2523
a(g373
V{+
p2524
tp2525
a(g373
Vprocess
p2526
tp2527
a(g373
V+}
p2528
tp2529
a(g7
V it just by using regular expressions and stacks.\u000a\u000aFor this, the `RegexLexer` allows callbacks to be given in rule tuples, instead\u000aof token types (`bygroups` and `using` are nothing else but preimplemented\u000acallbacks).  The callback must be a function taking two arguments:\u000a\u000a* the lexer itself\u000a* the match object for the last matched rule\u000a\u000aThe callback must then return an iterable of (or simply yield) ``(index,\u000atokentype, value)`` tuples, which are then just passed through by\u000a`get_tokens_unprocessed()`.  The ``index`` here is the position of the token in\u000athe input string, ``tokentype`` is the normal token type (like `Name.Builtin`),\u000aand ``value`` the associated part of the input string.\u000a\u000aYou can see an example 
p2530
tp2531
a(g333
V[-
p2532
tp2533
a(g333
Vhere:\u000a\u000a.. sourcecode:: python
p2534
tp2535
a(g333
V-]
p2536
tp2537
a(g7
g984
tp2538
a(g373
V{+
p2539
tp2540
a(g373
Vhere::
p2541
tp2542
a(g373
V+}
p2543
tp2544
a(g7
V\u000a\u000a    from pygments.lexer import RegexLexer\u000a    from pygments.token import Generic\u000a\u000a    class HypotheticLexer(RegexLexer):\u000a\u000a        def headline_callback(lexer, match):\u000a            equal_signs = match.group(1)\u000a            text = match.group(2)\u000a            yield match.start(), Generic.Headline, equal_signs 
p2545
tp2546
a(g7
g1163
tp2547
a(g7
V text 
p2548
tp2549
a(g7
g1163
tp2550
a(g7
V equal_signs\u000a\u000a        tokens = 
p2551
tp2552
a(g7
g1156
tp2553
a(g7
V\u000a            'root': 
p2554
tp2555
a(g7
g1142
tp2556
a(g7
V\u000a                (r'(=
p2557
tp2558
a(g7
g1163
tp2559
a(g7
V)(.*?)(\u005c1)', headline_callback)\u000a            
p2560
tp2561
a(g7
g1146
tp2562
a(g7
V\u000a        
p2563
tp2564
a(g7
g1173
tp2565
a(g7
V\u000a\u000aIf the regex for the `headline_callback` matches, the function is called with\u000athe match object.  Note that after the callback is done, processing continues\u000anormally, that is, after the end of the previous match.  The callback has no\u000apossibility to influence the position.\u000a\u000aThere are not really any simple examples for lexer callbacks, but you can see\u000athem in action e.g. in the 
p2566
tp2567
a(g333
V[-
p2568
tp2569
a(g333
V`compiled.py`_ source code
p2570
tp2571
a(g333
V-]
p2572
tp2573
a(g7
g984
tp2574
a(g373
V{+
p2575
tp2576
a(g373
V`SMLLexer` class
p2577
tp2578
a(g373
V+}
p2579
tp2580
a(g7
V in 
p2581
tp2582
a(g333
V[-
p2583
tp2584
a(g333
Vthe `CLexer` and\u000a`JavaLexer` classes.
p2585
tp2586
a(g333
V-]
p2587
tp2588
a(g7
g984
tp2589
a(g373
V{+
p2590
tp2591
a(g373
V`ml.py`_.
p2592
tp2593
a(g373
V+}
p2594
tp2595
a(g7
V\u000a\u000a.. 
p2596
tp2597
a(g333
V[-
p2598
tp2599
a(g333
V_compiled.py: http://bitbucket.org/birkenfeld/pygments
p2600
tp2601
a(g333
g958
tp2602
a(g333
Vmain/src/tip/pygments/lexers/compiled.py
p2603
tp2604
a(g333
V-]
p2605
tp2606
a(g7
g984
tp2607
a(g373
V{+
p2608
tp2609
a(g373
V_ml.py: http://bitbucket.org/birkenfeld/pygments
p2610
tp2611
a(g373
g958
tp2612
a(g373
Vmain/src/tip/pygments/lexers/ml.py
p2613
tp2614
a(g373
V+}
p2615
tp2616
a(g7
V\u000a\u000a\u000aThe ExtendedRegexLexer class\u000a============================\u000a\u000aThe `RegexLexer`, even with callbacks, unfortunately isn't powerful enough for\u000athe funky syntax rules of 
p2617
tp2618
a(g333
V[-
p2619
tp2620
a(g333
Vsome
p2621
tp2622
a(g333
V-]
p2623
tp2624
a(g7
V languages 
p2625
tp2626
a(g333
V[-
p2627
tp2628
a(g333
Vthat will go unnamed,
p2629
tp2630
a(g333
V-]
p2631
tp2632
a(g7
V such as Ruby.\u000a\u000aBut fear not; even then you don't have to abandon the regular expression\u000a
p2633
tp2634
a(g333
V[-
p2635
tp2636
a(g333
Vapproach. For
p2637
tp2638
a(g333
V-]
p2639
tp2640
a(g7
V\u000a
p2641
tp2642
a(g373
V{+
p2643
tp2644
a(g373
Vapproach:
p2645
tp2646
a(g373
V+}
p2647
tp2648
a(g7
V Pygments has a subclass of `RegexLexer`, the `ExtendedRegexLexer`.\u000aAll features known from RegexLexers are available here too, and the tokens are\u000aspecified in exactly the same way, *except* for one detail:\u000a\u000aThe `get_tokens_unprocessed()` method holds its internal state data not as local\u000avariables, but in an instance of the `pygments.lexer.LexerContext` class, and\u000athat instance is passed to callbacks as a third argument. This means that you\u000acan modify the lexer state in callbacks.\u000a\u000aThe `LexerContext` class has the following members:\u000a\u000a* `text` 
p2649
tp2650
a(g7
g958
tp2651
a(g7
g958
tp2652
a(g7
V the input text\u000a* `pos` 
p2653
tp2654
a(g7
g958
tp2655
a(g7
g958
tp2656
a(g7
V the current starting position that is used for matching regexes\u000a* `stack` 
p2657
tp2658
a(g7
g958
tp2659
a(g7
g958
tp2660
a(g7
V a list containing the state stack\u000a* `end` 
p2661
tp2662
a(g7
g958
tp2663
a(g7
g958
tp2664
a(g7
V the maximum position to which regexes are matched, this defaults to\u000a  the length of `text`\u000a\u000aAdditionally, the `get_tokens_unprocessed()` method can be given a\u000a`LexerContext` instead of a string and will then process this context instead of\u000acreating a new one for the string argument.\u000a\u000aNote that because you can set the current position to anything in the callback,\u000ait won't be automatically be set by the caller after the callback is finished.\u000aFor example, this is how the hypothetical lexer above would be written with the\u000a
p2665
tp2666
a(g333
V[-
p2667
tp2668
a(g333
V`ExtendedRegexLexer`:\u000a\u000a.. sourcecode:: python
p2669
tp2670
a(g333
V-]
p2671
tp2672
a(g7
V\u000a
p2673
tp2674
a(g373
V{+
p2675
tp2676
a(g373
V`ExtendedRegexLexer`::
p2677
tp2678
a(g373
V+}
p2679
tp2680
a(g7
V\u000a\u000a    from pygments.lexer import ExtendedRegexLexer\u000a    from pygments.token import Generic\u000a\u000a    class ExHypotheticLexer(ExtendedRegexLexer):\u000a\u000a        def headline_callback(lexer, match, ctx):\u000a            equal_signs = match.group(1)\u000a            text = match.group(2)\u000a            yield match.start(), Generic.Headline, equal_signs 
p2681
tp2682
a(g7
g1163
tp2683
a(g7
V text 
p2684
tp2685
a(g7
g1163
tp2686
a(g7
V equal_signs\u000a            ctx.pos = match.end()\u000a\u000a        tokens = 
p2687
tp2688
a(g7
g1156
tp2689
a(g7
V\u000a            'root': 
p2690
tp2691
a(g7
g1142
tp2692
a(g7
V\u000a                (r'(=
p2693
tp2694
a(g7
g1163
tp2695
a(g7
V)(.*?)(\u005c1)', headline_callback)\u000a            
p2696
tp2697
a(g7
g1146
tp2698
a(g7
V\u000a        
p2699
tp2700
a(g7
g1173
tp2701
a(g7
V\u000a\u000aThis might sound confusing (and it can really be). But it is needed, and for an\u000aexample look at the Ruby lexer in 
p2702
tp2703
a(g333
V[-
p2704
tp2705
a(g333
V`agile.py`_.
p2706
tp2707
a(g333
V-]
p2708
tp2709
a(g7
g984
tp2710
a(g373
V{+
p2711
tp2712
a(g373
V`ruby.py`_.
p2713
tp2714
a(g373
V+}
p2715
tp2716
a(g7
V\u000a\u000a.. 
p2717
tp2718
a(g333
V[-
p2719
tp2720
a(g333
V_agile.py: https://bitbucket.org/birkenfeld/pygments
p2721
tp2722
a(g333
g958
tp2723
a(g333
Vmain/src/tip/pygments/lexers/agile.py\u000a\u000a\u000aFiltering
p2724
tp2725
a(g333
V-]
p2726
tp2727
a(g7
g984
tp2728
a(g373
V{+
p2729
tp2730
a(g373
V_ruby.py: https://bitbucket.org/birkenfeld/pygments
p2731
tp2732
a(g373
g958
tp2733
a(g373
Vmain/src/tip/pygments/lexers/ruby.py\u000a\u000a\u000aHandling Lists of Keywords\u000a==========================\u000a\u000aFor a relatively short list (hundreds) you can construct an optimized regular\u000aexpression directly using ``words()`` (longer lists, see next section).  This\u000afunction handles a few things for you automatically, including escaping\u000ametacharacters and Python's first
p2734
tp2735
a(g373
g958
tp2736
a(g373
Vmatch rather than longest
p2737
tp2738
a(g373
g958
tp2739
a(g373
Vmatch in\u000aalternations.  Feel free to put the lists themselves in\u000a``pygments/lexers/_$lang_builtins.py`` (see examples there), and generated by\u000acode if possible.\u000a\u000aAn example of using ``words()`` is something like::\u000a\u000a    from pygments.lexer import RegexLexer, words, Name\u000a\u000a    class MyLexer(RegexLexer):\u000a\u000a        tokens = 
p2740
tp2741
a(g373
g1156
tp2742
a(g373
V\u000a            'root': 
p2743
tp2744
a(g373
g1142
tp2745
a(g373
V\u000a                (words(('else', 'elseif'), suffix=r'\u005cb'), Name.Builtin),\u000a                (r'\u005cw
p2746
tp2747
a(g373
g1163
tp2748
a(g373
V', Name),\u000a            
p2749
tp2750
a(g373
g1146
tp2751
a(g373
V,\u000a        
p2752
tp2753
a(g373
g1173
tp2754
a(g373
V\u000a\u000aAs you can see, you can add ``prefix`` and ``suffix`` parts to the constructed\u000aregex.\u000a\u000a\u000aModifying
p2755
tp2756
a(g373
V+}
p2757
tp2758
a(g7
V Token Streams\u000a=======================\u000a\u000aSome languages ship a lot of builtin functions (for example PHP).  The total\u000aamount of those functions differs from system to system because not everybody\u000ahas every extension installed.  In the case of PHP there are over 3000 builtin\u000afunctions.  That's an 
p2759
tp2760
a(g333
V[-
p2761
tp2762
a(g333
Vincredible
p2763
tp2764
a(g333
V-]
p2765
tp2766
a(g7
g984
tp2767
a(g373
V{+
p2768
tp2769
a(g373
Vincredibly
p2770
tp2771
a(g373
V+}
p2772
tp2773
a(g7
V huge amount of functions, much more than you\u000a
p2774
tp2775
a(g333
V[-
p2776
tp2777
a(g333
Vcan
p2778
tp2779
a(g333
V-]
p2780
tp2781
a(g7
V\u000a
p2782
tp2783
a(g373
V{+
p2784
tp2785
a(g373
Vwant to
p2786
tp2787
a(g373
V+}
p2788
tp2789
a(g7
V put into a regular expression.\u000a\u000aBut because only `Name` tokens can be function names 
p2790
tp2791
a(g333
V[-
p2792
tp2793
a(g333
Vit's
p2794
tp2795
a(g333
V-]
p2796
tp2797
a(g7
g984
tp2798
a(g373
V{+
p2799
tp2800
a(g373
Vthis is
p2801
tp2802
a(g373
V+}
p2803
tp2804
a(g7
V solvable by\u000aoverriding the ``get_tokens_unprocessed()`` method.  The following lexer\u000asubclasses the `PythonLexer` so that it highlights some additional names as\u000apseudo 
p2805
tp2806
a(g333
V[-
p2807
tp2808
a(g333
Vkeywords:\u000a\u000a.. sourcecode:: python
p2809
tp2810
a(g333
V-]
p2811
tp2812
a(g7
g984
tp2813
a(g373
V{+
p2814
tp2815
a(g373
Vkeywords::
p2816
tp2817
a(g373
V+}
p2818
tp2819
a(g7
V\u000a\u000a    from 
p2820
tp2821
a(g333
V[-
p2822
tp2823
a(g333
Vpygments.lexers.agile
p2824
tp2825
a(g333
V-]
p2826
tp2827
a(g7
g984
tp2828
a(g373
V{+
p2829
tp2830
a(g373
Vpygments.lexers.python
p2831
tp2832
a(g373
V+}
p2833
tp2834
a(g7
V import PythonLexer\u000a    from pygments.token import Name, Keyword\u000a\u000a    class MyPythonLexer(PythonLexer):\u000a        EXTRA_KEYWORDS = 
p2835
tp2836
a(g333
V[-
p2837
tp2838
a(g333
g1142
tp2839
a(g333
V'foo',
p2840
tp2841
a(g333
V-]
p2842
tp2843
a(g7
g984
tp2844
a(g373
V{+
p2845
tp2846
a(g373
Vset(('foo',
p2847
tp2848
a(g373
V+}
p2849
tp2850
a(g7
V 'bar', 'foobar', 'barfoo', 'spam', 
p2851
tp2852
a(g333
V[-
p2853
tp2854
a(g333
V'eggs'
p2855
tp2856
a(g333
g1146
tp2857
a(g333
V-]
p2858
tp2859
a(g7
g984
tp2860
a(g373
V{+
p2861
tp2862
a(g373
V'eggs'))
p2863
tp2864
a(g373
V+}
p2865
tp2866
a(g7
V\u000a\u000a        def get_tokens_unprocessed(self, text):\u000a            for index, token, value in PythonLexer.get_tokens_unprocessed(self, text):\u000a                if token is Name and value in self.EXTRA_KEYWORDS:\u000a                    yield index, Keyword.Pseudo, value\u000a                else:\u000a                    yield index, token, value\u000a\u000aThe `PhpLexer` and `LuaLexer` use this method to resolve builtin functions.\u000a\u000a
p2867
tp2868
a(g333
V[-
p2869
tp2870
a(g333
V.. note:: Do not confuse this with the :doc:`filter <filters>` system.
p2871
tp2872
a(g333
V-]
p2873
tp2874
a(g7
V\u000a
p2875
tp2876
a.