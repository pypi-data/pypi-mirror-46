"""
Datavoreclient is a python API usefull to get data from different services.
With this API you can communicate with Datavore, Datalaps, Datahive and Sentinel_1.


Some functions of this API return an image.
To display this image you can use an external library such as the python
Image module. Eg :

| import datavoreclient
| from PIL import Image
| from StringIO import StringIO
| dc = datavoreclient.Datavore()
| image = dc.getImage(...)
| Image.open(StringIO(image)).show()

Or if you use Jupyter you can just use :

| import datavoreclient
| from IPython.display import Image, display
| dc = datavoreclient.Datavore()
| image = dc.getImage(...)
| display(Image(image))

Some functions will also return you pandas series. You can then
display them simply with the panda function plot(). Example :

| data = dlaps.getTimeserie(index='2000', varname='SULHF', coord='-27.42,19.97', datelaps='19000101010101,21000101010101', groupby=None)
| data.plot()

more information at http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.html

"""

from dateutil.parser import parse
import requests
import urllib2
import json
import datetime
import re
import pandas as pd
import time
from StringIO import StringIO

# try:
#     import pyhs2
# except ImportError:
#     print "pyhs2 not installed, DataHive query will not be available."

DEFAULT='default'
DEFAULT_TIMEOUT = 10
DEFAULT_DATAVORE_SERVICE = 'https://www.ifremer.fr/datavore/exp/datavore/public'
DEFAULT_DATALAPS_SERVICE = 'https://www.ifremer.fr/datavore/exp/datavore/public'
# Intranet only
#DEFAULT_DATAVORE_SERVICE = 'http://br156-136.ifremer.fr:8000/datavore/public'
#DEFAULT_DATALAPS_SERVICE = 'http://br156-136.ifremer.fr:9091/api/datavore/public/'

def bbox2html(bbox):
    """
    >>> bbox2html('TOTO')
    'TOTO'
    >>> bbox2html('[180, 180]')
    '180,180'
    """
    bbox = str(bbox).strip('[]').replace(" ", "")
    return bbox

def index2html(index):
    """
    >>> index2html('TOTO')
    'TOTO'
    >>> index2html('ISAS13/v3')
    'ISAS13>v3'
    """
    index = str(str(index).replace("/", ">"))
    return index

def date2html(date):
    """
    >>> date2html(20020101000000)
    '20020101000000'
    >>> date2html('20020101000000')
    '20020101000000'
    """
    if not (isinstance(date, basestring)):
        if (isinstance(date, int)):
            date=str(date)
        else:
            date = date.strftime('%Y%m%d%H%M%S')
    return date

def opt2html(value):
    """
    >>> opt2html('c')
    'c'
    >>> opt2html(None)
    null
    """
    if isinstance(value, basestring):
        return value
    else:
        return json.dumps(value)

class Datavore(object):
    """
    Class to communicate with Datavore. Datavore is a visualization tool
    that is able to look for data from different satellites and display
    the information as a map with customization options.
    """

    OPTIONS_DEFAULT = ['vMin', 'vMax', 'cmap', 'offset', 'resolution', 'paramsPlot']

    def __init__(self, service=None):
        if not service : self.service = DEFAULT_DATAVORE_SERVICE
        else : self.service = service

    def getImage(self, index, varname, date, bbox='global', vMin=DEFAULT, vMax=DEFAULT, cmap=DEFAULT, nearest=None, offset=DEFAULT, resolution=DEFAULT,filters={}, paramsPlot=DEFAULT):
        """
        Returns an image generated from Datavore.
        Works the same as Datavore on web, except you give parameters manually.

        Args:
            index (str): Name of the index to get data from.
            varname (str): Name of the variable of the index to get data from.
            date (str): formatted string representing a date.\n
                format is : YYYYMMDDhhmmss. Eg : 20120815125959.
            bbox([float] or string): Corresponds to a rectangle of coordinates\n
                Array : [x1, y1, x2, y2] or string : "x1, y1, x2, y2".
            vMin(int) : Minimum value of the scale.
            vMax(int) : Maximum value of the scale.
            cmap(str) : Change the color of the map.\n
                Available styles : jet, bwr, viridis, inferno, plasma, magma, Blues, bone, cool, autumn, s3pcpn
            nearest(int) : If there is no data at the exact given date,
                nearest is how far in seconds datavore will look for data
                around the given date
            offset(int) : Offset the value of the data by this amount
            resolution(int) : Resolution of the image returned
            filters : Probably useless
            paramsPlot(dictionary or str) :
                Add some options for image rendering.\n
                Eg : {"projection":"pc_world","radius":None,"plot_method":"pcolormesh","resample":True}

        Returns:
            image: An image representing a map generated by Datavore.

        | Example of use :
        | getImage('ISAS13>v3','PSAL','20120815000000',bbox=[-60,3,-22,27])
        | will return the data from the value PSAL of the index ISAS13>v3 at coordinates [-60,3,-22,27] at the 15th august of 2012
        """

        date = date2html(date)
        bbox = bbox2html(bbox)
        index = index2html(index)

        options = ''
        if nearest!=None:options += 'nearest='+ opt2html(nearest) +'&'
        if filters!=None:options += 'filters='+ opt2html(filters) +'&'
        for key, value in locals().iteritems():
            if key in self.OPTIONS_DEFAULT:
                if value!=DEFAULT:
                    options += key +'='+ opt2html(value) +'&'

        url = "{self.service}/{index}/{varname}/{bbox}/{date}/map/?{options}".format(**locals())
        print(url)
        return requests.get(url, timeout = DEFAULT_TIMEOUT).content

    def getData(self, index, varname, date, bbox='global', vMin=DEFAULT, vMax=DEFAULT, cmap=DEFAULT, nearest=None, offset=DEFAULT, resolution=DEFAULT,filters={}, paramsPlot=DEFAULT, liste=False):
        """
        Returns data generated from Datavore.
        Works the same as getImage (see above), except it
        returns data instead of a map.
        """

        date = date2html(date)
        bbox = bbox2html(bbox)
        index = index2html(index)

        options = ''
        if nearest!=None:options += 'nearest='+ opt2html(nearest) +'&'
        if filters!=None:options += 'filters='+ opt2html(filters) +'&'
        if liste!=None:options += 'list='+ opt2html(liste) +'&'
        for key, value in locals().iteritems():
            if key in self.OPTIONS_DEFAULT:
                if value!=DEFAULT:
                    options += key +'='+ opt2html(value) +'&'

        url = "{self.service}/{index}/{varname}/{bbox}/{date}/data/?{options}".format(**locals())
        print(url)
        binary = requests.get(url, timeout = DEFAULT_TIMEOUT).content
        import msgpack
        import msgpack_numpy as m
        return msgpack.unpackb(binary, object_hook=m.decode)


    def getImageFromUrl(self, url):
        """
        Return an image from a url of datavore. Just copy-paste the url of the Datavore web page after you generated your data map, and it should return you the same image.

        Args:
            url (str): Url of the Datavore web page.

        Returns:
            image: An image representing a map generated by Datavore.
        """
        url = urllib2.unquote(url)
        index = re.search('d=(.*)&r', url).group(1)
        coordString = re.search('r=(.*)&v', url).group(1)
        bbox = []
        for coord in coordString.split(','):
            bbox.append(float(coord))
        varname = re.search('v=(.*)&dt', url).group(1)
        date = re.search('dt=(.*)&t', url).group(1)
        date = parse(date)
        print date
        return self.getImage(index, varname, date, bbox, nearest=3600)

    def getFileList(self, index, varname, bbox='global', startdate='19500917', stopdate='21000917', dl=0, inv='null', filters='null'):
        """
        Returns a list of the files used to search for data with given parameters.

        Args:
            index (str): Name of the index to get data from.
            varname (str): Name of the variable of the index to get data from.
            startdate (str): formatted string representing a date.\n
                format is : YYYYMMDDhhmmss. Eg : 20120815125959.
            stopdate (str): Same as startDate.
            bbox([float] or string):
                Corresponds to a rectangle of coordinates\n
                Array : [x1, y1, x2, y2] or String : "x1, y1, x2, y2".
            filters : Probably useless

        Returns:
            array: A list of the files used to search for data with given parameters.
        """

        startdate = date2html(startdate)
        stopdate = date2html(stopdate)
        for var,value in locals().iteritems():
                value = str(value)
        bbox = bbox2html(bbox)
        index = index2html(index)
        url = "{self.service}/{index}/{varname}/{bbox}/{startdate},{stopdate}/filelist/?dl={dl}&inv={inv}&filters={filters}".format(**locals())
        print(url)
        return requests.get(url, timeout = DEFAULT_TIMEOUT).content

    def getIndexes(self):
        """
        Returns:
            dictionary: The indexes available with their configuration.
        """
        return json.loads(requests.get(self.service +'/config/', timeout = DEFAULT_TIMEOUT).content)

    def getListIndexes(self):
        """
        Returns:
            array: List of indexes available.
        """
        return self.getIndexes().keys()

    def printListIndexes(self):
        """
        Print list of indexes.
        """
        print '\n'.join(self.getListIndexes())

class Datavoresentinel1(object):
    """
    Class to get data from the sentinel 1 satellite.
    """

    def __init__(self, service=None):
        if not service : self.service = DEFAULT_DATAVORE_SERVICE
        else : self.service = service

    def getImage(self, index, varname, date, bbox='global'):
        """
        Generate and return a map from sentinel 1.


        Args:
            index (str): Name of the index to get data from. For sentinel 1,
                it is either "S1AWV.v3<" or "S1BWV.v3<".
            varname (str):
                Name of the variable of the index to get data from.
                Possible values :\n
                l1_roughness,\n
                S1A_WV_OCN__2S_realcrossspectra_s1a,\n
                S1B_WV_OCN__2S_realcrossspectra_s1b,\n
                S1A_WV_OCN__2S_imaginarycrossspectra_s1a,\n
                S1B_WV_OCN__2S_imaginarycrossspectra_s1b,\n
                S1A_WV_OCN__2S_ocean_swell_spectra_s1a,\n
                S1B_WV_OCN__2S_ocean_swell_spectra_s1b,\n
                S1A_WV_OCN__2S_ww3,\n
                S1B_WV_OCN__2S_ww3 (not working).\n
                Has to match the S1A or S1B from the index.

            date (str): formatted string representing a date.
                format is : YYYYMMDDhhmmss. Eg : 20120815125959.
            bbox([float] or string): Corresponds to a rectangle of coordinates
                like so : [x1, y1, x2, y2] or like so : "x1, y1, x2, y2".

        Returns:
            image: An image representing a map generated by Sentinel 1.

        """
        date = date2html(date)
        bbox = bbox2html(bbox)

        url = "{self.service}/{index}/{varname}/{bbox}/{date}/quicklook/".format(**locals())
        print(url)
        return requests.get(url, timeout = DEFAULT_TIMEOUT).content

    def getFileList(self, bbox='global', startdate='19500917', stopdate='21000917', dl=0, inv='null', filters='null'):
        """
        Returns a list of the files used to search for data with parameters
        given.

        Args:
            bbox([float] or string):
                Corresponds to a rectangle of coordinates\n
                Array : [x1, y1, x2, y2] or String : "x1, y1, x2, y2".
            startdate (str): formatted string representing a date.\n
                format is : YYYYMMDDhhmmss. Eg : 20120815125959.
            stopdate (str): Same as startDate.
            filters : Probably useless

        Returns:
            array: A list of the files used to search for data with given parameters.
        """

        startdate = date2html(startdate)
        stopdate = date2html(stopdate)
        for var,value in locals().iteritems():
                value = str(value)
        bbox = bbox2html(bbox)
        url = "{self.service}/all</sss/{bbox}/{startdate},{stopdate}/filelist/?dl={dl}&inv={inv}&filters={filters}".format(**locals())
        print(url)
        return requests.get(url, timeout = DEFAULT_TIMEOUT).content

class Datalaps(object):
    """
    Just like Datavore, Datalaps is a visualization tool.
    It is able to look for data from different satellites and display the information as a map. The main difference are that it is able to look
    for data between a time lapse and aggregate the information by a scale
    of time.

    """


    def __init__(self, datavoreService=None, datalapsService=None):
        if not datavoreService : self.datavoreService = DEFAULT_DATAVORE_SERVICE
        else : self.datavoreService = datavoreService
        if not datalapsService : self.datalapsService = DEFAULT_DATALAPS_SERVICE
        else : self.datalapsService = datalapsService

    def getConfig(self):
        print self.datalapsService +'/config_vertx/'
        return json.loads(requests.get(self.datalapsService +'/config_vertx/', timeout = DEFAULT_TIMEOUT).content)

    def searchIndexes(self, pattern, search_field='name', return_name_only=False, return_id_only=False, return_all=False):
        import re
        conf = self.getConfig()
        res = []
        for p in conf:
            if re.search(pattern, p[search_field]): 
                idx = p['index']
                name = p['name']
                content = p
                #print idx, name
                if return_id_only:
                    res += [idx]
                elif return_name_only:
                    res += [name]
                elif return_all:
                    res += [ (idx, name, content) ]
                else:
                    res += [(idx, name)]
        return res
            
    def getData(self, index, varnames, date, bbox, filters="", output_format='csv', other_params={}, time_index=True):
        urlFormat = "{self.datalapsService}/{index}/{varname}/{coord}/{datelaps}/extract/?filters={filters}&format={output_format}"

        conf = {}
        conf['output_format'] = output_format
        conf['filters'] = filters
        conf.update(other_params)

        url = self.getUrl(urlFormat, index, varnames, bbox, date, other_params=conf)
        result = requests.get(url, timeout = DEFAULT_TIMEOUT).content  

        df = pd.read_csv(StringIO(result))

        if time_index and 'TS' in df.columns:
            df['time'] = df['TS'].apply(
                lambda x: datetime.datetime.fromtimestamp(x/1000))
            df.set_index(['time'], inplace=True)

        return df

    def getImage(self, index, varname, bbox, datelaps='19500917,21000917', aggregate='avg'):
        """
        Return an image generated by Datalaps.\n
        CARE large areas will be very slow to load, please use datavore to display large maps.

        Args:
            index (str): Name of the index to get data from.
            varname (str): Name of the variable of the index to get data from.
            bbox(string or [float]):
                Corresponds to a rectangle of coordinates\n
                Array : [x1, y1, x2, y2] or String : "x1, y1, x2, y2".\n
            datelaps (str or [int] or [datetime]):
                formatted string representing a lapse of time.\n
                - format is : YYYYMMDDhhmmss. Eg :\n
                '19500917,21000917' (default).\n
                - It can also be an array of int Eg :\n
                [19500917,21000917].\n
                - It can also be an array of datetime Eg :\n
                [datetime.date(1900, 12, 5),datetime.date(2100, 12, 5)].
            aggregate(str):
                String representing the function to use to aggregate the data of the time lapse. The aggregated data will be used to generate the map. Possible values :\n
                - 'avg' : average (default)
                - 'max' : maximum
                - 'min' : minimum
                - 'count' : number of result
                - 'std' : no se

        Returns:
            image: An image representing the map of the data aggregated.
        """

        urlFormat =  "{self.datavoreService}/{index}/{varname}/{coord}/{datelaps}/map/?sm={aggregate}&mapper_id=DVORTSMAPS"

        url = self.getUrl(urlFormat, index, varname, bbox, datelaps, 'None', aggregate)
        return requests.get(url, timeout = DEFAULT_TIMEOUT).content

    def getTimeserie(self, index, varname, coord, datelaps='19500917,21000917', groupby=None, aggregate='avg'):
        """
        Exactly the same as getTimeserieRaw() but return time series
        as pandas.

        Args:
            index (str): Name of the index to get data from.
            varname (str): Name of the variable of the index to get data from.
            coord(string or [float]):
                Corresponds to a position OR a rectangle of coordinates\n
                If a rectangle is passed, the data of the rectangle
                will be aggregated by the aggregate function given
                in parameter.\n
                Position : Array : [x1, y1] or String : "x1, y1".\n
                Rectangle : Array : [x1, y1, x2, y2] or String : "x1, y1, x2, y2".\n
            datelaps (str or [int] or [datetime]):
                formatted string representing a lapse of time.\n
                - format is : YYYYMMDDhhmmss. Eg :\n
                '19500917,21000917' (default).\n
                - It can also be an array of int Eg :\n
                [19500917,21000917].\n
                - It can also be an array of datetime Eg :\n
                [datetime.date(1900, 12, 5),datetime.date(2100, 12, 5)].
            groupby(str):
                Group by a period of time. Possible values :\n
                - 'yyyy' : group by year\n
                - 'yyyy-MM' : group by month\n
                - 'yyyy-MM-dd' : group by day\n
                - no value : all results
            aggregate(str):
                String representing the function to use to aggregate the data of the group by. Possible values :\n
                - 'avg' : average (default)
                - 'max' : maximum
                - 'min' : minimum
                - 'count' : number of result
                - 'std' : no se
        Returns:
            pandas: [timestamp, value] tuples

        You can use plot() to display the data in a graph.
        """

        data = self.getTimeserieRaw(index, varname, coord, datelaps, groupby, aggregate)
        ts = pd.DataFrame(data,columns=['time',str(index)+"_"+varname])
        ts['time'] = ts['time'].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))
        ts.set_index(['time'],inplace=True)
        return ts

    def mergeTimeserie(self, pandas):
        """
        Merge pandas dataframe into one dataframe
        It just uses the pandas function join. See
        http://pandas.pydata.org/pandas-docs/stable/merging.html

        Args:
            pandas([pandas]): List of pandas dataframe to merge.
        Returns:
            pandas: a single merged dataframe.
        """
        result = pandas[0].join(pandas[1:], how='outer')
        return result

    def getMergedTimeserie(self, indexTuples, coord, datelaps='19500917,21000917', groupby=None, aggregate='avg'):
        """
        For each index/varname tuple in indexTuples, this function
        will call getTimeserie() with the given parameters and merge
        the results into the same pandas dataframe.

        Args:
            indexTuples([[string,string]]):
                list of tuples [index, varname]
            otherArguments: see getTimeserie()

        Returns:
            pandas: a single merged dataframe.
        """
        pandas = []
        for indexTuple in indexTuples:
            pandas.append(self.getTimeserie(indexTuple[0], indexTuple[1], coord, datelaps, groupby, aggregate))
        return self.mergeTimeserie(pandas)

    def getIndexes(self):
        print self.datalapsService +'/config/'
        return json.loads(requests.get(self.datalapsService +'/config/', timeout = DEFAULT_TIMEOUT).content)

    def getTimeserieRaw(self, index, varname, coord, datelaps='19500917,21000917', groupby=None, aggregate='avg'):
        """
        Return time series of a data lapse at a position or in a
        rectangle of coordinates. This is the same as getTimeserie()
        but it returns the raw data (wich is a list of tuples) not
        transformed into pandas.

        Args:
            index (str): Name of the index to get data from.
            varname (str): Name of the variable of the index to get data from.
            coord(string or [float]):
                Corresponds to a position OR a rectangle of coordinates\n
                If a rectangle is passed, the data of the rectangle
                will be aggregated by the aggregate function given
                in parameter.\n
                Position : Array : [x1, y1] or String : "x1, y1".\n
                Rectangle : Array : [x1, y1, x2, y2] or String : "x1, y1, x2, y2".\n
            datelaps (str or [int] or [datetime]):
                formatted string representing a lapse of time.\n
                - format is : YYYYMMDDhhmmss. Eg :\n
                '19500917,21000917' (default).\n
                - It can also be an array of int Eg :\n
                [19500917,21000917].\n
                - It can also be an array of datetime Eg :\n
                [datetime.date(1900, 12, 5),datetime.date(2100, 12, 5)].
            groupby(str):
                Group by a period of time. Possible values :\n
                - 'yyyy' : group by year\n
                - 'yyyy-MM' : group by month\n
                - 'yyyy-MM-dd' : group by day\n
                - no value : all results
            aggregate(str):
                String representing the function to use to aggregate the data of the group by. Possible values :\n
                - 'avg' : average (default)
                - 'max' : maximum
                - 'min' : minimum
                - 'count' : number of result
                - 'std' : no se
        Returns:
            array: list of [timestamp, value] tuples
        """

        urlFormat = "{self.datalapsService}/{index}/{varname}/{coord}/{datelaps}/ts?{groupby}sm={aggregate}"

        url = self.getUrl(urlFormat, index, varname, coord, datelaps, groupby, aggregate)
        result = requests.get(url, timeout = DEFAULT_TIMEOUT).content
        return json.loads(result)['res']

    def getUrl(self, urlFormat, index, varname, coord,  datelaps='19500917,21000917', groupby=None, aggregate='avg', other_params= {}):
        """
        Create and return a url to get the information from Datalaps with the urlformat given in parameters.
        """

        if isinstance(datelaps, list) :
            datelaps = date2html(datelaps[0]) +","+ date2html(datelaps[1])
        else :
            datelaps = date2html(datelaps)

        if groupby!=None:
            groupby='groupby='+opt2html(groupby)+'&'
        else:groupby=''
        coord = bbox2html(coord)
        #print groupby
        # index = index2html(index)
        
        conf = locals()
        conf.update(other_params)
        #print conf
        url = urlFormat.format(**conf)
        print(url)
        return url

class Datahive(object):
    """
    Hive est une infrastructure d'entrepot de donnee integree sur Hadoop permettant l'analyse, le requetage via un langage proche syntaxiquement de SQL ainsi que la synthese de donnees.
    """


    def executeQueryPYHS2(self, query, host='br156-165', port=10000, authMechanism="PLAIN", user='root', password='test', database='default'):
        """
        execute

        NoteFred: fonctionne treeeeees lentement pour la recuperation des resultats ... 1000 records/s ==> des heures d'attente pour des millions de records... Passage a impyla
        Args:
            query(string):
        """
        import pyhs2
        from collections import OrderedDict
        with pyhs2.connect(host=host,
                           port=port,
                           authMechanism=authMechanism,
                           user=user,
                           password=password,
                           database=database) as conn:
            with conn.cursor() as cur:
                #Show databases
                # print cur.getDatabases()

                #Execute query
                t0 = time.time()
                cur.execute(query)
                t1 = time.time()
                elapsed = t1-t0
                print "Request time : %s"%(elapsed)

                #Return column info from query
                # print cur.getSchema()
                columns = OrderedDict()
                for column in cur.getSchema():
                    columns.update({column['columnName']:column['type']})
                print columns
                df = pd.DataFrame(cur.fetchall())
                print df.size
                if(df.size > 0):
                    df.columns = columns.keys()
                #Fetch table results
                #for i in cur.fetch():
                #    print i
                # df = pd.DataFrame(cur.fetchall())
                return df


    def executeQuery(self, query, host='br156-165', port=10000, auth_mechanism='PLAIN', user='root', password='test', database='default', output_pandas=True, queue_name='hive1'):
        from impala.dbapi import connect
        from impala.util import as_pandas
        conn = connect(host=host, port=port, auth_mechanism=auth_mechanism, user=user, password=password, database=database)
        cursor = conn.cursor()
        t0 = time.time()
        cursor.execute(query, configuration={'tez.queue.name':queue_name, 'mapred.job.queue.name':queue_name, 'mapreduce.job.queue.name':queue_name})
        t1 = time.time()
        elapsed = t1-t0
        print cursor.description
        print "Request time : %.2fs"%(elapsed)
        if output_pandas is True:
            df = as_pandas(cursor)
            t2 = time.time()
            elapsed = t2-t1
            print "Conversion to pandas : %.2fs"%(elapsed)
            return df
        else:
            res = cursor.fetchall()
            t2 = time.time()
            elapsed = t2-t1
            print "Fetch results : %.2fs"%(elapsed)
            return res


