Metadata-Version: 2.1
Name: geolibs-dator
Version: 0.0.3
Summary: GeoLibs Dator - A data extractor
Home-page: https://github.com/GeographicaGS/GeoLibs-Dator
License: MIT
Author: Geographica
Author-email: hello@geographica.com
Requires-Python: >=3.6,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Requires-Dist: PyYAML (>=5.1,<6.0)
Requires-Dist: SQLAlchemy (>=1.2.19,<1.3.0)
Requires-Dist: carto (>=1.4,<2.0)
Requires-Dist: cartoframes (>=0.9.2,<0.10.0)
Requires-Dist: google-cloud-bigquery (>=1.11,<2.0)
Requires-Dist: marshmallow (>=2.19,<3.0)
Requires-Dist: pandas (>=0.24.2,<0.25.0)
Requires-Dist: psycopg2-binary (>=2.8.2,<3.0.0)
Description-Content-Type: text/markdown

# GeoLibs-Dator
Dator, a data extractor (ETL as a library), that uses Pandas' DataFrames as in memory temporal storage.

### Features
| Source | Extract | Transform | Load |
| --- | --- | --- | --- |
| BigQuery | Y | Y |  |
| CARTO | Y | Y | Y* |
| CSV | Y |  | Y |
| Pandas |  | Y |  |
| PostgreSQL | Y | Y | Y |

_* Note:_ We are waiting for the append feature on [CARTOframes](https://github.com/CartoDB/cartoframes), because the one we are using is a _Ã±apa_.

### Configuration
Create a `config.yml` file using the `config.example.yml` one as guide. You can find in that one all the possible ETL cases.

If you are using BigQuery in your ETL process, you need to add a `GOOGLE_APPLICATION_CREDENTIALS` environment variable with the path to your Google Cloud's `credentials.json` file.

You can test them with the `example.py` file.

### Example

```python
from dator import Dator

dator = Dator('/usr/src/app/dator_config.yml')
df = dator.extract()
df = dator.transform(df)
dator.load(df)
```

### TODOs
- Better doc.
- Tests.

